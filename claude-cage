#!/bin/bash

# Detect operating system
detect_os() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        echo "macos"
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        echo "linux"
    else
        echo "unsupported"
    fi
}

OS_TYPE=$(detect_os)

# Parse --dry-run, --verbose, --debug, and --os early to allow OS simulation
dry_run=false
verbose=false
debug=false
simulated_os=""
next_is_os=false
for arg in "$@"; do
    if [ "$next_is_os" = true ]; then
        simulated_os="$arg"
        next_is_os=false
    elif [ "$arg" = "--dry-run" ]; then
        dry_run=true
    elif [ "$arg" = "--verbose" ] || [ "$arg" = "-v" ]; then
        verbose=true
    elif [ "$arg" = "--debug" ]; then
        debug=true
    elif [ "$arg" = "--os" ]; then
        next_is_os=true
    fi
done

# --debug implies --verbose
[ "$debug" = true ] && verbose=true

# Handle --os flag (only valid with --dry-run)
if [ -n "$simulated_os" ]; then
    if [ "$dry_run" != true ]; then
        echo "Error: --os can only be used with --dry-run"
        exit 1
    fi
    if [ "$simulated_os" != "linux" ] && [ "$simulated_os" != "macos" ]; then
        echo "Error: --os must be 'linux' or 'macos'"
        exit 1
    fi
    OS_TYPE="$simulated_os"
    echo "[dry-run] Simulating OS: $OS_TYPE"
fi

if [ "$OS_TYPE" = "unsupported" ]; then
    echo "Unsupported operating system: $OSTYPE"
    echo "claude-cage supports Linux and macOS only."
    exit 1
fi

# ============================================================================
# Dry-run Mode Helper Functions
# ============================================================================

# Note: dry_run, verbose, and OS_TYPE are parsed at the top of the script

# ANSI color codes
_yellow='\033[33m'
_reset='\033[0m'

# Wrapper function for commands that modify the system
# In dry-run mode, prints the command instead of executing it
# In verbose mode, prints the command in yellow before executing
run() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] $*"
        return 0
    fi
    if [ "$verbose" = true ]; then
        echo -e "${_yellow}[run] $*${_reset}" >&2
    fi
    "$@"
}

# Wrapper for commands that should be silent in normal mode but shown in dry-run
# In verbose mode, prints the command in yellow before executing
# In debug mode, shows command output instead of suppressing it
run_quiet() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] $*"
        return 0
    fi
    if [ "$verbose" = true ]; then
        echo -e "${_yellow}[run] $*${_reset}" >&2
    fi
    if [ "$debug" = true ]; then
        "$@"
    else
        "$@" >/dev/null 2>&1
    fi
}

# Run unison in background with proper PID tracking (output suppressed unless --debug)
# Usage: run_unison_bg [--pid-file FILE --pid-label LABEL] [--as USER] [--cmd] unison_args_or_cmd...
# Sets $unison_bg_pid to the PID of the backgrounded process
# If --pid-file is provided, writes "LABEL|PID" to the file
# If --as USER is provided, runs as that user via su (requires --cmd)
# If --cmd is provided, treats remaining arg as a command string for bash -c
# Default (no --cmd): arguments are passed directly to unison, preserving array quoting
run_unison_bg() {
    local pid_file=""
    local pid_label=""
    local run_as_user=""
    local is_cmd_string=false

    # Parse optional arguments
    while [[ "$1" == --* ]]; do
        case "$1" in
            --pid-file)
                pid_file="$2"
                shift 2
                ;;
            --pid-label)
                pid_label="$2"
                shift 2
                ;;
            --as)
                run_as_user="$2"
                shift 2
                ;;
            --cmd)
                is_cmd_string=true
                shift
                ;;
            *)
                break
                ;;
        esac
    done

    # Build display string (for dry-run/verbose output)
    # Note: Default case uses $* for display but "$@" for execution to preserve quoting
    local cmd_display
    if [ "$is_cmd_string" = true ]; then
        if [ -n "$run_as_user" ]; then
            cmd_display="su $run_as_user -c \"bash -c '$1'\""
        else
            cmd_display="$1"
        fi
    else
        cmd_display="unison $*"
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] $cmd_display &"
        unison_bg_pid="<PID>"
        return 0
    fi

    if [ "$verbose" = true ]; then
        echo -e "${_yellow}[run] $cmd_display &${_reset}" >&2
    fi

    # Execute in background (output suppressed unless --debug)
    if [ "$debug" = true ]; then
        if [ "$is_cmd_string" = true ]; then
            if [ -n "$run_as_user" ]; then
                su "$run_as_user" -c "bash -c '$1'" &
            else
                bash -c "$1" &
            fi
        else
            unison "$@" &
        fi
    else
        if [ "$is_cmd_string" = true ]; then
            if [ -n "$run_as_user" ]; then
                su "$run_as_user" -c "bash -c '$1'" >/dev/null 2>&1 &
            else
                bash -c "$1" >/dev/null 2>&1 &
            fi
        else
            unison "$@" >/dev/null 2>&1 &
        fi
    fi
    unison_bg_pid=$!

    if [ -n "$pid_file" ] && [ -n "$pid_label" ]; then
        echo "${pid_label}|${unison_bg_pid}" >> "$pid_file"
    fi
}

# Print a section header with a blank line before it
section_header() {
    echo ""
    echo "$*"
}

# Run a command inside a bwrap sandbox as the specified user (Linux bwrap mode only)
# Usage: run_in_bwrap <username> <mapped_home> <project_src> <project_dest> <workdir> [command...]
#
# Arguments:
#   username     - The cage user (e.g., "claude") for UID/GID and iptables
#   mapped_home  - Path to bindfs-mapped home (owned by cage user), mounted as /home/<user>
#   project_src  - Path to bindfs-mapped project files (owned by cage user)
#   project_dest - Mount destination inside sandbox (e.g., /home/claude/caged/project)
#   workdir      - Working directory inside sandbox
#   [command...] - Optional command to run (defaults to interactive shell)
#
# The persistent home and project files are pre-mapped via bindfs to appear owned
# by the cage user. bwrap constructs the final filesystem from these sources.
run_in_bwrap() {
    local username="$1"
    local mapped_home="$2"
    local project_src="$3"
    local project_dest="$4"
    local workdir="$5"
    shift 5

    local user_uid user_gid user_home
    user_home="/home/$username"
    # Get UID/GID, use placeholders in dry-run if user doesn't exist
    if user_uid=$(id -u "$username" 2>/dev/null); then
        user_gid=$(id -g "$username")
    else
        user_uid="<UID>"
        user_gid="<GID>"
    fi

    # Get hostname for the cage (caged.<host-hostname>)
    local cage_hostname="caged.$(hostname)"

    # Build bwrap command as a string (will be passed to su -c)
    local bwrap_cmd="bwrap"

    # System binaries (read-only)
    bwrap_cmd+=" --ro-bind /usr /usr"
    bwrap_cmd+=" --ro-bind /bin /bin"
    bwrap_cmd+=" --ro-bind /lib /lib"
    bwrap_cmd+=" --ro-bind-try /lib64 /lib64"
    bwrap_cmd+=" --ro-bind-try /sbin /sbin"

    # System config (read-only)
    bwrap_cmd+=" --ro-bind /etc/passwd /etc/passwd"
    bwrap_cmd+=" --ro-bind /etc/group /etc/group"
    bwrap_cmd+=" --ro-bind /etc/resolv.conf /etc/resolv.conf"
    bwrap_cmd+=" --ro-bind /etc/hosts /etc/hosts"
    bwrap_cmd+=" --ro-bind /etc/nsswitch.conf /etc/nsswitch.conf"
    bwrap_cmd+=" --ro-bind /etc/ssl /etc/ssl"
    bwrap_cmd+=" --ro-bind-try /etc/ca-certificates /etc/ca-certificates"
    bwrap_cmd+=" --ro-bind-try /etc/localtime /etc/localtime"
    bwrap_cmd+=" --ro-bind-try /etc/timezone /etc/timezone"
    bwrap_cmd+=" --ro-bind-try /etc/alternatives /etc/alternatives"

    # Home directory from mapped persistent home
    # This contains .claude/, .local/bin/claude, etc.
    bwrap_cmd+=" --bind '$mapped_home' '$user_home'"

    # Project files overlaid into home
    bwrap_cmd+=" --bind '$project_src' '$project_dest'"

    # Temp/runtime filesystems
    bwrap_cmd+=" --tmpfs /tmp"
    bwrap_cmd+=" --tmpfs /run"

    # Special filesystems
    bwrap_cmd+=" --proc /proc"
    bwrap_cmd+=" --dev /dev"
    bwrap_cmd+=" --dev-bind /dev/pts /dev/pts"

    # Environment variables
    bwrap_cmd+=" --setenv HOME '$user_home'"
    bwrap_cmd+=" --setenv USER '$username'"
    bwrap_cmd+=" --setenv SHELL /bin/bash"
    bwrap_cmd+=" --setenv LC_ALL '${LC_ALL}'"
    bwrap_cmd+=" --setenv PATH '/usr/local/bin:/usr/bin:/bin:$user_home/.local/bin'"
    bwrap_cmd+=" --setenv TERM '${TERM:-xterm-256color}'"
    bwrap_cmd+=" --setenv LANG '${LANG:-C.UTF-8}'"

    # User namespace (required for tmpfs/proc/dev mounts and --uid/--gid)
    bwrap_cmd+=" --unshare-user"
    bwrap_cmd+=" --uid $user_uid"
    bwrap_cmd+=" --gid $user_gid"

    # Process isolation
    bwrap_cmd+=" --unshare-pid"

    # Hostname isolation
    bwrap_cmd+=" --unshare-uts"
    bwrap_cmd+=" --hostname '$cage_hostname'"

    # Cleanup on parent exit
    bwrap_cmd+=" --die-with-parent"

    # Working directory
    bwrap_cmd+=" --chdir '$workdir'"

    # Add command or interactive shell
    if [ $# -eq 0 ]; then
        # No command: interactive login shell
        bwrap_cmd+=" /bin/bash -l"
    else
        # Command provided: run via login shell
        # Escape single quotes in the command
        local escaped_cmd="${*//\'/\'\\\'\'}"
        bwrap_cmd+=" /bin/bash -l -c '$escaped_cmd'"
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] sudo -u $username bash -c \"$bwrap_cmd\""
        return 0
    fi

    if [ "$verbose" = true ]; then
        echo -e "${_yellow}[run] sudo -u $username bash -c \"$bwrap_cmd\"${_reset}" >&2
    fi

    # Use sudo -u for cleaner semantics - bwrap sets up the environment via --setenv
    sudo -u "$username" bash -c "$bwrap_cmd"
}

# ============================================================================
# Instance and Process Management Helpers
# ============================================================================

# Filter live instances/PIDs from a file into an array
# Usage: filter_live_instances <file_path> <array_name>
# The array will contain only PIDs that are still running
filter_live_instances() {
    local file_path="$1"
    local -n result_array="$2"
    result_array=()

    [ -f "$file_path" ] || return 0

    while IFS= read -r inst_id; do
        if [ -n "$inst_id" ] && kill -0 "$inst_id" 2>/dev/null; then
            result_array+=("$inst_id")
        fi
    done < "$file_path"
}

# Kill processes from a PID file (simple format: one PID per line)
# Usage: kill_processes_from_file <file_path> [--remove]
# If --remove is specified, removes the file after killing processes
kill_processes_from_file() {
    local file_path="$1"
    local remove_file=false
    [ "$2" = "--remove" ] && remove_file=true

    [ -f "$file_path" ] || return 0

    while IFS= read -r pid; do
        if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
            run_quiet kill "$pid"
        fi
    done < "$file_path"

    if [ "$remove_file" = true ]; then
        run rm -f "$file_path"
    fi
}

# Kill processes from a labeled PID file (format: label|PID per line)
# Usage: kill_labeled_processes_from_file <file_path> [--remove]
kill_labeled_processes_from_file() {
    local file_path="$1"
    local remove_file=false
    [ "$2" = "--remove" ] && remove_file=true

    [ -f "$file_path" ] || return 0

    while IFS='|' read -r entry_name entry_pid; do
        if [ -n "$entry_pid" ] && kill -0 "$entry_pid" 2>/dev/null; then
            run_quiet kill "$entry_pid"
        fi
    done < "$file_path"

    if [ "$remove_file" = true ]; then
        run rm -f "$file_path"
    fi
}

# ============================================================================
# OS Abstraction Functions - User Management
# ============================================================================

# Check if user exists
user_exists() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -u "$username" >/dev/null 2>&1
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" >/dev/null 2>&1
    fi
}

# Get user UID
get_user_uid() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -u "$username" 2>/dev/null
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" UniqueID 2>/dev/null | awk '{print $2}'
    fi
}

# Get user GID
get_user_gid() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -g "$username" 2>/dev/null
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" PrimaryGroupID 2>/dev/null | awk '{print $2}'
    fi
}

# Get user home directory
# Create user
# For bwrap mode, we don't need a real home directory -
# the persistent home lives in ~/.local/share/claude-cage/ and is mounted via bwrap
create_user() {
    local username="$1"
    local user_home="$2"
    local use_custom_home="$3"  # true/false
    local create_home="${4:-true}"  # true/false, default true for backwards compat

    if [ "$OS_TYPE" = "linux" ]; then
        local home_args=""
        if [ "$use_custom_home" = "true" ]; then
            home_args="--home $user_home"
        fi
        if [ "$create_home" = "false" ]; then
            home_args="$home_args --no-create-home"
        fi
        run adduser --disabled-password --shell /bin/bash $home_args --comment "" "$username"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Find next available UID (starting from 501, avoiding system range)
        local max_uid=$(dscl . -list /Users UniqueID | awk '{print $2}' | sort -n | tail -1)
        local new_uid=$((max_uid + 1))
        if [ $new_uid -lt 501 ]; then
            new_uid=501
        fi

        # Find next available GID
        local max_gid=$(dscl . -list /Groups PrimaryGroupID | awk '{print $2}' | sort -n | tail -1)
        local new_gid=$((max_gid + 1))
        if [ $new_gid -lt 501 ]; then
            new_gid=501
        fi

        # Set home directory
        if [ "$use_custom_home" != "true" ]; then
            user_home="/Users/$username"
        fi

        # Create user using dscl
        run dscl . -create /Users/"$username"
        run dscl . -create /Users/"$username" UserShell /bin/bash
        run dscl . -create /Users/"$username" RealName "$username"
        run dscl . -create /Users/"$username" UniqueID "$new_uid"
        run dscl . -create /Users/"$username" PrimaryGroupID "$new_gid"
        run dscl . -create /Users/"$username" NFSHomeDirectory "$user_home"

        # Create home directory if it doesn't exist
        if [ ! -d "$user_home" ] || [ "$dry_run" = true ]; then
            run mkdir -p "$user_home"
            run chown "$username:staff" "$user_home"
            run chmod 755 "$user_home"
        fi

        # Create group (macOS requires this)
        if ! dscl . -read /Groups/"$username" >/dev/null 2>&1 || [ "$dry_run" = true ]; then
            run dscl . -create /Groups/"$username"
            run dscl . -create /Groups/"$username" PrimaryGroupID "$new_gid"
        fi
    fi
}

# Delete user
delete_user() {
    local username="$1"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet userdel -r "$username" || run_quiet userdel "$username"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Delete user
        run_quiet dscl . -delete /Users/"$username"
        # Delete group if it exists
        run_quiet dscl . -delete /Groups/"$username"
        # Remove home directory if it exists
        local user_home=$(dscl . -read /Users/"$username" NFSHomeDirectory 2>/dev/null | awk '{print $2}')
        if [ -n "$user_home" ] && [ -d "$user_home" ]; then
            run rm -rf "$user_home"
        fi
    fi
}

# ============================================================================
# OS Abstraction Functions - Network/Firewall
# ============================================================================

# Check if firewall chain/anchor exists
firewall_chain_exists() {
    local chain_name="$1"

    # In dry-run mode, report what we would check and return false (chain doesn't exist)
    if [ "$dry_run" = true ]; then
        echo "[dry-run] check firewall chain exists: $chain_name"
        return 1
    fi

    if [ "$OS_TYPE" = "linux" ]; then
        iptables -L "$chain_name" >/dev/null 2>&1
    elif [ "$OS_TYPE" = "macos" ]; then
        # Check if anchor exists in pf rules
        pfctl -s Anchors 2>/dev/null | grep -q "^$chain_name$"
    fi
}

# Create firewall chain/anchor
create_firewall_chain() {
    local chain_name="$1"
    local user_uid="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet iptables -N "$chain_name" || return 1
        # Jump to our chain for output from user
        run iptables -I OUTPUT -m owner --uid-owner "$user_uid" -j "$chain_name"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Create anchor in pf
        # macOS pf uses anchors - we'll load rules from a secure temp file
        if [ "$dry_run" = true ]; then
            echo "[dry-run] pf_rules_file=\$(mktemp)"
            echo "[dry-run] echo '# Claude-cage rules for UID $user_uid' > \$pf_rules_file"
            echo "[dry-run] echo 'anchor \"$chain_name\"' >> \$pf_rules_file"
            echo "[dry-run] pfctl -a $chain_name -f \$pf_rules_file"
            # Set a dummy path for dry-run mode (used by other pf functions)
            pf_rules_file="/tmp/dry-run-pf-rules"
            return 0
        fi

        # Use mktemp for secure temporary file (avoid TOCTOU attacks)
        pf_rules_file=$(mktemp)

        # Create the anchor definition
        echo "# Claude-cage rules for UID $user_uid" > "$pf_rules_file"
        echo "anchor \"$chain_name\"" >> "$pf_rules_file"

        # Load the anchor (this doesn't activate rules yet, just creates the anchor point)
        run_quiet pfctl -a "$chain_name" -f "$pf_rules_file" || return 1
    fi
}

# Add firewall rule
add_firewall_rule() {
    local chain_name="$1"
    local action="$2"        # ACCEPT or REJECT
    local ip_or_network="$3"
    local ports="$4"          # Optional: comma-separated ports or empty
    local insert_mode="$5"    # Optional: "insert" to add at beginning

    if [ "$OS_TYPE" = "linux" ]; then
        local iptables_action
        if [ "$action" = "ACCEPT" ]; then
            iptables_action="ACCEPT"
        else
            iptables_action="REJECT"
        fi

        local iptables_flag="-A"
        if [ "$insert_mode" = "insert" ]; then
            iptables_flag="-I"
        fi

        if [ -z "$ports" ]; then
            # No port restriction - allow/block all ports
            run iptables $iptables_flag "$chain_name" -d "$ip_or_network" -j "$iptables_action"
        else
            # Port restriction - apply to TCP and UDP
            if [[ "$ports" == *","* ]]; then
                # Multiple ports - use multiport
                run iptables $iptables_flag "$chain_name" -p tcp -d "$ip_or_network" -m multiport --dports "$ports" -j "$iptables_action"
                run iptables $iptables_flag "$chain_name" -p udp -d "$ip_or_network" -m multiport --dports "$ports" -j "$iptables_action"
            else
                # Single port
                run iptables $iptables_flag "$chain_name" -p tcp -d "$ip_or_network" --dport "$ports" -j "$iptables_action"
                run iptables $iptables_flag "$chain_name" -p udp -d "$ip_or_network" --dport "$ports" -j "$iptables_action"
            fi
        fi
    elif [ "$OS_TYPE" = "macos" ]; then
        # macOS pfctl - append rules to the anchor's rule file
        # pf_rules_file is set by create_firewall_chain
        local pf_action

        if [ "$action" = "ACCEPT" ]; then
            pf_action="pass"
        else
            pf_action="block"
        fi

        if [ "$dry_run" = true ]; then
            if [ -z "$ports" ]; then
                echo "[dry-run] echo '$pf_action out to $ip_or_network' >> \$pf_rules_file"
            else
                IFS=',' read -ra port_array <<< "$ports"
                for port in "${port_array[@]}"; do
                    echo "[dry-run] echo '$pf_action out proto tcp to $ip_or_network port $port' >> \$pf_rules_file"
                    echo "[dry-run] echo '$pf_action out proto udp to $ip_or_network port $port' >> \$pf_rules_file"
                done
            fi
            echo "[dry-run] pfctl -a $chain_name -f \$pf_rules_file"
            return 0
        fi

        if [ -z "$ports" ]; then
            # No port restriction
            echo "$pf_action out to $ip_or_network" >> "$pf_rules_file"
        else
            # With port restriction
            IFS=',' read -ra port_array <<< "$ports"
            for port in "${port_array[@]}"; do
                echo "$pf_action out proto tcp to $ip_or_network port $port" >> "$pf_rules_file"
                echo "$pf_action out proto udp to $ip_or_network port $port" >> "$pf_rules_file"
            done
        fi

        # Reload the anchor with updated rules
        run_quiet pfctl -a "$chain_name" -f "$pf_rules_file"
    fi
}

# Delete firewall chain/anchor
delete_firewall_chain() {
    local chain_name="$1"
    local user_uid="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        # Remove jump rule from OUTPUT chain
        run_quiet iptables -D OUTPUT -m owner --uid-owner "$user_uid" -j "$chain_name"

        # Flush and delete the chain
        run_quiet iptables -F "$chain_name"
        run_quiet iptables -X "$chain_name"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Flush rules from anchor
        run_quiet pfctl -a "$chain_name" -F all

        # Remove the temp file (pf_rules_file set by create_firewall_chain)
        if [ -n "$pf_rules_file" ] && [ -f "$pf_rules_file" ]; then
            run_quiet rm -f "$pf_rules_file"
        fi
    fi
}

# Get last rule number in chain (Linux iptables only)
get_last_firewall_rule_number() {
    local chain_name="$1"

    if [ "$OS_TYPE" = "linux" ]; then
        iptables -L "$chain_name" -n --line-numbers | grep -E "^[0-9]" | tail -1 | awk '{print $1}'
    elif [ "$OS_TYPE" = "macos" ]; then
        # Not applicable to pf
        echo ""
    fi
}

# Delete specific firewall rule by number (Linux iptables only)
delete_firewall_rule_by_number() {
    local chain_name="$1"
    local rule_number="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet iptables -D "$chain_name" "$rule_number"
    elif [ "$OS_TYPE" = "macos" ]; then
        # For pf, we rebuild the entire ruleset instead
        # This is handled in add_firewall_rule by rewriting the file
        :
    fi
}

# Add final catch-all rule to chain
add_catchall_firewall_rule() {
    local chain_name="$1"
    local action="$2"  # ACCEPT or REJECT

    if [ "$OS_TYPE" = "linux" ]; then
        run iptables -A "$chain_name" -j "$action"
    elif [ "$OS_TYPE" = "macos" ]; then
        # pf_rules_file is set by create_firewall_chain
        if [ "$dry_run" = true ]; then
            if [ "$action" = "ACCEPT" ]; then
                echo "[dry-run] echo 'pass out' >> \$pf_rules_file"
            else
                echo "[dry-run] echo 'block out' >> \$pf_rules_file"
            fi
            echo "[dry-run] pfctl -a $chain_name -f \$pf_rules_file"
            return 0
        fi

        if [ "$action" = "ACCEPT" ]; then
            echo "pass out" >> "$pf_rules_file"
        else
            echo "block out" >> "$pf_rules_file"
        fi
        run_quiet pfctl -a "$chain_name" -f "$pf_rules_file"
    fi
}

# Add network rules for a batch of domains/IPs/networks
# Usage: add_network_rules_batch <chain> <action> <type> <config_var> [insert_mode]
# type: "domains", "ips", or "networks"
# config_var: pipe-separated list of addresses (e.g., "domain1:443|domain2")
# insert_mode: optional "insert" to add at beginning of chain
add_network_rules_batch() {
    local chain_name="$1"
    local action="$2"
    local type="$3"
    local config_var="$4"
    local insert_mode="$5"

    [ -z "$config_var" ] && return 0

    IFS='|' read -ra items <<< "$config_var"
    for item_spec in "${items[@]}"; do
        IFS='|' read -r item ports < <(parse_ip_port "$item_spec")
        if [ "$type" = "domains" ]; then
            # Resolve domain to IPs
            while IFS= read -r ip; do
                [ -n "$ip" ] && add_firewall_rule "$chain_name" "$action" "$ip" "$ports" "$insert_mode"
            done < <(resolve_domain "$item")
        else
            # IPs or networks - add directly
            add_firewall_rule "$chain_name" "$action" "$item" "$ports" "$insert_mode"
        fi
    done
}

# ============================================================================
# Docker Mode Functions
# ============================================================================

# Check if docker command is available
docker_available() {
    command -v docker >/dev/null 2>&1
}

# Check if user has docker access (in docker group or root)
docker_accessible() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker ps (checking access)"
        return 0
    fi
    docker ps >/dev/null 2>&1
}

# Generate container name for isolated mode (per-project)
# Format: prefix-project-hash (hash from source path for uniqueness)
docker_container_name_isolated() {
    local prefix="$1"
    local project="$2"
    local source_path="$3"
    local hash=$(echo "$source_path" | md5sum | cut -c1-8)
    echo "${prefix}-${project}-${hash}"
}

# Generate container name for shared mode (all projects share one container)
# Format: prefix-uid (unique per user on the system)
docker_container_name_shared() {
    local prefix="$1"
    local uid="$2"
    echo "${prefix}-${uid}"
}

# Compute container name based on mode (existing, isolated, or shared)
# Consolidates the container name logic used in multiple places
docker_compute_container_name() {
    local existing_container="$1"
    local isolated="$2"
    local name_prefix="$3"
    local project="$4"
    local source="$5"
    local direct_mount="$6"

    if [ -n "$existing_container" ]; then
        echo "$existing_container"
    elif [ "$isolated" = "true" ]; then
        if [ "$direct_mount" = "workspace" ]; then
            local workspace_name=$(basename "$source")
            docker_container_name_isolated "$name_prefix" "$workspace_name" "$source"
        else
            docker_container_name_isolated "$name_prefix" "$project" "$source"
        fi
    else
        docker_container_name_shared "$name_prefix" "$(id -u)"
    fi
}

# Compute persistent home path based on isolation mode
# Docker: ~/.local/share/claude-cage/docker/<container-name>/home
# bwrap mode: ~/.local/share/claude-cage/bwrap/<username>/home
#
# For bwrap mode, we use a single shared home per username (like Docker's non-isolated mode).
# The persistent home is owned by the original user and mapped via bindfs for the cage user.
persistent_home_path() {
    local mode="$1"  # "docker" or "user"
    local identifier="$2"  # container name for docker, username for bwrap mode
    local owner_home="$3"  # home directory of the owner (original user)

    if [ "$mode" = "docker" ]; then
        echo "$owner_home/.local/share/claude-cage/docker/$identifier/home"
    else
        echo "$owner_home/.local/share/claude-cage/bwrap/$identifier/home"
    fi
}

# Backwards compat wrapper for docker mode
docker_persistent_home_path() {
    local isolated="$1"
    local config_root="$2"
    local project="$3"
    local container_name="$4"
    local owner_home="$5"
    persistent_home_path "docker" "$container_name" "$owner_home"
}

# Check if container exists (running or stopped)
docker_container_exists() {
    local container_name="$1"
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker container inspect $container_name"
        return 1  # Assume doesn't exist in dry-run
    fi
    docker container inspect "$container_name" >/dev/null 2>&1
}

# Check if container is running
docker_container_running() {
    local container_name="$1"
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker container inspect -f '{{.State.Running}}' $container_name"
        return 1  # Assume not running in dry-run
    fi
    [ "$(docker container inspect -f '{{.State.Running}}' "$container_name" 2>/dev/null)" = "true" ]
}

# Build or pull docker image with required packages
# Creates a cached image: claude-cage:hash (where hash is from base image + packages)
docker_ensure_image() {
    local base_image="$1"
    local packages="$2"  # pipe-separated list

    # Generate image tag from base + packages
    local image_hash=$(echo "${base_image}|${packages}" | md5sum | cut -c1-12)
    local image_tag="claude-cage:${image_hash}"

    # Check if our custom image already exists
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker image inspect $image_tag"
    elif docker image inspect "$image_tag" >/dev/null 2>&1; then
        echo "$image_tag"
        return 0
    fi

    # If no packages, just use the base image directly
    if [ -z "$packages" ]; then
        if [ "$dry_run" = true ]; then
            echo "[dry-run] docker pull $base_image (if needed)" >&2
        else
            echo "Pullin' base image $base_image (this might take a minute)..." >&2
            run docker pull "$base_image" 2>&1 | grep -E '^[a-f0-9]+:|Status:|Digest:' >&2 || true
        fi
        echo "$base_image"
        return 0
    fi

    # Build custom image with packages
    # Convert pipe-separated packages to space-separated for apt
    local pkg_list=$(echo "$packages" | tr '|' ' ')

    # Create Dockerfile
    local dockerfile_content="FROM ${base_image}
RUN apt-get update && apt-get install -y ${pkg_list} && rm -rf /var/lib/apt/lists/*
"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] Building Docker image $image_tag with packages: $pkg_list" >&2
        echo "[dry-run] docker build -t $image_tag -" >&2
        echo "$image_tag"
        return 0
    fi

    echo "Buildin' Docker image with packages: $pkg_list (this might take a minute)..." >&2
    echo "$dockerfile_content" | run docker build -t "$image_tag" - 2>&1 | grep -E '^Step |^Successfully |^ ---> ' >&2 || true
    if [ $? -ne 0 ]; then
        echo "Failed to build Docker image" >&2
        return 1
    fi

    echo "$image_tag"
}

# Start a new container
docker_start_container() {
    local container_name="$1"
    local image="$2"
    local mount_source="$3"
    local mount_dest="$4"
    local network_mode="$5"  # "none" or "bridge"
    local extra_args="$6"
    local host_uid="$7"
    local host_gid="$8"
    local home_mount="$9"    # Optional: host path for persistent home

    # Build home volume arg if provided
    local home_vol_arg=""
    if [ -n "$home_mount" ]; then
        home_vol_arg="-v \"$home_mount:/home/claude\""
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker run -d --name $container_name --hostname $container_name --network=$network_mode -u ${host_uid}:${host_gid} -e HOME=/home/claude $home_vol_arg -v \"$mount_source:$mount_dest\" -w \"$mount_dest\" --init $extra_args $image tail -f /dev/null"
        return 0
    fi

    # Build args array to handle paths with spaces properly
    # Set HOME explicitly since the UID may not exist in container's /etc/passwd
    # Use container name as hostname for consistency
    local -a docker_args=(
        "run" "-d"
        "--name" "$container_name"
        "--hostname" "$container_name"
        "--network=$network_mode"
        "-u" "${host_uid}:${host_gid}"
        "-e" "HOME=/home/claude"
    )

    # Add home volume mount if provided
    if [ -n "$home_mount" ]; then
        docker_args+=("-v" "$home_mount:/home/claude")
    fi

    docker_args+=(
        "-v" "$mount_source:$mount_dest"
        "-w" "$mount_dest"
        "--init"
    )

    # Add extra args if provided (these get word-split intentionally)
    if [ -n "$extra_args" ]; then
        docker_args+=($extra_args)
    fi

    docker_args+=("$image" "tail" "-f" "/dev/null")

    local output
    output=$(docker "${docker_args[@]}" 2>&1)
    local exit_code=$?
    if [ $exit_code -ne 0 ]; then
        echo "Docker error: $output" >&2
        return $exit_code
    fi
}

# Execute command in running container (internal implementation)
# Usage: _docker_exec_impl <interactive> container_name [--user username] command...
_docker_exec_impl() {
    local interactive="$1"
    local container_name="$2"
    shift 2
    local -a user_opt=()
    if [ "$1" = "--user" ]; then
        user_opt=("-u" "$2")
        shift 2
    fi

    local -a it_flag=()
    local it_display=""
    if [ "$interactive" = true ]; then
        it_flag=("-it")
        it_display="-it "
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker exec ${it_display}-e HOME=/home/claude ${user_opt[*]} $container_name $*"
        return 0
    fi

    # Set HOME explicitly since the UID may not exist in container's /etc/passwd
    run docker exec "${it_flag[@]}" -e HOME=/home/claude "${user_opt[@]}" "$container_name" "$@"
}

# Execute command in running container (interactive)
# Usage: docker_exec container_name [--user username] command...
docker_exec() {
    _docker_exec_impl true "$@"
}

# Execute command in running container (non-interactive)
# Usage: docker_exec_quiet container_name [--user username] command...
docker_exec_quiet() {
    _docker_exec_impl false "$@"
}

# Stop a running container
docker_stop_container() {
    local container_name="$1"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker stop $container_name"
        return 0
    fi

    run_quiet docker stop "$container_name"
}

# Remove a container
docker_remove_container() {
    local container_name="$1"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker rm $container_name"
        return 0
    fi

    run_quiet docker rm "$container_name"
}

# Copy file/directory to container
# For directories, removes destination first to avoid nesting (docker cp quirk)
# Important things first
print_banner() {
    local banner=$(cat << 'EOF'



   ██████╗██╗      █████╗ ██╗   ██╗██████╗ ███████╗
  ██╔════╝██║     ██╔══██╗██║   ██║██╔══██╗██╔════╝
  ██║     ██║     ███████║██║   ██║██║  ██║█████╗
  ██║     ██║     ██╔══██║██║   ██║██║  ██║██╔══╝
  ╚██████╗███████╗██║  ██║╚██████╔╝██████╔╝███████╗
   ╚═════╝╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝
                  ___________
                .'           '.
               /  -_-    -_-   \
              |    (_)  (_)     |
              |                 |          ,----.
              |      .---.      |         /||||||\
               \    '.__.'     /         | ||||||.|
                '.          .'           | |||||| |
                  '-._____.-'            | |||||| |
                      |||                |_||||||_|
                     /|||\                 \    /
                    / ||| \                 |  |

        ██████╗ █████╗  ██████╗ ███████╗
        ██╔════╝██╔══██╗██╔════╝ ██╔════╝
        ██║     ███████║██║  ███╗█████╗
        ██║     ██╔══██║██║   ██║██╔══╝
        ╚██████╗██║  ██║╚██████╔╝███████╗
         ╚═════╝╚═╝  ╚═╝ ╚═════╝ ╚══════╝


EOF
)

    # ANSI color codes
    local yellow='\033[33m'
    local reset='\033[0m'

    # Print banner line by line with a slight delay for "slide up" effect
    local line_num=0
    while IFS= read -r line; do
        line_num=$((line_num + 1))
        # Lines 4-9 are CLAUDE (after 3 blank lines), lines 23-28 are CAGE
        if (( line_num >= 4 && line_num <= 9 )) || (( line_num >= 23 && line_num <= 28 )); then
            echo -e "${yellow}${line}${reset}"
        else
            echo "$line"
        fi
        sleep 0.01
    done <<< "$banner"
    sleep 0.3
}

# Check if lua is available early (before sudo check)
if ! command -v lua >/dev/null 2>&1; then
    echo "Now listen carefully. We got a problem here."
    echo "I need lua installed on this bird."
    echo "Can't do nothin' without it."
    exit 1
fi

# Check for file monitoring tools (OS-specific)
if [ "$OS_TYPE" = "linux" ]; then
    # Linux uses inotify-tools
    if ! command -v inotifywait >/dev/null 2>&1; then
        echo "Hold on now. We got a problem here."
        echo "Unison needs inotify-tools for file monitoring."
        echo "Without it, this bird ain't gonna watch your files properly."
        echo "Install it: sudo apt install inotify-tools"
        exit 1
    fi
    # Linux bwrap mode uses bubblewrap for sandboxing
    if ! command -v bwrap >/dev/null 2>&1; then
        echo "Hold on now. We got a problem here."
        echo "I need bubblewrap (bwrap) installed for sandboxing."
        echo "Install it: sudo apt install bubblewrap"
        exit 1
    fi
elif [ "$OS_TYPE" = "macos" ]; then
    # macOS - fswatch is optional for unison, we'll fall back to polling
    # Just check that unison itself is available
    if ! command -v unison >/dev/null 2>&1; then
        echo "Hold on now. We got a problem here."
        echo "I need unison installed on this bird."
        echo "Install it: brew install unison"
        exit 1
    fi
fi

# Get the original user (in case running with sudo)
original_user="${SUDO_USER:-$USER}"

# Define config file paths
system_config="/etc/claude-cage/config"
user_config="/home/${original_user}/.config/claude-cage/config"

# Parse --config flag early (before config search)
explicit_config=""
config_next=false
for arg in "$@"; do
    if [ "$config_next" = true ]; then
        explicit_config="$arg"
        config_next=false
    elif [ "$arg" = "--config" ]; then
        config_next=true
    fi
done

# Function to search for config file up the directory tree
find_config() {
    local dir="$1"
    while [ "$dir" != "/" ]; do
        if [ -f "$dir/claude-cage.config" ]; then
            echo "$dir"
            return 0
        fi
        dir=$(dirname "$dir")
    done
    return 1
}

# Determine config file location
if [ -n "$explicit_config" ]; then
    # Explicit config specified with --config
    if [ ! -f "$explicit_config" ]; then
        echo "Hold on now. That config file '$explicit_config' ain't there."
        echo "Check your path and try again."
        exit 1
    fi
    local_config="$explicit_config"
    config_root=$(dirname "$(realpath "$explicit_config")")
else
    # Search up directory tree for config
    current_dir=$(pwd)
    config_root=$(find_config "$current_dir")
    if [ -z "$config_root" ]; then
        echo "Hold on now. I'm lookin' for a file called 'claude-cage.config' and it ain't here."
        echo "Searched from $(pwd) all the way up to /."
        echo "Can't take off without that config file somewhere above this directory."
        echo "You understand what I'm tellin' you?"
        exit 1
    fi
    local_config="$config_root/claude-cage.config"
fi

# Compute the relative path from config root to current working directory
current_dir=$(pwd)
config_root_real=$(realpath "$config_root")
current_dir_real=$(realpath "$current_dir")

# Calculate relative path from config root to CWD
if [ "$config_root_real" = "$current_dir_real" ]; then
    relative_path=""
else
    # Strip config_root prefix from current_dir to get relative path
    relative_path="${current_dir_real#$config_root_real/}"
fi

# Derive project name and start subdirectory from directory structure
# Project = first component of relative path (or basename of config root if at root)
# Start subdir = remainder of relative path
if [ -n "$relative_path" ]; then
    derived_project=$(echo "$relative_path" | cut -d'/' -f1)
    start_subdir_from_path=$(echo "$relative_path" | cut -d'/' -f2- -s)
else
    derived_project=$(basename "$config_root_real")
    start_subdir_from_path=""
fi

# Parse command line arguments BEFORE running Lua
# Need to extract non-flag argument to pass to Lua
cli_project_arg=""
skip_next=false
for arg in "$@"; do
    if [ "$skip_next" = true ]; then
        skip_next=false
        continue
    fi
    if [ "$arg" = "--config" ] || [ "$arg" = "--os" ]; then
        skip_next=true
        continue
    fi
    if [ "$arg" != "--test" ] && [ "$arg" != "--no-banner" ] && [ "$arg" != "--cleanup" ] && [ "$arg" != "--continue" ] && [ "$arg" != "--resume" ] && [ "$arg" != "--dry-run" ] && [ "$arg" != "--verbose" ] && [ "$arg" != "-v" ] && [ "$arg" != "--debug" ] && [ "$arg" != "--delete-docker-container" ]; then
        cli_project_arg="$arg"
        break
    fi
done

# Extract config values using Lua with multi-level loading
# Pass command-line project argument and derived values to Lua
lua_output=$(lua - "$cli_project_arg" "$derived_project" "$config_root_real" "$relative_path" <<EOF 2>&1
-- Get command-line project argument and derived values
local cli_arg = arg[1] or ""
local derived_project = arg[2] or ""
local config_root = arg[3] or ""
local relative_path = arg[4] or ""

-- Function to merge two tables (later overrides earlier)
local function merge_config(base, override)
    local result = {}

    -- Copy base config
    for k, v in pairs(base) do
        if type(v) == "table" then
            result[k] = {}
            for k2, v2 in pairs(v) do
                result[k][k2] = v2
            end
        else
            result[k] = v
        end
    end

    -- Override with new values
    for k, v in pairs(override) do
        if k == "exclude" and type(v) == "table" then
            -- Merge exclude sub-fields (path, name, belowPath, regex)
            result.exclude = result.exclude or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.exclude[subkey] = result.exclude[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.exclude[subkey], item)
                    end
                end
            end
        elseif k == "block" and type(v) == "table" then
            -- Merge block sub-fields (domains, ips, networks)
            result.block = result.block or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.block[subkey] = result.block[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.block[subkey], item)
                    end
                end
            end
        elseif k == "allow" and type(v) == "table" then
            -- Merge allow sub-fields (domains, ips, networks)
            result.allow = result.allow or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.allow[subkey] = result.allow[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.allow[subkey], item)
                    end
                end
            end
        elseif k == "cageLocal" and type(v) == "table" then
            -- Merge cageLocal sub-fields (path, name, belowPath, regex)
            -- cageLocal prevents new files created in cage from appearing in source
            result.cageLocal = result.cageLocal or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.cageLocal[subkey] = result.cageLocal[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.cageLocal[subkey], item)
                    end
                end
            end
        elseif k == "homeConfigSync" and type(v) == "table" then
            -- Merge homeConfigSync entries (array of paths/tables)
            result.homeConfigSync = result.homeConfigSync or {}
            for _, item in ipairs(v) do
                table.insert(result.homeConfigSync, item)
            end
        else
            -- Override value
            result[k] = v
        end
    end

    return result
end

-- Define a handler for claude_cage function
local configs = {}
function claude_cage(tbl)
    table.insert(configs, tbl)
end

-- Track items by source for display
local sources = {
    { name = "system", path = "$system_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "user", path = "$user_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "local", path = "$local_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "project", path = "", exclude = {}, cageLocal = {}, block = {}, allow = {} }  -- path set later
}

-- Helper to extract items from a config into a source tracker
local function track_items(source_entry, cfg)
    if cfg.exclude then
        for subkey, items in pairs(cfg.exclude) do
            source_entry.exclude[subkey] = source_entry.exclude[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.exclude[subkey], item)
                end
            end
        end
    end
    if cfg.cageLocal then
        for subkey, items in pairs(cfg.cageLocal) do
            source_entry.cageLocal[subkey] = source_entry.cageLocal[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.cageLocal[subkey], item)
                end
            end
        end
    end
    if cfg.block then
        for subkey, items in pairs(cfg.block) do
            source_entry.block[subkey] = source_entry.block[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.block[subkey], item)
                end
            end
        end
    end
    if cfg.allow then
        for subkey, items in pairs(cfg.allow) do
            source_entry.allow[subkey] = source_entry.allow[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.allow[subkey], item)
                end
            end
        end
    end
end

-- Load configs in priority order (system -> user -> local)
local config_files = {
    { idx = 1, path = "$system_config" },
    { idx = 2, path = "$user_config" },
    { idx = 3, path = "$local_config" }
}

for _, cf in ipairs(config_files) do
    local f = io.open(cf.path, "r")
    if f then
        f:close()
        local before_count = #configs
        local success, err = pcall(function()
            dofile(cf.path)
        end)
        if not success then
            io.stderr:write("Error loading config file: " .. cf.path .. "\n")
            io.stderr:write(tostring(err) .. "\n")
            os.exit(1)
        end
        -- Track items from newly loaded configs
        for i = before_count + 1, #configs do
            track_items(sources[cf.idx], configs[i])
        end
    end
end

-- Merge all configs loaded so far
local config = {}
for _, cfg in ipairs(configs) do
    config = merge_config(config, cfg)
end

-- Determine project name from CLI arg, config, or derived from directory structure
local project = cli_arg ~= "" and cli_arg or config.project or derived_project or ""

-- If project name is set, try to load project-specific config
if project ~= "" then
    local project_config = config_root .. "/" .. project .. ".claude-cage.config"
    sources[4].path = project_config
    local f = io.open(project_config, "r")
    if f then
        f:close()
        -- Reset configs table to reload just the project config
        local project_configs = {}
        local old_claude_cage = claude_cage
        function claude_cage(tbl)
            table.insert(project_configs, tbl)
        end

        local success, err = pcall(function()
            dofile(project_config)
        end)

        -- Restore original function
        claude_cage = old_claude_cage

        if not success then
            io.stderr:write("Error loading project config file: " .. project_config .. "\n")
            io.stderr:write(tostring(err) .. "\n")
            os.exit(1)
        end

        -- Track and merge project-specific configs
        for _, cfg in ipairs(project_configs) do
            track_items(sources[4], cfg)
            config = merge_config(config, cfg)
        end
    end
end

-- Update project from CLI arg if provided (CLI arg takes precedence)
if cli_arg ~= "" then
    config.project = cli_arg
    project = cli_arg
end

-- Set defaults from config, using derived values as fallbacks
-- Priority: CLI arg > config > derived from directory structure
if project == "" then
    project = config.project or derived_project
end
local user = config.user or "claude-cage"
local isolationMode = config.isolationMode or "bwrap"  -- Options: "bwrap" or "docker"
local source = config.source or ""
local sync = config.sync or ""
local mounted = config.mounted or ""
local directMount = config.directMount or false
local showBanner = config.showBanner
if showBanner == nil then showBanner = true end

-- Docker configuration defaults
local docker = config.docker or {}
local dockerImage = docker.image or "node:lts-slim"
local dockerPackages = docker.packages or {}
local dockerNamePrefix = docker.namePrefix or "claude-cage"
local dockerExtraArgs = docker.extraArgs or ""
local dockerIsolated = docker.isolated or false  -- false: shared container, true: per-project
local dockerContainer = docker.container or ""   -- Use existing container (user-managed)
local dockerUser = docker.user or ""             -- User to run as in existing container
local dockerWorkdir = docker.workdir or ""       -- Working directory in existing container

-- Validate isolationMode
if isolationMode ~= "bwrap" and isolationMode ~= "docker" then
    error("Invalid isolationMode: must be 'bwrap' or 'docker'")
end

-- Source defaults to the project directory (config_root/project)
-- This ensures we sync the specific project, not the entire parent workspace
-- In direct mount modes, source is the config root (mount the whole workspace or just project)
if source == "" then
    if directMount == "workspace" then
        -- Workspace mode: mount the entire config root
        source = config_root
    elseif directMount == "project" then
        -- Project mode: mount just the project subdirectory
        if relative_path ~= "" then
            source = config_root .. "/" .. project
        else
            source = config_root
        end
    else
        -- Sync mode: sync the project directory (first component of relative path)
        if relative_path ~= "" then
            source = config_root .. "/" .. project
        else
            -- At config root - this will be caught by validation later
            source = config_root
        end
    end
end

-- If sync is empty, set a placeholder (overridden in bash to use /run/)
-- Actual path: /run/claude-cage/<user>/sync/<original_user>/projects/<project> (bwrap mode)
--              /run/user/<uid>/claude-cage/projects/<project>/sync (docker mode)
if sync == "" then
    sync = "__default__"
end

-- Set mounted default to project name
if mounted == "" then
    if project ~= "" then
        mounted = project
    else
        mounted = "project"
    end
end

-- Network configuration defaults
local networkMode = config.networkMode or "disabled"

-- ============================================================================
-- Reusable function to build unison pattern arguments
-- Handles path, name, regex, belowPath arrays for both -ignore and -nocreationpartial
-- ============================================================================
local function build_pattern_args(obj, arg_type, source_path, path_prefix)
    if not obj then return "" end
    local args = ""
    path_prefix = path_prefix or ""

    -- For nocreationpartial, we need " -> source" suffix
    local suffix = ""
    if arg_type == "nocreationpartial" and source_path then
        suffix = " -> " .. source_path
    end

    -- name: Match files/folders by name anywhere in tree
    if obj.name then
        for _, item in ipairs(obj.name) do
            args = args .. '-' .. arg_type .. ' "Name ' .. item .. suffix .. '" '
        end
    end

    -- path: Match exact paths relative to replica root
    if obj.path then
        for _, item in ipairs(obj.path) do
            local full_path = path_prefix ~= "" and (path_prefix .. "/" .. item) or item
            args = args .. '-' .. arg_type .. ' "Path ' .. full_path .. suffix .. '" '
        end
    end

    -- regex: Match paths using regex patterns
    if obj.regex then
        for _, item in ipairs(obj.regex) do
            args = args .. '-' .. arg_type .. ' "Regex ' .. item .. suffix .. '" '
        end
    end

    -- belowPath: Match path and everything below it
    if obj.belowPath then
        for _, item in ipairs(obj.belowPath) do
            local full_path = path_prefix ~= "" and (path_prefix .. "/" .. item) or item
            args = args .. '-' .. arg_type .. ' "BelowPath ' .. full_path .. suffix .. '" '
        end
    end

    return args
end

-- Build exclude arguments for unison
local exclude = config.exclude or {}
local exclude_args = ""

-- Add exclude patterns using reusable function
exclude_args = exclude_args .. build_pattern_args(exclude, "ignore", nil, nil)

-- Build cageLocal arguments for unison (prevent new files in cage from being created on source)
-- Uses -nocreationpartial - only blocks creation, existing files still sync normally
local cageLocal = config.cageLocal or {}
local cageLocal_args = build_pattern_args(cageLocal, "nocreationpartial", source, nil)

-- Output basic config (use | delimiter to preserve empty fields)
print(user .. "|" .. source .. "|" .. sync .. "|" .. mounted .. "|" .. exclude_args .. "|" .. tostring(showBanner) .. "|" .. cageLocal_args)

-- Output exclude patterns for validation (pipe-separated)
local function array_to_string(arr)
    if not arr or #arr == 0 then return "EMPTY" end
    local result = {}
    for _, item in ipairs(arr) do
        table.insert(result, item)
    end
    return table.concat(result, "|")
end

print(array_to_string(exclude.path))
print(array_to_string(exclude.name))
print(array_to_string(exclude.regex))
print(array_to_string(exclude.belowPath))

-- Output cageLocal patterns for validation (pipe-separated)
print(array_to_string(cageLocal.path))
print(array_to_string(cageLocal.name))
print(array_to_string(cageLocal.regex))
print(array_to_string(cageLocal.belowPath))

-- Output network configuration
local allow = config.allow or {}
local block = config.block or {}
print(networkMode)
print(array_to_string(allow.domains))
print(array_to_string(allow.ips))
print(array_to_string(allow.networks))
print(array_to_string(block.domains))
print(array_to_string(block.ips))
print(array_to_string(block.networks))

-- Output project for validation
print(project)

-- Output directMount setting (false, "workspace", or "project")
print(tostring(directMount))

-- Output relative_path for start subdirectory (bash will use this)
print(relative_path)

-- Output config_root for source directory
print(config_root)

-- Output source-tracked items for display (format: SOURCE|TYPE|items,comma,separated)
-- This allows bash to display items grouped by source
local function format_source_items(src, category)
    local lines = {}
    local items = src[category] or {}
    for subkey, arr in pairs(items) do
        if #arr > 0 then
            table.insert(lines, src.name .. "|" .. subkey .. "|" .. table.concat(arr, ", "))
        end
    end
    return lines
end

-- Collect all display lines
local display_lines = {}
for _, src in ipairs(sources) do
    -- Check if this source has any items
    local has_items = false
    for _, cat in ipairs({"exclude", "cageLocal", "block", "allow"}) do
        for _, arr in pairs(src[cat] or {}) do
            if #arr > 0 then has_items = true break end
        end
        if has_items then break end
    end

    if has_items then
        for _, line in ipairs(format_source_items(src, "exclude")) do
            table.insert(display_lines, "EXCLUDE|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "cageLocal")) do
            table.insert(display_lines, "CAGELOCAL|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "block")) do
            table.insert(display_lines, "BLOCK|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "allow")) do
            table.insert(display_lines, "ALLOW|" .. line)
        end
    end
end

-- Output homeConfigSync entries
-- Format: path|dest|mode|exclude_args (exclude_args are unison -ignore arguments)
local homeConfigSync = config.homeConfigSync or {}
print(#homeConfigSync)
for _, entry in ipairs(homeConfigSync) do
    local path, dest, mode, exclude_args = "", "", "init", ""

    if type(entry) == "string" then
        -- Simple string: path = dest, mode = init
        path = entry
        dest = entry
    elseif type(entry) == "table" then
        if entry.path then
            -- New table syntax: { path = "...", destination = "...", mode = "...", exclude = {...} }
            path = entry.path
            dest = entry.destination or entry.path
            mode = entry.mode or "init"
            -- Build unison -ignore args for excludes, scoped to this entry's path
            -- Only path and belowPath are supported for homeConfigSync excludes
            if entry.exclude then
                exclude_args = build_pattern_args(entry.exclude, "ignore", nil, path)
            end
        elseif #entry == 2 then
            -- Legacy array syntax: { source, dest }
            path = entry[1]
            dest = entry[2]
        end
    end

    if path ~= "" then
        print(path .. "|" .. dest .. "|" .. mode .. "|" .. exclude_args)
    end
end

-- Output display line count, then lines
print(#display_lines)
for _, line in ipairs(display_lines) do
    print(line)
end

-- Output isolation mode and docker configuration
print(isolationMode)
print(dockerImage)
print(array_to_string(dockerPackages))
print(dockerNamePrefix)
print(dockerExtraArgs)
print(tostring(dockerIsolated))
print(dockerContainer)
print(dockerUser)
print(dockerWorkdir)
EOF
)
lua_exit_code=$?

# Check if lua command failed BEFORE parsing output
if [ $lua_exit_code -ne 0 ]; then
    echo ""
    echo "============================================"
    echo "Somethin' went wrong with the config files"
    echo "============================================"
    echo ""
    echo "$lua_output"
    echo ""
    echo "Now I want you to fix that and we'll try this again."
    exit 1
fi

# Parse the lua output (only if lua succeeded)
{
    IFS='|' read -r cfg_user cfg_source cfg_sync cfg_mounted cfg_exclude cfg_showBanner cfg_cageLocal
    read -r cfg_exclude_path
    read -r cfg_exclude_name
    read -r cfg_exclude_regex
    read -r cfg_exclude_belowPath
    read -r cfg_cageLocal_path
    read -r cfg_cageLocal_name
    read -r cfg_cageLocal_regex
    read -r cfg_cageLocal_belowPath
    read -r cfg_networkMode
    read -r cfg_allow_domains
    read -r cfg_allow_ips
    read -r cfg_allow_networks
    read -r cfg_block_domains
    read -r cfg_block_ips
    read -r cfg_block_networks
    read -r cfg_project
    read -r cfg_directMount
    read -r cfg_relative_path
    read -r cfg_config_root
    read -r cfg_homeConfigSync_count
    # Read homeConfigSync entries into array
    cfg_homeConfigSync=()
    for ((i=0; i<cfg_homeConfigSync_count; i++)); do
        read -r line
        cfg_homeConfigSync+=("$line")
    done
    read -r cfg_display_line_count
    # Read display lines into array
    cfg_display_lines=()
    for ((i=0; i<cfg_display_line_count; i++)); do
        read -r line
        cfg_display_lines+=("$line")
    done
    # Read isolation mode and docker configuration
    read -r cfg_isolationMode
    read -r cfg_docker_image
    read -r cfg_docker_packages
    read -r cfg_docker_namePrefix
    read -r cfg_docker_extraArgs
    read -r cfg_docker_isolated
    read -r cfg_docker_container
    read -r cfg_docker_user
    read -r cfg_docker_workdir
} <<< "$lua_output"

# Replace EMPTY placeholder with empty string for array values
[ "$cfg_exclude_path" = "EMPTY" ] && cfg_exclude_path=""
[ "$cfg_exclude_name" = "EMPTY" ] && cfg_exclude_name=""
[ "$cfg_exclude_regex" = "EMPTY" ] && cfg_exclude_regex=""
[ "$cfg_exclude_belowPath" = "EMPTY" ] && cfg_exclude_belowPath=""
[ "$cfg_cageLocal_path" = "EMPTY" ] && cfg_cageLocal_path=""
[ "$cfg_cageLocal_name" = "EMPTY" ] && cfg_cageLocal_name=""
[ "$cfg_cageLocal_regex" = "EMPTY" ] && cfg_cageLocal_regex=""
[ "$cfg_cageLocal_belowPath" = "EMPTY" ] && cfg_cageLocal_belowPath=""
[ "$cfg_allow_domains" = "EMPTY" ] && cfg_allow_domains=""
[ "$cfg_allow_ips" = "EMPTY" ] && cfg_allow_ips=""
[ "$cfg_allow_networks" = "EMPTY" ] && cfg_allow_networks=""
[ "$cfg_block_domains" = "EMPTY" ] && cfg_block_domains=""
[ "$cfg_block_ips" = "EMPTY" ] && cfg_block_ips=""
[ "$cfg_block_networks" = "EMPTY" ] && cfg_block_networks=""
[ "$cfg_docker_packages" = "EMPTY" ] && cfg_docker_packages=""

# Parse command line arguments
test_mode=false
cleanup_mode=false
delete_docker_container=false
claude_continue=false
claude_resume=false
source_arg=""
start_subdir=""
project_arg=""
skip_next_arg=false

for arg in "$@"; do
    if [ "$skip_next_arg" = true ]; then
        skip_next_arg=false
        continue
    fi
    if [ "$arg" = "--test" ]; then
        test_mode=true
    elif [ "$arg" = "--no-banner" ]; then
        cfg_showBanner="false"
    elif [ "$arg" = "--cleanup" ]; then
        cleanup_mode=true
    elif [ "$arg" = "--delete-docker-container" ]; then
        delete_docker_container=true
    elif [ "$arg" = "--continue" ]; then
        claude_continue=true
    elif [ "$arg" = "--resume" ]; then
        claude_resume=true
    elif [ "$arg" = "--config" ] || [ "$arg" = "--os" ]; then
        skip_next_arg=true
    elif [ "$arg" = "--dry-run" ]; then
        # Already parsed early, just skip here
        :
    elif [ "$arg" = "--verbose" ] || [ "$arg" = "-v" ]; then
        # Already parsed early, just skip here
        :
    elif [ "$arg" = "--debug" ]; then
        # Already parsed early, just skip here
        :
    else
        # Non-flag argument is either project name or subdirectory (depending on mode)
        source_arg="$arg"
    fi
done

# Handle start_subdir based on mode and relative path
# For sync mode: start_subdir is the path WITHIN the project (after the first component)
# For direct mount workspace: start_subdir is the full relative path
# For direct mount project: start_subdir is the path within the project
if [ "$cfg_directMount" = "workspace" ]; then
    # Workspace mode: full relative path from config root
    start_subdir="$cfg_relative_path"
elif [ "$cfg_directMount" = "project" ]; then
    # Project mode: path within project (after first component)
    if [ -n "$cfg_relative_path" ]; then
        start_subdir=$(echo "$cfg_relative_path" | cut -d'/' -f2- -s)
    fi
else
    # Sync mode: path within project (after first component)
    if [ -n "$cfg_relative_path" ]; then
        start_subdir=$(echo "$cfg_relative_path" | cut -d'/' -f2- -s)
    fi
fi

# Command-line argument can override start_subdir in direct mount modes
if [ -n "$source_arg" ] && [ "$cfg_directMount" = "workspace" -o "$cfg_directMount" = "project" ]; then
    start_subdir="$source_arg"
fi

# Source is now derived from config root by Lua
# No need to set default here

# Define cage_home_base early (needed by cleanup mode)
cage_home_base="/home/.claude-cage"

# Project is now derived from directory structure if not in config
# It will only be empty if both config and directory structure failed
if [ -z "$cfg_project" ]; then
    echo "Listen to me very carefully now."
    echo "Couldn't figure out a project name."
    echo "This shouldn't happen since it's derived from the directory structure."
    echo "Check your config file location and try again."
    exit 1
fi

# Docker mode dependency checks (must happen after config is parsed)
if [ "$cfg_isolationMode" = "docker" ]; then
    if ! docker_available; then
        echo "Hold on now. You're tryin' to use Docker mode but docker ain't installed."
        echo "Either install Docker or switch to bwrap mode (isolationMode = \"bwrap\")."
        exit 1
    fi
    if ! docker_accessible; then
        echo "Hold on now. Can't talk to Docker."
        echo "Either the daemon ain't runnin', or you don't have permission."
        echo ""
        echo "Try one of these:"
        echo "  - Start Docker: sudo systemctl start docker"
        echo "  - Add yourself to docker group: sudo usermod -aG docker $USER"
        echo "    (then log out and back in)"
        exit 1
    fi
fi

# Set sync directory in /run/
# bwrap mode: /run/claude-cage/<user>/sync/<original_user>/projects/<project>
# Docker mode: /run/user/<uid>/claude-cage/projects/<project>/sync
if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ]; then
    if [ "$cfg_isolationMode" = "docker" ]; then
        cfg_sync="/run/user/$(id -u)/claude-cage/projects/${cfg_project}/sync"
    else
        cfg_sync="/run/claude-cage/${cfg_user}/sync/${original_user}/projects/${cfg_project}"
    fi
fi

# In sync mode, validate we're not at the config root
# Running from config root would sync everything including sibling projects
if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ]; then
    if [ -z "$cfg_relative_path" ]; then
        echo "Hold on now. You're tryin' to run sync mode from the config root directory."
        echo "That would sync everythin' includin' all your sibling projects."
        echo ""
        echo "You got a few options:"
        echo "  1. cd into a subdirectory and run from there"
        echo "  2. Use direct mount mode: directMount = \"workspace\" or \"project\""
        echo "  3. Move your config file up one level"
        exit 1
    fi
fi

# Define PID and instance file paths early (needed for cleanup mode)
# bwrap mode: /run/claude-cage/<user>/projects/<project>/
# Docker mode: /run/user/<uid>/claude-cage/projects/<project>/
if [ "$cfg_isolationMode" = "docker" ]; then
    pid_file="/run/user/$(id -u)/claude-cage/projects/${cfg_project}/claude-cage.pid"
    local_instance_file="/run/user/$(id -u)/claude-cage/projects/${cfg_project}/claude-cage.instances"
else
    pid_file="/run/claude-cage/${cfg_user}/projects/${cfg_project}/claude-cage.pid"
    local_instance_file="/run/claude-cage/${cfg_user}/projects/${cfg_project}/claude-cage.instances"
fi

# For direct mount mode, we track instances by mount point (not project)
# This allows multiple projects under the same mount to share it
# The mount point instance file is stored in the user's home directory
# (will be set after user_home is determined)

# Source is derived from config_root, which should always exist
if [ -z "$cfg_source" ]; then
    echo "Hold on. Where's the source directory?"
    echo "This shouldn't happen since it's derived from the config location."
    echo "Check your setup and try again."
    exit 1
fi

if [ ! -d "$cfg_source" ]; then
    echo "Now we got a problem. That source directory '$cfg_source' don't exist."
    echo "Can't work with somethin' that ain't there."
    exit 1
fi

# In directMount mode, require a starting subdirectory/project if not at a subdirectory already
if [ "$cfg_directMount" = "workspace" ] || [ "$cfg_directMount" = "project" ]; then
    if [ -z "$start_subdir" ]; then
        echo "Hold on now. In direct mount mode, you gotta tell me which project to work in."
        echo "Either cd into a project subdirectory, or specify it on the command line."
        echo "Run it like: sudo claude-cage <subdirectory>"
        echo "For example: sudo claude-cage my-project"
        exit 1
    fi

    # Validate the subdirectory exists
    if [ ! -d "$cfg_source/$start_subdir" ]; then
        echo "Now we got a problem. That subdirectory '$cfg_source/$start_subdir' don't exist."
        echo "Can't start Claude in somethin' that ain't there."
        exit 1
    fi
fi

# Handle --delete-docker-container
if [ "$delete_docker_container" = true ]; then
    if [ "$cfg_isolationMode" != "docker" ]; then
        echo "Hold on. --delete-docker-container only works in Docker mode."
        echo "Your config has isolationMode = \"$cfg_isolationMode\""
        exit 1
    fi

    # Compute container name using helper
    container_name=$(docker_compute_container_name "$cfg_docker_container" "$cfg_docker_isolated" \
        "$cfg_docker_namePrefix" "$cfg_project" "$cfg_source" "$cfg_directMount")

    echo "Container: $container_name"

    # Check for active instances before deleting
    if [ -f "$local_instance_file" ]; then
        live_instances=()
        filter_live_instances "$local_instance_file" live_instances
        if [ ${#live_instances[@]} -gt 0 ]; then
            echo "Hold on there. Got ${#live_instances[@]} active instance(s) using this container."
            echo "Close 'em first, then try again."
            exit 1
        fi
    fi

    # Persistent home directory path
    persistent_home_dir="$HOME/.local/share/claude-cage/docker/$container_name"

    if ! docker_container_exists "$container_name"; then
        echo "Container don't exist. Nothin' to delete."
        # Still check for orphaned persistent home
        if [ -d "$persistent_home_dir" ] || [ "$dry_run" = true ]; then
            echo "But there's leftover data at: $persistent_home_dir"
            echo "Cleanin' that up..."
            run rm -rf "$persistent_home_dir"
            echo "Done."
        fi
        exit 0
    fi

    if docker_container_running "$container_name"; then
        echo "Stoppin' container..."
        docker_stop_container "$container_name"
    fi

    echo "Removin' container..."
    docker_remove_container "$container_name"

    # Also delete persistent home directory
    if [ -d "$persistent_home_dir" ] || [ "$dry_run" = true ]; then
        echo "Removin' persistent home data..."
        run rm -rf "$persistent_home_dir"
    fi

    echo "Done. Container and all its data are gone."
    exit 0
fi

# Handle cleanup mode
if [ "$cleanup_mode" = true ]; then
    # Check for root (unless dry-run or docker mode)
    if [ "$cfg_isolationMode" != "docker" ] && [ "$EUID" -ne 0 ] && [ "$dry_run" != true ]; then
        echo "Gonna need you to run this as root. Use sudo, Bay-BEE!"
        exit 1
    fi

    echo "=== CLEANUP MODE ==="
    section_header "Alright, let's clean up this operation."

    # Construct paths using same logic as main script
    # In bwrap architecture, mounts are in /run/claude-cage/<user>/bwrap/
    mapped_home_base="/run/claude-cage/$cfg_user/bwrap"
    mapped_home="$mapped_home_base/home"
    mapped_project="$mapped_home_base/projects/$cfg_mounted"

    # Find and unmount project bindfs mount
    echo "Checking for project mount..."
    if mountpoint -q "$mapped_project" 2>/dev/null || [ "$dry_run" = true ]; then
        echo "Found project mapping at $mapped_project, unmountin' it now..."
        run_quiet umount -l "$mapped_project"
        if [ $? -eq 0 ]; then
            echo "  Unmounted project. All clear."
        else
            echo "  Had some trouble unmountin' project. May need to clean that up yourself."
        fi
    else
        echo "  No project mapping at $mapped_project. Already clean."
    fi

    # Find and unmount home bindfs mount
    echo "Checking for home mount..."
    if mountpoint -q "$mapped_home" 2>/dev/null || [ "$dry_run" = true ]; then
        echo "Found home mapping at $mapped_home, unmountin' it now..."
        run_quiet umount -l "$mapped_home"
        if [ $? -eq 0 ]; then
            echo "  Unmounted home. All clear."
        else
            echo "  Had some trouble unmountin' home. May need to clean that up yourself."
        fi
    else
        echo "  No home mapping at $mapped_home. Already clean."
    fi

    # Clean up the /run directories if empty
    if [ "$dry_run" != true ]; then
        rmdir "$mapped_home_base/projects" 2>/dev/null
        rmdir "$mapped_home_base" 2>/dev/null
        rmdir "/run/claude-cage/$cfg_user/bwrap" 2>/dev/null
    fi

    # Find and unmount homeConfigSync mounts for this user (bwrap mode only)
    # Docker mode uses different paths and doesn't have bindfs mounts
    if [ "$cfg_isolationMode" != "docker" ]; then
        # Look for sync directories (structure: /run/claude-cage/<cage_user>/sync/<original_user>/home-config/)
        sync_base="/run/claude-cage/${cfg_user}/sync"
        echo "Checking for sync directories at $sync_base ..."
        if [ -d "$sync_base" ] || [ "$dry_run" = true ]; then
            # Check if any instances are still running for this user
            global_inst_file="/run/claude-cage/${cfg_user}/instances/global"
            skip_cleanup=false
            if [ -f "$global_inst_file" ] && [ "$dry_run" != true ]; then
                filter_live_instances "$global_inst_file" running_instances
                if [ ${#running_instances[@]} -gt 0 ]; then
                    echo "  WARNING: ${#running_instances[@]} instance(s) still running for user $cfg_user"
                    echo "           PIDs: ${running_instances[*]}"
                    echo "           Skipping cleanup. Stop instances first or use --cleanup again after they exit."
                    skip_cleanup=true
                fi
            fi

            if [ "$skip_cleanup" = false ]; then
                # Find all home-config directories under sync/<user>/
                found_homesync=false
                for homesync_dir in "$sync_base"/*/home-config/; do
                    [ -d "$homesync_dir" ] || continue
                    found_homesync=true
                    echo "  Found homeConfigSync directory: $homesync_dir"

                    if [ "$dry_run" = true ]; then
                        echo "[dry-run] kill <PIDs from ${homesync_dir}pids>"
                        echo "[dry-run] umount -l ${homesync_dir}cage-mount (bindfs mount)"
                        echo "[dry-run] umount per-entry mounts under ${homesync_dir}origin/"
                        echo "[dry-run] rm -rf $homesync_dir"
                    else
                        # Kill shared processes from the homesync PID file
                        if [ -f "${homesync_dir}pids" ]; then
                            echo "    Stopping shared homeConfigSync processes..."
                            kill_labeled_processes_from_file "${homesync_dir}pids" --remove
                        fi

                        # Unmount cage-mount/ bindfs mount first (it references origin/)
                        if mountpoint -q "${homesync_dir}cage-mount" 2>/dev/null; then
                            run_quiet umount -l "${homesync_dir}cage-mount"
                            echo "    Unmounted ${homesync_dir}cage-mount"
                        fi

                        # Unmount per-entry bindfs mounts in origin/ (both files and directories)
                        homesync_origin_dest_dir="${homesync_dir}origin"
                        if [ -d "$homesync_origin_dest_dir" ]; then
                            echo "    Unmounting origin/ per-entry mounts..."
                            for mount_path in $(mount | grep " ${homesync_origin_dest_dir}/" | awk '{print $3}'); do
                                if mountpoint -q "$mount_path" 2>/dev/null; then
                                    run_quiet umount -l "$mount_path"
                                    echo "      Unmounted $mount_path"
                                fi
                            done
                        fi

                        # Remove homesync directory
                        run_quiet rm -rf "$homesync_dir"
                        echo "    Cleaned up $homesync_dir"
                    fi
                done

                if [ "$found_homesync" = false ]; then
                    echo "  No homeConfigSync directories found."
                fi

                # Clean up sync directory structure if empty
                if [ "$dry_run" != true ]; then
                    for user_sync_dir in "$sync_base"/*/; do
                        [ -d "$user_sync_dir" ] || continue
                        rmdir "$user_sync_dir" 2>/dev/null
                    done
                    rmdir "$sync_base" 2>/dev/null
                fi
            fi
        else
            echo "  No sync directory found."
        fi

        # Check for persistent home directory
        persistent_home_dir="$HOME/.local/share/claude-cage/bwrap/${cfg_user}"
        echo "Checking for persistent home at $persistent_home_dir ..."
        if [ -d "$persistent_home_dir" ] || [ "$dry_run" = true ]; then
            echo "  Found persistent home directory."
            if [ "$dry_run" = true ]; then
                echo "[dry-run] Would prompt to delete persistent home"
            else
                echo -n "  Delete persistent home (contains Claude credentials)? (y/N): "
                read -r response
                if [ "$response" = "y" ] || [ "$response" = "Y" ]; then
                    run rm -rf "$persistent_home_dir"
                    # Clean up parent dirs if empty
                    rmdir "$HOME/.local/share/claude-cage/bwrap" 2>/dev/null
                    rmdir "$HOME/.local/share/claude-cage" 2>/dev/null
                    echo "  Persistent home deleted."
                else
                    echo "  Leaving persistent home alone."
                fi
            fi
        else
            echo "  No persistent home found."
        fi
    fi

    # Clean up iptables rules for this user (bwrap mode only)
    # Docker mode uses Docker networking, not iptables
    if [ "$cfg_isolationMode" != "docker" ]; then
        if user_exists "$cfg_user" || [ "$dry_run" = true ]; then
            user_uid=$(get_user_uid "$cfg_user")
            # Look for any chains with our pattern
            if [ "$OS_TYPE" = "linux" ]; then
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] iptables -L OUTPUT -n | grep CLAUDE_CAGE_"
                    echo "[dry-run] (would clean up any matching firewall chains)"
                else
                    # First, get all CLAUDE_CAGE chains and their associated UIDs from OUTPUT rules
                    iptables -L OUTPUT -n | grep "CLAUDE_CAGE_" | while read -r line; do
                        chain=$(echo "$line" | awk '{print $1}')
                        uid=$(echo "$line" | grep -o "owner UID match [0-9]*" | awk '{print $4}')

                        echo "Found firewall chain: $chain (UID: $uid), cleanin' it up..."

                        # Remove the OUTPUT jump rule
                        run_quiet iptables -D OUTPUT -m owner --uid-owner "$uid" -j "$chain"

                        # Flush and delete the chain
                        run_quiet iptables -F "$chain"
                        run_quiet iptables -X "$chain"

                        echo "  Done. $chain is gone."
                    done
                fi
            elif [ "$OS_TYPE" = "macos" ]; then
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] pfctl -s Anchors | grep CLAUDE_CAGE_"
                    echo "[dry-run] (would clean up any matching pf anchors)"
                else
                    # Clean up pf anchors
                    for anchor in $(pfctl -s Anchors 2>/dev/null | grep "CLAUDE_CAGE_"); do
                        echo "Found firewall anchor: $anchor, cleanin' it up..."
                        delete_firewall_chain "$anchor" "$user_uid"
                        echo "  Done. $anchor is gone."
                    done
                fi
            fi
        fi
    else
        # Docker mode doesn't need --cleanup (no system-level changes)
        echo ""
        echo "Docker mode doesn't leave system-level mess to clean up."
        echo "To delete a container, use: claude-cage --delete-docker-container"
    fi

    # Kill processes from PID file
    if [ -f "$pid_file" ] || [ "$dry_run" = true ]; then
        echo "Found PID file, stoppin' tracked processes..."
        if [ "$dry_run" = true ]; then
            echo "[dry-run] kill <PIDs from $pid_file>"
            echo "[dry-run] rm -f $pid_file"
        else
            while IFS= read -r pid; do
                if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
                    run_quiet kill "$pid"
                    echo "  Process $pid stopped."
                fi
            done < "$pid_file"
            run rm -f "$pid_file"
        fi
        echo "  PID file's gone."
    else
        echo "No PID file found at $pid_file"
    fi

    # Ask about user deletion (only in bwrap mode, not docker mode)
    # Docker mode doesn't create system users
    if [ "$cfg_isolationMode" != "docker" ]; then
        if user_exists "$cfg_user"; then
            echo ""
            echo "System user '$cfg_user' exists (used for iptables UID matching)."

            # Check if any instances are still running for this user
            global_inst_file="/run/claude-cage/${cfg_user}/instances/global"
            has_running_instances=false
            if [ -f "$global_inst_file" ]; then
                filter_live_instances "$global_inst_file" running_instances
                if [ ${#running_instances[@]} -gt 0 ]; then
                    has_running_instances=true
                fi
            fi

            if [ "$has_running_instances" = true ]; then
                echo "Other instances are still runnin'. Not gonna delete the user."
            elif [ "$dry_run" = true ]; then
                echo "[dry-run] Would prompt to delete user '$cfg_user'"
            else
                echo -n "Want me to delete this system user? (y/N): "
                read -r response
                if [ "$response" = "y" ] || [ "$response" = "Y" ]; then
                    echo "Alright, deletin' user '$cfg_user'..."
                    delete_user "$cfg_user"
                    echo "User '$cfg_user' is gone."
                else
                    echo "Leavin' user '$cfg_user' alone."
                fi
            fi
        else
            echo "System user '$cfg_user' doesn't exist. Nothin' to delete."
        fi
    fi

    section_header "Cleanup complete. All done."
    exit 0
fi

# Now check for root after validating config (unless dry-run or docker mode)
# Docker mode doesn't need root - just Docker group membership
if [ "$cfg_isolationMode" != "docker" ] && [ "$EUID" -ne 0 ] && [ "$dry_run" != true ]; then
    echo "Gonna need you to run this as root. Use sudo, Bay-BEE!"
    exit 1
fi

if [ "$cfg_showBanner" = "true" ]; then
    print_banner
fi

echo "Alright. Here's what we're workin' with:"
echo ""
echo "Configuration:"
echo "  Project:       $cfg_project"
echo "  Isolation:     $cfg_isolationMode"
if [ "$cfg_isolationMode" = "docker" ]; then
    echo "  Image:         $cfg_docker_image"
    if [ -n "$cfg_docker_packages" ]; then
        echo "  Packages:      $(echo "$cfg_docker_packages" | tr '|' ' ')"
    fi
else
    echo "  User:          $cfg_user"
fi
if [ "$cfg_directMount" = "workspace" ]; then
    echo "  File mode:     Direct mount (workspace - access to sibling projects)"
    echo "  Source:        $cfg_source"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
elif [ "$cfg_directMount" = "project" ]; then
    echo "  File mode:     Direct mount (project only)"
    echo "  Source:        $cfg_source"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
else
    echo "  File mode:     Sync mode"
    echo "  Source:        $cfg_source"
    echo "  Sync:          $cfg_sync"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
fi
if [ "$cfg_isolationMode" != "docker" ]; then
    echo "  Mount point:   /home/${cfg_user}/caged/${cfg_mounted}"
fi
echo "  Network mode:  $cfg_networkMode"

# Display excludes and network rules grouped by source config
# Format from Lua: CATEGORY|source|type|items,comma,separated
# Sources are ordered: system, user, local, project

# Helper to get display name for source
get_source_display() {
    case "$1" in
        system) echo "System config" ;;
        user) echo "User config" ;;
        local) echo "Local config" ;;
        project) echo "Project config" ;;
        *) echo "$1" ;;
    esac
}

# Display a pattern-based config section (Excludes, Cage-local, Block, Allow)
# Usage: display_config_section CATEGORY "Header text" [show_if_empty]
display_config_section() {
    local filter_category="$1"
    local header="$2"
    local show_if_empty="${3:-false}"
    local has_items=false
    local current_source=""

    for line in "${cfg_display_lines[@]}"; do
        IFS='|' read -r category source type items <<< "$line"
        if [ "$category" = "$filter_category" ]; then
            if [ "$has_items" = false ]; then
                echo ""
                echo "$header"
                has_items=true
            fi
            if [ "$source" != "$current_source" ]; then
                current_source="$source"
                echo "  $(get_source_display "$source"):"
            fi
            # Capitalize first letter of type, preserve camelCase for belowPath
            local type_display
            type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
            [ "$type" = "belowPath" ] && type_display="BelowPath"
            printf "    %-10s %s\n" "$type_display:" "$items"
        fi
    done

    if [ "$has_items" = false ] && [ "$show_if_empty" = true ]; then
        echo ""
        echo "$header"
        echo "  (none)"
    fi
}

# Display Excludes (always show, even if empty)
display_config_section "EXCLUDE" "Excludes:" true

# Display Cage-local (only if present)
display_config_section "CAGELOCAL" "Cage-local files (new creations blocked on source):"

# Display homeConfigSync entries if any (group consecutive non-sync entries by mode)
if [ ${#cfg_homeConfigSync[@]} -gt 0 ]; then
    echo ""
    echo "Home config sync:"

    hcs_prev_mode=""
    hcs_pending_entries=""

    for entry in "${cfg_homeConfigSync[@]}"; do
        IFS='|' read -r sync_source sync_dest sync_mode sync_excludes <<< "$entry"

        # Format entry (show -> dest if different)
        hcs_entry_display="$sync_source"
        [ "$sync_source" != "$sync_dest" ] && hcs_entry_display="$sync_source -> $sync_dest"

        if [ "$sync_mode" = "sync" ]; then
            # Flush any pending entries first
            if [ -n "$hcs_pending_entries" ]; then
                printf "  %-6s %s\n" "[$hcs_prev_mode]" "$hcs_pending_entries"
                hcs_pending_entries=""
            fi
            # Sync mode: show on its own line with excludes
            hcs_sync_display="$hcs_entry_display"
            if [ -n "$sync_excludes" ]; then
                # Extract just the paths from -ignore "Path x" -ignore "BelowPath y" format
                hcs_exclude_paths=$(echo "$sync_excludes" | sed 's/-ignore "//g; s/" /,/g; s/"$//; s/Path //g; s/BelowPath //g; s/Name //g')
                hcs_sync_display="$hcs_sync_display (excludes: $hcs_exclude_paths)"
            fi
            printf "  %-6s %s\n" "[sync]" "$hcs_sync_display"
            hcs_prev_mode=""
        elif [ "$sync_mode" = "$hcs_prev_mode" ]; then
            # Same mode as previous, append
            hcs_pending_entries="$hcs_pending_entries, $hcs_entry_display"
        else
            # Different mode, flush previous and start new group
            if [ -n "$hcs_pending_entries" ]; then
                printf "  %-6s %s\n" "[$hcs_prev_mode]" "$hcs_pending_entries"
            fi
            hcs_pending_entries="$hcs_entry_display"
            hcs_prev_mode="$sync_mode"
        fi
    done

    # Flush any remaining entries
    if [ -n "$hcs_pending_entries" ]; then
        printf "  %-6s %s\n" "[$hcs_prev_mode]" "$hcs_pending_entries"
    fi
fi

# Display network rules by source if network mode is enabled
if [ "$cfg_networkMode" != "disabled" ]; then
    echo ""
    echo "Network restrictions ($cfg_networkMode mode):"

    has_block=false
    has_allow=false
    current_source=""

    # Show block rules first (for blocklist mode)
    if [ "$cfg_networkMode" = "blocklist" ]; then
        for line in "${cfg_display_lines[@]}"; do
            IFS='|' read -r category source type items <<< "$line"
            if [ "$category" = "BLOCK" ]; then
                has_block=true
                if [ "$source" != "$current_source" ]; then
                    current_source="$source"
                    echo "  Block ($(get_source_display "$source")):"
                fi
                type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
                printf "    %-10s %s\n" "$type_display:" "$items"
            fi
        done
    fi

    # Show allow rules
    current_source=""
    for line in "${cfg_display_lines[@]}"; do
        IFS='|' read -r category source type items <<< "$line"
        if [ "$category" = "ALLOW" ]; then
            has_allow=true
            if [ "$source" != "$current_source" ]; then
                current_source="$source"
                if [ "$cfg_networkMode" = "blocklist" ]; then
                    echo "  Exceptions ($(get_source_display "$source")):"
                else
                    echo "  Allow ($(get_source_display "$source")):"
                fi
            fi
            type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
            printf "    %-10s %s\n" "$type_display:" "$items"
        fi
    done
fi
echo ""

# Set computed values
cfg_user="${cfg_user:-claude-cage}"
if [ -z "$cfg_mounted" ]; then
    cfg_mounted="$cfg_source"
fi

# Validate and sanitize username
original_username="$cfg_user"
sanitized_username="$cfg_user"
was_truncated=false

# Check for invalid characters (allowed: lowercase letters, digits, hyphens, underscores)
# Must start with a letter or underscore
if [[ ! "$sanitized_username" =~ ^[a-zA-Z_][a-zA-Z0-9_-]*$ ]]; then
    # Replace invalid characters with hyphens
    # First, ensure it starts with a valid character
    if [[ ! "$sanitized_username" =~ ^[a-zA-Z_] ]]; then
        sanitized_username="u-$sanitized_username"
    fi
    # Replace invalid characters with hyphens
    sanitized_username=$(echo "$sanitized_username" | sed 's/[^a-zA-Z0-9_-]/-/g')
    # Convert to lowercase for maximum compatibility
    sanitized_username=$(echo "$sanitized_username" | tr '[:upper:]' '[:lower:]')
fi

# Remove trailing hyphens/underscores (valid but not best practice)
if [[ "$sanitized_username" =~ [-_]+$ ]]; then
    sanitized_username=$(echo "$sanitized_username" | sed 's/[-_]*$//')
fi

# Check username length (useradd has 32 character limit)
if [ ${#sanitized_username} -gt 32 ]; then
    sanitized_username="${sanitized_username:0:32}"
    # Re-check for trailing hyphens after truncation
    sanitized_username=$(echo "$sanitized_username" | sed 's/[-_]*$//')
    was_truncated=true
fi

# Display warning only if username was truncated
if [ "$was_truncated" = true ]; then
    echo ""
    echo "Hold on now. That username's too long for this bird."
    echo "What you wanted:  $original_username (${#original_username} characters)"
    echo "What you got:     $sanitized_username (${#sanitized_username} characters)"
    echo "Had to trim it down. Regulations, you understand."
    echo ""
fi

cfg_user="$sanitized_username"

# Check if sanitized username conflicts with existing system user
if [ "$original_username" != "$sanitized_username" ] && user_exists "$sanitized_username"; then
    echo ""
    echo "Hold on now. We got ourselves a situation here."
    echo "After cleanin' up that username, it became '$sanitized_username'"
    echo "But there's already a user with that name on this system."
    echo ""
    echo "You got two choices:"
    echo "  1. Change the username in your config to somethin' else"
    echo "  2. Continue if you're sure this is the right user to use"
    echo ""
    read -p "Continue with existing user '$sanitized_username'? [y/N] " -n 1 -r
    echo
    if ! [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "Smart move. Change that username and try again."
        exit 1
    fi
fi

# Track if user exists before we start
user_existed_before=false
if user_exists "$cfg_user"; then
    user_existed_before=true
fi

# Create claude-cage base directory for tracking/config
run mkdir -p "$cage_home_base"

# Track whether we prompted the user to continue
user_was_prompted=false

# Create user if it doesn't exist (or show what would be created in dry-run)
# For bwrap mode with bwrap: user is created without home directory (just for iptables UID)
# The persistent home lives in ~/.local/share/claude-cage/bwrap/<username>/home/
if ! user_exists "$cfg_user" || [ "$dry_run" = true ]; then
    if [ "$dry_run" = true ]; then
        echo "Would create user '$cfg_user' without home dir (doesn't exist or dry-run mode)."
        create_user "$cfg_user" "" "false" "false"
        user_was_prompted=true
    else
        echo "That user '$cfg_user' ain't on this system yet."
        read -p "Want me to create that user? [y/N] " -n 1 -r
        echo
        user_was_prompted=true
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            # Create user without home directory - we use a persistent home in ~/.local/share/claude-cage/
            create_user "$cfg_user" "" "false" "false"
            echo "Done. User '$cfg_user' is ready (no home dir - we'll use persistent home instead)."
        else
            echo "Can't fly this bird without that user. We're done here."
            exit 1
        fi
    fi
fi

# Prompt to continue if user wasn't already prompted during user creation (skip in dry-run)
if [ "$user_was_prompted" = "false" ] && [ "$dry_run" != true ]; then
    echo ""
    read -p "Ready to proceed? [Y/n] " -n 1 -r key
    echo
    if [[ $key =~ ^[Nn]$ ]]; then
        echo "Alright, abortin' the mission."
        exit 0
    fi
fi

# Set up persistent home and user info
# Both Docker and bwrap mode use ~/.local/share/claude-cage/{docker,bwrap}/<name>/home/
# This is owned by the original user; for bwrap mode, bindfs maps it to appear owned by cage user
original_home="/home/$original_user"
if [ "$dry_run" = true ]; then
    user_uid="${user_uid:-<UID>}"
    if [ "$cfg_isolationMode" = "docker" ]; then
        persistent_home=$(persistent_home_path "docker" "$docker_container_name_value" "$original_home")
    else
        persistent_home=$(persistent_home_path "user" "$cfg_user" "$original_home")
    fi
elif [ "$cfg_isolationMode" = "docker" ]; then
    user_uid="$(id -u)"  # Current user's UID for file ownership
    persistent_home=$(persistent_home_path "docker" "$docker_container_name_value" "$original_home")
else
    # bwrap mode: get cage user's UID for iptables rules
    user_uid=$(get_user_uid "$cfg_user")
    persistent_home=$(persistent_home_path "user" "$cfg_user" "$original_home")
fi

# For bwrap mode, we also need the mapped home path in /run (bindfs target)
# This appears owned by the cage user and is what bwrap mounts as /home/<user>
if [ "$cfg_isolationMode" != "docker" ]; then
    mapped_home_base="/run/claude-cage/$cfg_user/bwrap"
    mapped_home="$mapped_home_base/home"
    mapped_project_base="$mapped_home_base/projects"
    # Create persistent home early so homeConfigSync_copy can use it
    # Must be owned by original user (bindfs will map to cage user)
    run mkdir -p "$persistent_home"
    [ "$dry_run" != true ] && chown -R "$original_user:$original_user" "$HOME/.local/share/claude-cage"
fi

# Global arrays for homeConfigSync sync mode (populated by homeConfigSync_init)
# Used later to set up unison monitoring
declare -a homesync_sync_sources=()
declare -a homesync_sync_excludes=()

# Parse homeConfigSync entries and extract sync mode info for later unison setup
# Call this early, before homeConfigSync_copy
homeConfigSync_init() {
    for entry in "${cfg_homeConfigSync[@]}"; do
        IFS='|' read -r sync_source sync_dest sync_mode sync_excludes <<< "$entry"
        if [ "$sync_mode" = "sync" ]; then
            homesync_sync_sources+=("$sync_source")
            [ -n "$sync_excludes" ] && homesync_sync_excludes+=("$sync_excludes")
        fi
    done
}

# Do initial copies for all homeConfigSync entries
# Call this before Claude installation check so .local/bin/claude is available
# Args: target_home (destination home directory)
# Both modes now use persistent_home owned by original user, so no chown needed
homeConfigSync_copy() {
    local target_home="$1"
    local original_home="/home/${original_user}"
    local needs_chown=false  # No chown needed - persistent_home is owned by original user

    for entry in "${cfg_homeConfigSync[@]}"; do
        IFS='|' read -r sync_source sync_dest sync_mode sync_excludes <<< "$entry"
        local source_path="${original_home}/${sync_source}"
        local dest_path="${target_home}/${sync_dest}"
        local dest_dir=$(dirname "$dest_path")

        # Display mode info in dry-run
        if [ "$dry_run" = true ]; then
            echo "homeConfigSync: $sync_source -> $sync_dest (mode=$sync_mode)"
        fi

        case "$sync_mode" in
            init)
                # Copy only if destination doesn't exist
                if [ -e "$dest_path" ] && [ "$dry_run" != true ]; then
                    continue
                fi
                # Fall through to copy logic
                ;&
            copy)
                # copy: Copy on startup, overwrites existing
                if [ -f "$source_path" ] || [ -d "$source_path" ] || [ "$dry_run" = true ]; then
                    # Create destination parent directory if needed
                    if [ ! -d "$dest_dir" ]; then
                        run mkdir -p "$dest_dir"
                        # Chown all new directories up to target_home
                        if [ "$needs_chown" = true ]; then
                            local current="$dest_dir"
                            while [ "$current" != "$target_home" ] && [ "$current" != "/" ]; do
                                run chown "$cfg_user:$cfg_user" "$current"
                                current=$(dirname "$current")
                            done
                        fi
                    fi

                    # Sync file or directory
                    if [ "$dry_run" = true ]; then
                        if [ -d "$source_path" ]; then
                            echo "[dry-run] rsync -rL $source_path/ $dest_path/"
                            [ "$needs_chown" = true ] && echo "[dry-run] chown -R $cfg_user:$cfg_user $dest_path"
                        else
                            echo "[dry-run] rsync -L $source_path $dest_path"
                            [ "$needs_chown" = true ] && echo "[dry-run] chown $cfg_user:$cfg_user $dest_path"
                        fi
                    else
                        if [ -d "$source_path" ]; then
                            # Directory: recursive sync with trailing slashes, follow symlinks
                            run rsync -rL "$source_path/" "$dest_path/"
                            [ "$needs_chown" = true ] && run chown -R "$cfg_user:$cfg_user" "$dest_path"
                            [ "$verbose" = true ] && echo "Synced $sync_source/ -> $sync_dest/ (mode=$sync_mode)"
                        elif [ -f "$source_path" ]; then
                            # File: follow symlinks (-L)
                            run rsync -L "$source_path" "$dest_path"
                            [ "$needs_chown" = true ] && run chown "$cfg_user:$cfg_user" "$dest_path"
                            [ "$verbose" = true ] && echo "Synced $sync_source -> $sync_dest (mode=$sync_mode)"
                        fi
                    fi
                fi
                ;;
            sync)
                # sync: Skip here - unison handles initial copy and ongoing sync
                ;;
            link)
                # Symlink from cage home to host path (bwrap mode only)
                if [ "$cfg_isolationMode" = "docker" ]; then
                    echo "Warning: mode=link not supported for Docker containers, skipping $sync_source"
                    continue
                fi
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] ln -s $source_path $dest_path"
                else
                    # Create parent directory if needed
                    if [ ! -d "$dest_dir" ]; then
                        run mkdir -p "$dest_dir"
                        # Chown all new directories up to target_home
                        local current="$dest_dir"
                        while [ "$current" != "$target_home" ] && [ "$current" != "/" ]; do
                            run chown "$cfg_user:$cfg_user" "$current"
                            current=$(dirname "$current")
                        done
                    fi
                    # Remove existing file/link if present
                    if [ -e "$dest_path" ] || [ -L "$dest_path" ]; then
                        run rm -rf "$dest_path"
                    fi
                    run ln -s "$source_path" "$dest_path"
                    run chown -h "$cfg_user:$cfg_user" "$dest_path"
                    echo "Linked $sync_dest -> $source_path (mode=link)"
                    # Warn if source is a file (atomic writes will break symlink)
                    if [ -f "$source_path" ]; then
                        echo "  Warning: $sync_source is a file. Atomic writes may break the symlink."
                    fi
                fi
                ;;
        esac
    done
}

# Set up unison monitoring for sync mode entries (bidirectional sync)
# Call this after mounts are ready; uses homesync_sync_sources populated by homeConfigSync_init
# Args: target_home (destination home directory)
#
# Unified approach for both modes:
# 1. Unison syncs original home <-> synced directory with -path args
# 2. bwrap mode only: bindfs mount synced dir for cage user access, symlinks from cage home
#
# Docker mode: synced dir = target_home (persistent home), no bindfs needed
# bwrap mode: synced dir under /run, bindfs provides cage user permissions
homeConfigSync_setup_unison() {
    [ ${#homesync_sync_sources[@]} -eq 0 ] && return

    local target_home="$1"
    local original_home="/home/${original_user}"

    [ "$verbose" = true ] && section_header "Starting homeConfigSync unison for bidirectional sync..."

    # Determine directory structure and whether bindfs is needed
    local needs_bindfs=false
    local homesync_pid_file=""
    local homesync_origin_dest_dir=""
    local cage_dir=""

    if [ "$cfg_isolationMode" = "docker" ]; then
        # Docker: unison syncs original home directly to target home (no bindfs needed)
        :
    else
        # bwrap mode: home config sync architecture
        # All files under /run/claude-cage/<user>/sync/<original_user>/home-config/
        # origin/     = bindfs mounts to original user's files (owned by original_user)
        # cage-mount/ = bindfs of origin/ with ownership mapped to cage_user
        # unison syncs cage-mount/ <-> target_home (cage user's actual home)
        homesync_base_dir="/run/claude-cage/${cfg_user}/sync/${original_user}/home-config"
        homesync_origin_dest_dir="${homesync_base_dir}/origin"
        cage_dir="${homesync_base_dir}/cage-mount"
        homesync_pid_file="${homesync_base_dir}/pids"
        needs_bindfs=true
    fi

    # Build -path args for all entries (as array to avoid eval)
    # For directories: add trailing slash to prevent prefix matching (.claude/ won't match .claude-backup/)
    # For files: add -ignore pattern since trailing slash doesn't work for files
    local -a path_args=()
    local -a exclude_args=()
    for entry_path in "${homesync_sync_sources[@]}"; do
        local src="${original_home}/${entry_path}"
        if [ -d "$src" ]; then
            # Directory: trailing slash prevents prefix matching
            path_args+=("-path" "${entry_path}/")
            [ "$dry_run" = true ] && echo "[dry-run] homeConfigSync sync dir: ${entry_path}/"
        else
            # File (or unknown in dry-run): use -ignore to prevent prefix matching
            path_args+=("-path" "$entry_path")
            exclude_args+=("-ignore" "Path ${entry_path}?*")
            [ "$dry_run" = true ] && echo "[dry-run] homeConfigSync sync file: $entry_path (with auto-exclude: Path ${entry_path}?*)"
        fi
    done

    # Add user-specified exclude args (already prefixed with entry path by Lua parser)
    # Each exclude is like '-ignore "Path .claude/settings.json"'
    for excl in "${homesync_sync_excludes[@]}"; do
        # excl contains flag and value, e.g. '-ignore "Path foo"'
        # The Lua parser outputs '-ignore "Path x"' with double quotes
        # Extract the flag (-ignore) and the quoted value
        local flag="${excl%% *}"
        local value="${excl#* }"
        # Remove surrounding double quotes from value if present
        value="${value#\"}"
        value="${value%\"}"
        exclude_args+=("$flag" "$value")
    done

    # Check if mounts already exist (another instance set them up)
    local mounts_exist=false
    if [ "$needs_bindfs" = true ]; then
        if [ -d "$homesync_base_dir" ] && [ "$dry_run" != true ]; then
            if mountpoint -q "$cage_dir" 2>/dev/null; then
                mounts_exist=true
            fi
        fi
    fi

    # Track file entries separately (need different sync strategy than directories)
    local -a file_entries=()

    # bwrap mode: set up origin/ with mounts (dirs) or copies (files), bindfs to cage/, unison to home
    if [ "$needs_bindfs" = true ]; then
        if [ "$mounts_exist" = true ]; then
            [ "$verbose" = true ] && section_header "homeConfigSync mounts already exist (shared with other instances)"
        else
            [ "$verbose" = true ] && section_header "Setting up homeConfigSync..."
            run mkdir -p "$homesync_origin_dest_dir" "$cage_dir"
            [ "$dry_run" != true ] && chown "$original_user:$original_user" "$homesync_origin_dest_dir"

            # Set up entries in origin/ (preserving home structure)
            # Directories: bindfs mount
            # Files: rsync copy (bindfs doesn't support single files)
            for entry_path in "${homesync_sync_sources[@]}"; do
                local src="${original_home}/${entry_path}"
                local dst="${homesync_origin_dest_dir}/${entry_path}"
                local dst_parent=$(dirname "$dst")

                # Ensure parent directory exists
                if [ "$dst_parent" != "$homesync_origin_dest_dir" ]; then
                    run mkdir -p "$dst_parent"
                    [ "$dry_run" != true ] && chown "$original_user:$original_user" "$dst_parent"
                fi

                if [ "$dry_run" = true ]; then
                    # In dry-run, check if source exists and is a directory
                    # Since we can't know for sure, show both possibilities
                    echo "[dry-run] homeConfigSync setup: $entry_path"
                    echo "[dry-run]   if directory: bindfs \"$src\" \"$dst\""
                    echo "[dry-run]   if file: rsync -a \"$src\" \"$dst\" (then unison for sync)"
                elif [ -d "$src" ]; then
                    # Directory: bindfs mount
                    run mkdir -p "$dst"
                    run chown "$original_user:$original_user" "$dst"
                    run bindfs "$src" "$dst"
                    [ "$verbose" = true ] && echo "  Mounted directory: $entry_path"
                elif [ -f "$src" ]; then
                    # File: rsync copy (bindfs doesn't work for single files)
                    # Will use unison for ongoing bidirectional sync
                    run rsync -a "$src" "$dst"
                    run chown "$original_user:$original_user" "$dst"
                    file_entries+=("$entry_path")
                    [ "$verbose" = true ] && echo "  Copied file: $entry_path"
                else
                    echo "  Warning: Source does not exist: $src"
                fi
            done

            # bindfs mount origin/ -> cage/ with ownership mapping
            # Files appear owned by cage user, created as original user
            run bindfs -u "$cfg_user" -g "$cfg_user" \
                --chown-ignore --chgrp-ignore \
                --create-for-user="$original_user" --create-for-group="$original_user" \
                "$homesync_origin_dest_dir" "$cage_dir"
            [ "$verbose" = true ] && [ "$dry_run" != true ] && echo "Created homeConfigSync bindfs mount: origin/ -> cage/"
        fi
    fi

    # Skip unison setup if mounts already exist (another instance is handling sync)
    if [ "$mounts_exist" = true ]; then
        return
    fi

    # Check if unison is already running (bwrap mode only, shared across instances)
    local unison_running=false
    if [ -n "$homesync_pid_file" ] && [ -f "$homesync_pid_file" ] && [ "$dry_run" != true ]; then
        while IFS='|' read -r entry_name entry_pid; do
            if [ "$entry_name" = "unison" ] && kill -0 "$entry_pid" 2>/dev/null; then
                unison_running=true
                break
            fi
        done < "$homesync_pid_file"
    fi

    # Build unison command
    # bwrap mode: sync cage/ <-> target_home (both owned by cage user via bindfs)
    # Docker mode: sync original_home <-> target_home directly
    local unison_src unison_dst
    if [ "$needs_bindfs" = true ]; then
        unison_src="$cage_dir"
        unison_dst="$target_home"
    else
        unison_src="$original_home"
        unison_dst="$target_home"
    fi

    # Build unison args as array (avoids eval)
    local -a unison_base_args=("$unison_src" "$unison_dst" "-batch" "-confirmbigdel=false")
    unison_base_args+=("${path_args[@]}")
    unison_base_args+=("${exclude_args[@]}")

    # In bwrap mode, add -owner -group so unison preserves ownership from source
    # (source files appear owned by cage user via bindfs mapping)
    if [ "$needs_bindfs" = true ]; then
        unison_base_args+=("-owner" "-group")
    fi

    # Initial sync args: ignore any stale archives and force from source
    local -a unison_initial_args=("${unison_base_args[@]}" "-ignorearchives" "-force" "$unison_src")

    if [ "$unison_running" = true ]; then
        [ "$verbose" = true ] && echo "homeConfigSync unison already running (shared)"
    else
        # Initial one-shot sync (force from source to populate destination)
        run_quiet unison "${unison_initial_args[@]}"
        [ "$verbose" = true ] && [ "$dry_run" != true ] && echo "homeConfigSync initial sync complete"

        # Start watch mode (bidirectional)
        if [ -n "$homesync_pid_file" ]; then
            run_unison_bg --pid-file "$homesync_pid_file" --pid-label "unison" \
                "${unison_base_args[@]}" -repeat watch
        else
            run_unison_bg "${unison_base_args[@]}" -repeat watch
            homesync_unison_pid="$unison_bg_pid"
        fi
        [ "$verbose" = true ] && echo "homeConfigSync unison watch started (PID: $unison_bg_pid)"
    fi

    # For files in bwrap mode: run second unison to sync original_home <-> origin/
    # (Directories use bindfs so changes flow through automatically, but files are copies)
    if [ "$needs_bindfs" = true ] && [ ${#file_entries[@]} -gt 0 ] && [ "$unison_running" != true ]; then
        # Build file unison args as array
        local -a file_unison_args=("$original_home" "$homesync_origin_dest_dir" "-batch" "-confirmbigdel=false" "-owner" "-group")
        for entry in "${file_entries[@]}"; do
            file_unison_args+=("-path" "$entry")
            # Exclude prefix matches (e.g., .claude.json.bak when syncing .claude.json)
            file_unison_args+=("-ignore" "Path ${entry}?*")
        done

        # Start watch mode for files (bidirectional original <-> origin)
        if [ -n "$homesync_pid_file" ]; then
            run_unison_bg --pid-file "$homesync_pid_file" --pid-label "unison-files" \
                "${file_unison_args[@]}" -repeat watch
        else
            run_unison_bg "${file_unison_args[@]}" -repeat watch
        fi
        [ "$verbose" = true ] && echo "homeConfigSync file sync started (PID: $unison_bg_pid)"
    fi

    # Simple summary for non-verbose mode
    if [ "$verbose" != true ] && [ "$dry_run" != true ]; then
        local sync_list="${homesync_sync_sources[*]}"
        echo "homeConfigSync started: ${sync_list// /, }"
    fi
}

# Check if Claude Code is installed in the given home directory
# For bwrap mode: home_dir is persistent_home (owned by original user)
# For Docker mode: checks inside container
check_claude_installed() {
    local username="$1"
    local home_dir="$2"

    # Check if claude binary exists at the expected location
    if [ -x "$home_dir/.local/bin/claude" ]; then
        return 0
    fi

    return 1
}

# Install Claude Code to the given home directory
# For bwrap mode: installs to persistent_home as original user
# For Docker mode: handled separately in Docker branch
install_claude_code() {
    local username="$1"
    local home_dir="$2"

    echo ""
    echo "Now hold on. Claude Code ain't installed yet."
    echo "Can't run this operation without the main man himself."
    echo ""
    read -p "Want me to install Claude Code? [y/N] " -n 1 -r
    echo

    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Alright, we're bailin' out. Install Claude Code yourself and try again."
        echo "Run: curl -fsSL https://claude.ai/install.sh | bash"
        return 1
    fi

    # Check for curl
    if ! command -v curl >/dev/null 2>&1; then
        echo "Now we got a problem. Need curl to download, and it ain't here."
        echo "Install curl and try again, or install Claude Code manually."
        return 1
    fi

    section_header "Alright, runnin' the official installer..."
    echo "This might take a minute. Sit tight."

    # Run the installer with HOME set to the persistent home directory
    # This installs claude to $home_dir/.local/bin/claude
    if HOME="$home_dir" bash -c "curl -fsSL https://claude.ai/install.sh | bash" 2>&1; then
        echo ""
        echo "Done. Claude Code is locked and loaded."
        return 0
    else
        echo ""
        echo "The installer hit a snag. You might need to install manually."
        echo "Try runnin' as the user: curl -fsSL https://claude.ai/install.sh | bash"
        return 1
    fi
}

# Parse homeConfigSync entries (extracts sync mode info for later unison setup)
homeConfigSync_init

# Check if Claude Code is available for the user (skip in dry-run and Docker mode)
# In Docker mode, Claude Code is checked/installed inside the container, not on the host
if [ "$dry_run" = true ]; then
    echo "[dry-run] Would check if Claude Code is installed for user '$cfg_user'"
    # For dry-run, show what would be copied (Docker handles this in its branch)
    if [ "$cfg_isolationMode" != "docker" ]; then
        homeConfigSync_copy "$persistent_home"
    fi
elif [ "$cfg_isolationMode" = "docker" ]; then
    # Docker mode: homeConfigSync handled in Docker setup branch
    :
else
    # bwrap mode: Run homeConfigSync copy to persistent home before installation check
    # This allows .local/bin/claude from homeConfigSync to be used
    homeConfigSync_copy "$persistent_home"

    # Check if Claude is installed - look in persistent_home since that's where it would be
    if ! check_claude_installed "$cfg_user" "$persistent_home"; then
        if ! install_claude_code "$cfg_user" "$persistent_home"; then
            echo "Can't proceed without Claude Code installed. We're done here."
            exit 1
        fi
    fi
fi

# Construct mount point (path inside sandbox where project files appear)
# Both modes use /home/<user>/caged/ as the sandbox destination
# bwrap mode: bwrap constructs this from mapped paths in /run
# Docker mode: Docker mounts directly to this path
if [ "$cfg_isolationMode" = "docker" ]; then
    mount_base="/home/claude/caged"
else
    mount_base="/home/$cfg_user/caged"
fi

if [ "$cfg_directMount" = "workspace" ]; then
    # Workspace mode: mounted name based on source directory
    if [ "$cfg_source" = "." ]; then
        workspace_name=$(basename "$(pwd)")
    else
        workspace_name=$(basename "$cfg_source")
    fi
    mount_point="${mount_base}/${workspace_name}"
elif [ "$cfg_directMount" = "project" ]; then
    # Project mode: mounted name is the project subdirectory
    mount_point="${mount_base}/${start_subdir}"
else
    # Sync mode: use configured mounted name
    mount_point="${mount_base}/${cfg_mounted}"
fi

# For workspace direct mount mode, track instances by mount point instead of project
# This allows multiple subdirectories under the same mount to share it
# Instance tracking directory
# bwrap mode: /run/claude-cage/<user>/instances (requires sudo)
# Docker mode: /run/user/<uid>/claude-cage/instances (no sudo)
if [ "$cfg_isolationMode" = "docker" ]; then
    instance_dir="/run/user/$(id -u)/claude-cage/instances"
else
    instance_dir="/run/claude-cage/${cfg_user}/instances"
fi

# Create instance directory (will be created later during setup, define path here)

if [ "$cfg_directMount" = "workspace" ]; then
    # Create a safe filename from mount point path
    mount_point_hash=$(echo "$mount_point" | md5sum | cut -d' ' -f1)
    mount_instance_file="$instance_dir/mount-$mount_point_hash"
else
    mount_instance_file=""
fi

# Track iptables chain name for cleanup (shared chain for the user)
iptables_chain="CLAUDE_CAGE_${cfg_user}"

# Global instance file (tracks all projects for this user)
# bwrap mode: /run/claude-cage/<user>/instances/global
# Docker mode: /run/user/<uid>/claude-cage/instances/global
global_instance_file="$instance_dir/global"

# Pre-compute Docker container name and mount destination
# (needs to be available for cleanup and launch)
if [ "$cfg_isolationMode" = "docker" ]; then
    # Determine container name using helper
    docker_container_name_value=$(docker_compute_container_name "$cfg_docker_container" "$cfg_docker_isolated" \
        "$cfg_docker_namePrefix" "$cfg_project" "$cfg_source" "$cfg_directMount")

    # Track whether we're using an existing container (affects homeConfigSync behavior)
    if [ -n "$cfg_docker_container" ]; then
        docker_using_existing_container=true
    else
        docker_using_existing_container=false
    fi

    # Determine mount destination / working directory
    if [ -n "$cfg_docker_workdir" ]; then
        # User-specified working directory (for existing containers)
        docker_mount_dest="$cfg_docker_workdir"
    elif [ "$cfg_directMount" = "workspace" ]; then
        workspace_name=$(basename "$cfg_source")
        docker_mount_dest="/home/claude/caged/$workspace_name"
    elif [ "$cfg_directMount" = "project" ]; then
        docker_mount_dest="/home/claude/caged/$cfg_project"
    else
        # Sync mode
        docker_mount_dest="/home/claude/caged/$cfg_project"
    fi
else
    docker_container_name_value=""
    docker_mount_dest=""
    docker_using_existing_container=false
fi

# This instance's ID
instance_id="$$"

cleanup() {
    # Skip cleanup in dry-run mode (nothing was actually set up)
    if [ "$dry_run" = true ]; then
        return
    fi

    section_header "Alright, shuttin' down operations..."

    # Docker mode cleanup
    if [ "$cfg_isolationMode" = "docker" ]; then
        # Kill unison if running (sync mode)
        if [ -f "$pid_file" ]; then
            echo "Stoppin' unison sync..."
            kill_processes_from_file "$pid_file" --remove
        fi

        # Stop container (it stays around for --continue/--resume)
        if [ -n "$docker_container_name_value" ] && docker_container_running "$docker_container_name_value"; then
            echo "Stoppin' Docker container..."
            docker_stop_container "$docker_container_name_value"
        fi

        echo "All done. Stay safe out there."
        return
    fi

    # For workspace direct mount mode, track by mount point instead of project
    # This ensures we only unmount when the last instance using that mount exits
    should_unmount=true

    if [ "$cfg_directMount" = "workspace" ] && [ -n "$mount_instance_file" ] && [ -f "$mount_instance_file" ]; then
        # Remove this instance from mount point tracker
        sed -i "/^$instance_id$/d" "$mount_instance_file"

        # Check if other instances are still using this mount point
        filter_live_instances "$mount_instance_file" remaining_mount

        if [ ${#remaining_mount[@]} -gt 0 ]; then
            echo "Other instances still usin' mount point (${remaining_mount[*]}). Leavin' it mounted."
            # Update instance file to remove dead instances
            printf "%s\n" "${remaining_mount[@]}" > "$mount_instance_file"
            should_unmount=false
        else
            # Last instance using this mount, clean up the instance file
            run rm -f "$mount_instance_file"
        fi
    fi

    # Remove this instance from the local instance file (project tracking)
    if [ -f "$local_instance_file" ]; then
        sed -i "/^$instance_id$/d" "$local_instance_file"

        # Check if there are other instances of THIS project still running
        filter_live_instances "$local_instance_file" remaining_local

        if [ ${#remaining_local[@]} -gt 0 ]; then
            echo "Other instances of this project still runnin' (${remaining_local[*]}). Leavin' processes alone."
            # Update local instance file to remove dead instances
            printf "%s\n" "${remaining_local[@]}" > "$local_instance_file"

            # Still need to remove from global in bwrap mode
            if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
                sed -i "/^$instance_id$/d" "$global_instance_file"
            fi

            echo "This session's done. Stay safe out there."
            return
        else
            # No more instances of this project, remove the local instance file
            run rm -f "$local_instance_file"
        fi
    fi

    # Remove from global instance file (bwrap mode)
    if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
        sed -i "/^$instance_id$/d" "$global_instance_file"

        # Check if there are other projects still running as this user
        filter_live_instances "$global_instance_file" remaining_global

        if [ ${#remaining_global[@]} -gt 0 ]; then
            echo "Other projects still runnin' as user $cfg_user (${remaining_global[*]})."
            echo "Cleanin' up this project only. User and network rules stay in place."
            # Update global instance file to remove dead instances
            printf "%s\n" "${remaining_global[@]}" > "$global_instance_file"

            # Clean up local processes and mount (only if we should unmount)
            if [ -f "$pid_file" ]; then
                echo "Stoppin' processes from $pid_file..."
                kill_processes_from_file "$pid_file" --remove
            fi

            # Note: homeConfigSync mounts are shared across all instances for this user
            # They will be unmounted when the last instance for the user exits

            # Unmount project bindfs mapping (in /run)
            if [ "$should_unmount" = "true" ] && [ -n "$mapped_project" ] && mountpoint -q "$mapped_project" 2>/dev/null; then
                echo "Unmountin' project mapping at $mapped_project..."
                run_quiet umount -l "$mapped_project"
            fi

            echo "This project's done. Other projects still flyin'. Home mapping stays for other instances."
            return
        else
            # No more instances for this user, remove the global instance file
            run rm -f "$global_instance_file"
        fi
    fi

    # Only run full cleanup if this is the last instance
    section_header "Last instance shuttin' down. Cleanin' up everything..."

    # Kill processes from PID file
    if [ -f "$pid_file" ]; then
        echo "Stoppin' processes from $pid_file..."
        kill_processes_from_file "$pid_file" --remove
    fi

    # Unmount project bindfs mapping (in /run)
    if [ "$should_unmount" = "true" ] && [ -n "$mapped_project" ] && mountpoint -q "$mapped_project" 2>/dev/null; then
        echo "Unmountin' project mapping at $mapped_project..."
        run_quiet umount -l "$mapped_project"
    fi

    # Check for other instances before cleaning up shared resources
    has_other_instances=false
    if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
        local _check_instances=()
        filter_live_instances "$global_instance_file" _check_instances
        [ ${#_check_instances[@]} -gt 0 ] && has_other_instances=true
    fi

    # Clean up shared resources only if this is the last instance
    if [ "$has_other_instances" = "false" ]; then
        # Unmount home bindfs mapping (shared across all instances for this user)
        if [ -n "$mapped_home" ] && mountpoint -q "$mapped_home" 2>/dev/null; then
            echo "Unmountin' home mapping at $mapped_home..."
            run_quiet umount -l "$mapped_home"
        fi

        # Clean up the /run directories if empty
        if [ -n "$mapped_home_base" ]; then
            rmdir "$mapped_home_base/projects" 2>/dev/null
            rmdir "$mapped_home_base" 2>/dev/null
        fi

        # Clean up homeConfigSync (bwrap mode only) - shared across all instances for this user
        if [ -n "$homesync_base_dir" ] && [ -d "$homesync_base_dir" ]; then
            echo "Last instance for user $cfg_user, cleanin' up homeConfigSync..."

            # Kill shared unison processes from the homesync PID file
            local homesync_pid_file="${homesync_base_dir}/pids"
            if [ -f "$homesync_pid_file" ]; then
                echo "Stoppin' shared homeConfigSync processes..."
                kill_labeled_processes_from_file "$homesync_pid_file" --remove
            fi

            # Unmount cage-mount/ bindfs mount first (it references origin/)
            if mountpoint -q "${homesync_base_dir}/cage-mount" 2>/dev/null; then
                echo "Unmounting cage-mount/ bindfs mount..."
                run_quiet umount -l "${homesync_base_dir}/cage-mount"
            fi

            # Unmount per-entry bindfs mounts in origin/ (both files and directories)
            local homesync_origin_dest_dir="${homesync_base_dir}/origin"
            if [ -d "$homesync_origin_dest_dir" ]; then
                echo "Unmounting origin/ per-entry mounts..."
                # Safe to grep - we control this specific path
                for mount_path in $(mount | grep " ${homesync_origin_dest_dir}/" | awk '{print $3}'); do
                    if mountpoint -q "$mount_path" 2>/dev/null; then
                        run_quiet umount -l "$mount_path"
                    fi
                done
            fi

            # Clean up directory
            run_quiet rm -rf "$homesync_base_dir"
            # Clean up sync parent directories if empty
            rmdir "/run/claude-cage/${cfg_user}/sync/${original_user}" 2>/dev/null
            rmdir "/run/claude-cage/${cfg_user}/sync" 2>/dev/null
        fi

        # Clean up firewall rules
        if firewall_chain_exists "$iptables_chain"; then
            echo "Last instance for user $cfg_user, cleanin' up network restrictions..."
            delete_firewall_chain "$iptables_chain" "$user_uid"
        fi

        # Clean up the /run directories if empty
        rmdir "/run/claude-cage/${cfg_user}/bwrap" 2>/dev/null
        rmdir "/run/claude-cage/${cfg_user}" 2>/dev/null
    fi

    # bwrap mode always uses a shared user, so we don't delete it

    echo "All done. Stay safe out there."
}
trap cleanup SIGINT SIGTERM EXIT

# Function to resolve domain to IPs
resolve_domain() {
    local domain="$1"
    # Use getent to resolve domain (supports /etc/hosts and DNS)
    getent ahosts "$domain" 2>/dev/null | awk '{print $1}' | sort -u
}

# Function to parse IP/domain:port specification
# Returns: ip, ports (comma-separated)
parse_ip_port() {
    local spec="$1"
    local ip=""
    local ports=""

    if [[ "$spec" =~ ^(.+):([0-9,]+)$ ]]; then
        ip="${BASH_REMATCH[1]}"
        ports="${BASH_REMATCH[2]}"
    else
        ip="$spec"
        ports=""
    fi

    echo "$ip|$ports"
}

# Function to add iptables rule with optional port restriction
# Wrapper for backward compatibility - now uses OS abstraction
add_iptables_rule() {
    add_firewall_rule "$@"
}

# Function to setup network restrictions
setup_network_restrictions() {
    local mode="$1"
    local user_uid
    user_uid=$(get_user_uid "$cfg_user")

    if [ "$mode" = "disabled" ]; then
        echo "Network restrictions: None. You're flyin' without that extra safety net."
        return 0
    fi

    # Check if chain already exists
    local chain_exists=false
    if firewall_chain_exists "$iptables_chain"; then
        chain_exists=true
        section_header "Addin' network restrictions to existing chain (shared in bwrap mode)..."

        # Remove the final catch-all rule (could be ACCEPT or REJECT depending on previous mode)
        # We need to remove it so we can add new rules, then re-add it at the end
        # Try to get the last rule number and delete it (Linux only)
        local last_rule_num=$(get_last_firewall_rule_number "$iptables_chain")
        if [ -n "$last_rule_num" ]; then
            echo "Removin' final rule (line $last_rule_num) to add new restrictions..."
            delete_firewall_rule_by_number "$iptables_chain" "$last_rule_num"
        fi
    else
        section_header "Settin' up network restrictions (mode: $mode)..."
        # Create custom chain for claude-cage rules
        create_firewall_chain "$iptables_chain" "$user_uid" || {
            echo "Hold on. Couldn't create firewall chain. Network restrictions may not work right."
            return 1
        }
    fi

    if [ "$mode" = "allowlist" ]; then
        # Allow user-configured destinations
        add_network_rules_batch "$iptables_chain" "ACCEPT" "domains" "$cfg_allow_domains"
        add_network_rules_batch "$iptables_chain" "ACCEPT" "ips" "$cfg_allow_ips"
        add_network_rules_batch "$iptables_chain" "ACCEPT" "networks" "$cfg_allow_networks"

        # Reject everything else
        add_catchall_firewall_rule "$iptables_chain" "REJECT"

    elif [ "$mode" = "blocklist" ]; then
        # First, allow exceptions (insert at beginning so they're processed first)
        add_network_rules_batch "$iptables_chain" "ACCEPT" "domains" "$cfg_allow_domains" "insert"
        add_network_rules_batch "$iptables_chain" "ACCEPT" "ips" "$cfg_allow_ips" "insert"
        add_network_rules_batch "$iptables_chain" "ACCEPT" "networks" "$cfg_allow_networks" "insert"

        # Then, block configured targets
        add_network_rules_batch "$iptables_chain" "REJECT" "domains" "$cfg_block_domains"
        add_network_rules_batch "$iptables_chain" "REJECT" "ips" "$cfg_block_ips"
        add_network_rules_batch "$iptables_chain" "REJECT" "networks" "$cfg_block_networks"

        # Accept everything else
        add_catchall_firewall_rule "$iptables_chain" "ACCEPT"
    fi

    echo "Network restrictions in place. Locked down tight."
}

# Check for excluded files in sync directory (skip in directMount mode)
# Only check patterns that changed since last run
if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ] && [ -d "$cfg_sync" ]; then
    # excludes-cache is in the same directory as sync (parent of sync/)
    config_cache="$(dirname "$cfg_sync")/excludes-cache"
    current_excludes="${cfg_exclude_path}|${cfg_exclude_name}|${cfg_exclude_regex}|${cfg_exclude_belowPath}"

    # Check if exclude patterns changed since last run
    if [ -f "$config_cache" ]; then
        previous_excludes=$(cat "$config_cache")
        if [ "$current_excludes" != "$previous_excludes" ]; then
            echo "Hold on now. Your exclude patterns changed since last time."
            echo "Let me check if any newly-excluded files are sittin' in the sync directory..."

            # Find newly added patterns by comparing
            excluded_files=()

            # Only check patterns that are new (weren't in previous config)
            # This is a simplified check - we scan all current excludes and warn the user

            # Check exclude.path patterns
            if [ -n "$cfg_exclude_path" ]; then
                IFS='|' read -ra paths <<< "$cfg_exclude_path"
                for pattern in "${paths[@]}"; do
                    if [ -e "$cfg_sync/$pattern" ]; then
                        excluded_files+=("$cfg_sync/$pattern")
                    fi
                done
            fi

            # Check exclude.name patterns
            if [ -n "$cfg_exclude_name" ]; then
                IFS='|' read -ra names <<< "$cfg_exclude_name"
                for pattern in "${names[@]}"; do
                    while IFS= read -r -d '' file; do
                        excluded_files+=("$file")
                    done < <(find "$cfg_sync" -name "$pattern" -print0 2>/dev/null)
                done
            fi

            # Check exclude.regex patterns
            if [ -n "$cfg_exclude_regex" ]; then
                IFS='|' read -ra regexes <<< "$cfg_exclude_regex"
                for pattern in "${regexes[@]}"; do
                    while IFS= read -r -d '' file; do
                        excluded_files+=("$file")
                    done < <(find "$cfg_sync" -regextype posix-extended -regex "$cfg_sync/$pattern" -print0 2>/dev/null)
                done
            fi

            # Check belowPath patterns
            # Check exclude.belowPath patterns
            if [ -n "$cfg_exclude_belowPath" ]; then
                IFS='|' read -ra paths <<< "$cfg_exclude_belowPath"
                for pattern in "${paths[@]}"; do
                    if [ -d "$cfg_sync/$pattern" ]; then
                        excluded_files+=("$cfg_sync/$pattern")
                    fi
                done
            fi

            # If excluded files found, prompt user
            if [ ${#excluded_files[@]} -gt 0 ]; then
                echo ""
                echo "Now hold on. We got files here that match your new exclusion rules:"
                for file in "${excluded_files[@]}"; do
                    echo "  - $file"
                done
                echo ""
                echo "These could be from before you changed the rules."
                echo "They'll be ignored during sync, but they're still takin' up space."
                echo ""
                read -p "Want me to remove these files? [y/N] " -n 1 -r
                echo
                if [[ $REPLY =~ ^[Yy]$ ]]; then
                    for file in "${excluded_files[@]}"; do
                        run rm -rf "$file"
                        echo "Gone: $file"
                    done
                else
                    echo "Alright. They'll stay there but won't sync. Your call."
                fi
            fi
        fi
    fi

    # Save current exclude patterns for next run
    echo "$current_excludes" > "$config_cache"
fi

# Check if there's already a running instance
skip_setup=false
if [ -f "$pid_file" ]; then
    echo "Hold on now. Found a PID file from a previous run."
    echo "Checkin' if those processes are still alive..."

    filter_live_instances "$pid_file" running_pids

    if [ ${#running_pids[@]} -gt 0 ]; then
        echo "Processes still runnin': ${running_pids[*]}"
        echo "Reusing existing unison and bindfs processes."
        echo ""
        skip_setup=true
    else
        echo "Those processes are gone. Cleanin' up the old PID file..."
        run rm -f "$pid_file"
    fi
fi

if [ "$skip_setup" = false ]; then
    # Create instance tracking directory and project directory (for PID/instance files)
    run mkdir -p "$instance_dir"
    run mkdir -p "$(dirname "$local_instance_file")"

    if [ "$cfg_isolationMode" = "docker" ]; then
        # Docker mode setup
        section_header "Docker mode: settin' up container..."
        echo "Container name: $docker_container_name_value"

        # Display persistent home path (for managed containers)
        if [ "$docker_using_existing_container" != true ]; then
            persistent_home=$(docker_persistent_home_path "$cfg_docker_isolated" "$cfg_config_root" "$cfg_project" "$docker_container_name_value" "$original_home")
            echo "Persistent home: $persistent_home"
        fi

        if [ "$docker_using_existing_container" = true ]; then
            # Using user-specified existing container
            echo "Using existing container (user-managed)..."

            # Verify container exists
            if ! docker_container_exists "$docker_container_name_value"; then
                echo "Hold on now. That container '$docker_container_name_value' don't exist."
                echo "Make sure you've created it first. See docs/docker-existing-container.md"
                exit 1
            fi

            # Verify container is running
            if ! docker_container_running "$docker_container_name_value"; then
                echo "Container exists but ain't runnin'. Startin' it..."
                run_quiet docker start "$docker_container_name_value"
                if [ "$dry_run" != true ] && ! docker_container_running "$docker_container_name_value"; then
                    echo "Failed to start container."
                    exit 1
                fi
            fi
            echo "Container ready."

            # Note: Skip homeConfigSync for existing containers - user manages their own config

        else
            # claude-cage manages the container
            # Determine network mode for Docker
            case "$cfg_networkMode" in
                disabled|allowlist)
                    docker_network="none"
                    ;;
                blocklist)
                    docker_network="bridge"
                    ;;
                *)
                    docker_network="none"
                    ;;
            esac

            # Build/ensure image with packages
            docker_image_to_use=$(docker_ensure_image "$cfg_docker_image" "$cfg_docker_packages")
            if [ -z "$docker_image_to_use" ]; then
                echo "Failed to prepare Docker image."
                exit 1
            fi
            echo "Using image: $docker_image_to_use"

            # Determine mount source (destination was pre-computed)
            if [ "$cfg_directMount" = "workspace" ] || [ "$cfg_directMount" = "project" ]; then
                # Direct mount mode: mount source directly
                docker_mount_source="$cfg_source"
            else
                # Sync mode: run unison first, then mount sync directory
                run mkdir -p "$cfg_sync"

                # Build unison command with exclude options
                unison_cmd_base="unison \"$cfg_source\" \"$cfg_sync\" -batch -confirmbigdel=false"
                if [ -n "$cfg_exclude" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_exclude"
                fi
                if [ -n "$cfg_cageLocal" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_cageLocal"
                fi

                unison_cmd_initial="$unison_cmd_base -force \"$cfg_source\" -prefer \"$cfg_source\""
                unison_cmd_ongoing="$unison_cmd_base -auto"

                # Check for watch mode
                if command -v unison-fsmonitor >/dev/null 2>&1; then
                    repeat_mode="watch"
                else
                    repeat_mode="1"
                    echo "No unison-fsmonitor. Using polling mode (check every second)."
                fi

                # Run initial and ongoing sync
                run_quiet bash -c "$unison_cmd_initial"
                run_unison_bg --cmd "$unison_cmd_ongoing -repeat $repeat_mode"

                # Write unison PID to file
                run bash -c "echo '$unison_bg_pid' > '$pid_file'"

                docker_mount_source="$cfg_sync"
            fi

            # Get host UID/GID for file ownership mapping
            host_uid=$(id -u)
            host_gid=$(id -g)

            # Check if container already exists
            if docker_container_exists "$docker_container_name_value"; then
                if docker_container_running "$docker_container_name_value"; then
                    echo "Container already runnin'. Reusin' it."
                else
                    echo "Container exists but stopped. Startin' it..."
                    run_quiet docker start "$docker_container_name_value"
                fi
            else
                # Start new container
                echo "Creatin' new container..."

                # Create persistent home directory if it doesn't exist
                run mkdir -p "$persistent_home"

                # Pre-create the mount point directory so Docker doesn't create it as root
                # docker_mount_dest is /home/claude/caged/... and persistent_home is mounted as /home/claude
                mount_point_relative="${docker_mount_dest#/home/claude/}"
                run mkdir -p "$persistent_home/$mount_point_relative"

                docker_start_container "$docker_container_name_value" "$docker_image_to_use" \
                    "$docker_mount_source" "$docker_mount_dest" \
                    "$docker_network" "$cfg_docker_extraArgs" \
                    "$host_uid" "$host_gid" "$persistent_home"

                if [ "$dry_run" != true ] && ! docker_container_running "$docker_container_name_value"; then
                    echo "Failed to start Docker container."
                    exit 1
                fi
                echo "Container started."
            fi

            # Ensure home directory exists, create claude user, and set ownership
            # Run as root to: create home dir, add claude user to /etc/passwd, chown
            # Adding user entry ensures 'whoami' returns 'claude' not 'node' (which has same UID)
            if [ "$dry_run" = true ]; then
                echo "[dry-run] docker exec -u root ... setup claude user and home directory"
            else
                run docker exec -u root "$docker_container_name_value" bash -c "
                    mkdir -p /home/claude
                    # Add claude user entry if not exists (maps host UID to 'claude' username)
                    if ! grep -q '^claude:' /etc/passwd; then
                        echo 'claude:x:${host_uid}:${host_gid}::/home/claude:/bin/bash' >> /etc/passwd
                    fi
                    # Add claude group if not exists
                    if ! grep -q '^claude:' /etc/group; then
                        echo 'claude:x:${host_gid}:' >> /etc/group
                    fi
                    chown ${host_uid}:${host_gid} /home/claude
                "
                # Create .profile with PATH if it doesn't exist
                run docker exec -e HOME=/home/claude "$docker_container_name_value" bash -c '[ -f ~/.profile ] || cat > ~/.profile << "PROFILE"
export PATH="$HOME/.local/bin:$PATH"
PROFILE'
            fi

            # Copy homeConfigSync files to persistent home BEFORE checking Claude installation
            # This allows .local/bin/claude from homeConfigSync to be used
            # The persistent home is mounted as /home/claude in the container
            homeConfigSync_copy "$persistent_home"

            # Check if Claude Code is installed in container (after homeConfigSync)
            # Check explicit path since the UID may not exist in /etc/passwd (no profile to set PATH)
            if ! docker exec "$docker_container_name_value" test -x /home/claude/.local/bin/claude 2>/dev/null; then
                echo "Claude Code ain't installed in the container. Installin' it now..."
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] Installing curl and Claude Code in container"
                else
                    # Install curl if needed (slim images don't have it)
                    # Run as root since apt-get needs privileges
                    if ! docker exec "$docker_container_name_value" which curl >/dev/null 2>&1; then
                        echo "Installing curl first..."
                        run_quiet docker exec -u root "$docker_container_name_value" bash -c "apt-get update -qq && apt-get install -qq -y curl"
                        if [ $? -ne 0 ]; then
                            echo "Failed to install curl in container."
                            exit 1
                        fi
                    fi
                    # Install Claude Code (as the regular user for correct home dir)
                    # HOME and PATH must be set for the installer to work correctly and not warn
                    echo "Downloading and installing Claude Code..."
                    run docker exec -e HOME=/home/claude -e PATH="/home/claude/.local/bin:\$PATH" "$docker_container_name_value" bash -c "set -o pipefail && curl -fsSL https://claude.ai/install.sh | bash"
                    if [ $? -ne 0 ]; then
                        echo "Failed to install Claude Code in container."
                        exit 1
                    fi
                    # Verify installation by checking explicit path
                    if ! docker exec "$docker_container_name_value" test -x /home/claude/.local/bin/claude 2>/dev/null; then
                        echo "Claude Code installation failed - binary not found at /home/claude/.local/bin/claude"
                        exit 1
                    fi
                    echo "Claude Code installed."
                fi
            else
                echo "Claude Code already installed in container."
            fi

            # Set up unison for sync mode entries (bidirectional sync)
            homeConfigSync_setup_unison "$persistent_home"
        fi

    else
        # bwrap mode setup - new bwrap architecture
        # persistent_home is in ~/.local/share/claude-cage/bwrap/<username>/home/ (owned by original user)
        # mapped_home is in /run/claude-cage/<username>/home (bindfs, appears owned by cage user)
        # bwrap mounts mapped_home as /home/<user> and project as /home/<user>/caged/<project>

        # Setup network restrictions if configured
        setup_network_restrictions "$cfg_networkMode"

        # persistent_home was created earlier (before homeConfigSync_copy)
        # Now create the caged directory structure for the project mount point
        section_header "Settin' up persistent home..."
        mount_point_relative="${mount_point#/home/$cfg_user/}"
        run mkdir -p "$persistent_home/$mount_point_relative"
        # Ensure persistent home is owned by original user
        [ "$dry_run" != true ] && chown -R "$original_user:$original_user" "$persistent_home"

        echo "Persistent home: $persistent_home"

        # Create mapped directories in /run
        run mkdir -p "$mapped_home"
        run mkdir -p "$mapped_project_base"

        # Set up bindfs mapping: persistent_home → mapped_home (appears owned by cage user)
        # Check if already mounted (shared across instances)
        if [ "$dry_run" != true ] && mountpoint -q "$mapped_home" 2>/dev/null; then
            echo "Mapped home already mounted. Reusin' it."
        else
            section_header "Settin' up home bindfs mapping..."
            if ! run bindfs -u "$cfg_user" -g "$cfg_user" \
                --create-for-user="$original_user" --create-for-group="$original_user" \
                "$persistent_home" "$mapped_home"; then
                if [ "$dry_run" != true ]; then
                    echo "bindfs failed for home mapping."
                    exit 1
                fi
            fi
            echo "Home mapping ready."
        fi

        # In sync mode, create sync directory (owned by original user)
        if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ]; then
            run mkdir -p "$cfg_sync"
        fi

        # Determine project source based on mode
        if [ "$cfg_directMount" = "workspace" ]; then
            project_source="$cfg_source"
            project_name=$(basename "$cfg_source")
        elif [ "$cfg_directMount" = "project" ]; then
            project_source="$cfg_source/$start_subdir"
            project_name="$start_subdir"
        else
            # Sync mode
            project_source="$cfg_sync"
            project_name="$cfg_mounted"
        fi

        # Set up mapped project directory
        mapped_project="$mapped_project_base/$project_name"
        run mkdir -p "$mapped_project"

        # Set up project bindfs mapping
        skip_mount=false
        if [ "$dry_run" != true ] && mountpoint -q "$mapped_project" 2>/dev/null; then
            if [ "$cfg_directMount" = "workspace" ]; then
                echo "Project mount already exists. Reusin' it."
                run bash -c "echo '$instance_id' >> '$mount_instance_file'"
                skip_mount=true
            else
                echo "Hold on now. That project's already mounted."
                echo "Either another instance is runnin', or cleanup didn't happen."
                echo "Try: sudo claude-cage --cleanup"
                exit 1
            fi
        fi

        if [ "$skip_mount" = "false" ]; then
            if [ "$cfg_directMount" = "workspace" ]; then
                section_header "Workspace mode: settin' up project mapping..."
            elif [ "$cfg_directMount" = "project" ]; then
                section_header "Project mode: settin' up project mapping..."
            else
                # Sync mode: run unison first
                section_header "Sync mode: startin' file sync..."

                # Build unison command with exclude options
                unison_cmd_base="unison \"$cfg_source\" \"$cfg_sync\" -batch -confirmbigdel=false"
                if [ -n "$cfg_exclude" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_exclude"
                fi
                if [ -n "$cfg_cageLocal" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_cageLocal"
                fi

                unison_cmd_initial="$unison_cmd_base -force \"$cfg_source\" -prefer \"$cfg_source\""
                unison_cmd_ongoing="$unison_cmd_base -auto"

                if command -v unison-fsmonitor >/dev/null 2>&1; then
                    repeat_mode="watch"
                else
                    repeat_mode="1"
                    echo "No unison-fsmonitor. Using polling mode."
                fi

                run_quiet su "$original_user" -c "bash -c '$unison_cmd_initial'"
                run_unison_bg --as "$original_user" --cmd "$unison_cmd_ongoing -repeat $repeat_mode"
                unison_pid="$unison_bg_pid"
            fi

            # bindfs map project source → mapped_project
            if ! run bindfs -u "$cfg_user" -g "$cfg_user" \
                --create-for-user="$original_user" --create-for-group="$original_user" \
                "$project_source" "$mapped_project"; then
                if [ "$dry_run" != true ]; then
                    echo "bindfs failed for project mapping."
                    [ -n "$unison_pid" ] && run_quiet kill "$unison_pid"
                    exit 1
                fi
            fi

            echo "Project mapping ready."

            if [ "$cfg_directMount" = "workspace" ]; then
                run bash -c "echo '$instance_id' >> '$mount_instance_file'"
            fi
        fi

        # Verify mappings (skip in dry-run)
        if [ "$dry_run" != true ]; then
            if ! mountpoint -q "$mapped_home" 2>/dev/null; then
                echo "Home mapping failed."
                exit 1
            fi
            if ! mountpoint -q "$mapped_project" 2>/dev/null; then
                echo "Project mapping failed."
                exit 1
            fi
        fi

        # Write unison PID to file for cleanup (sync mode only)
        if [ -n "$unison_pid" ]; then
            run bash -c "echo '$unison_pid' > '$pid_file'"
        fi
    fi  # End of bwrap mode setup
else
    # Verify mappings still exist (bwrap mode only)
    if [ "$cfg_isolationMode" != "docker" ]; then
        if ! mountpoint -q "$mapped_home" 2>/dev/null || ! mountpoint -q "$mapped_project" 2>/dev/null; then
            echo "Wait a minute. The mappings ain't there anymore."
            echo "Somethin' went wrong. Run: sudo claude-cage --cleanup"
            exit 1
        fi
        echo "Mappings still there. We're good."
    fi
fi

# Register this instance
run bash -c "echo '$instance_id' >> '$local_instance_file'"

# Also register globally
if [ -n "$global_instance_file" ]; then
    run bash -c "echo '$instance_id' >> '$global_instance_file'"
fi

# Set up unison monitoring for homeConfigSync sync mode entries
# bwrap mode: use persistent_home (owned by original user)
# Docker mode: set up in Docker branch after container is ready
if [ "$cfg_isolationMode" != "docker" ]; then
    homeConfigSync_setup_unison "$persistent_home"
fi

if [ "$dry_run" = true ]; then
    echo ""
    # Show what launch command would be used
    if [ "$cfg_isolationMode" = "docker" ]; then
        echo "Would launch Claude in Docker container."
    else
        # Determine workdir for the preview
        if [ "$cfg_directMount" = "workspace" ]; then
            preview_workdir="$mount_point/$start_subdir"
        elif [ "$cfg_directMount" = "project" ]; then
            preview_workdir="$mount_point"
        else
            if [ -n "$start_subdir" ]; then
                preview_workdir="$mount_point/$start_subdir"
            else
                preview_workdir="$mount_point"
            fi
        fi
        if [ "$test_mode" = true ]; then
            run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$preview_workdir"
        else
            run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$preview_workdir" "claude"
        fi
    fi
    echo ""
    echo "=== DRY-RUN COMPLETE ==="
    echo "No changes were made. Above shows what would be executed."
    echo ""
    exit 0
elif [ "$test_mode" = true ]; then
    echo ""
    echo "=== TEST MODE ==="

    if [ "$cfg_isolationMode" = "docker" ]; then
        echo "Alright, everything's ready. Droppin' you into the Docker container."
        echo "Your files are at: $docker_mount_dest"
        if [ -n "$start_subdir" ]; then
            echo "Navigate to your project with: cd $docker_mount_dest/$start_subdir"
        fi
        echo ""
        echo "When you're done pokin' around, type 'exit' and we'll clean up."
        echo "================="
        echo ""
        # Use bash with PATH set up so 'claude' command works
        if [ -n "$cfg_docker_user" ]; then
            docker_exec "$docker_container_name_value" --user "$cfg_docker_user" bash -c "export PATH=\"/home/claude/.local/bin:\$PATH\" && exec bash"
        else
            docker_exec "$docker_container_name_value" bash -c "export PATH=\"/home/claude/.local/bin:\$PATH\" && exec bash"
        fi
        exit_code=$?
    else
        echo "Alright, everything's ready. Droppin' you into the bwrap cage as user '$cfg_user'."
        # Determine working directory for test mode
        if [ "$cfg_directMount" = "workspace" ]; then
            test_workdir="$mount_point"
            echo "Your files are at: $mount_point"
            echo "Navigate to your project with: cd $start_subdir"
            echo "You can access sibling projects from the mount root."
        elif [ "$cfg_directMount" = "project" ]; then
            test_workdir="$mount_point"
            echo "Your files are at: $mount_point"
            echo "Only this project is accessible (no sibling projects)."
        else
            if [ -n "$start_subdir" ]; then
                test_workdir="$mount_point/$start_subdir"
            else
                test_workdir="$mount_point"
            fi
            echo "Your files are at: $mount_point"
        fi
        echo ""
        echo "When you're done pokin' around, type 'exit' and we'll clean up."
        echo "================="
        echo ""
        run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$test_workdir"
        exit_code=$?
    fi
else
    # Build claude command with optional flags
    # Use full path in Docker mode since PATH isn't set up for non-existent users
    if [ "$cfg_isolationMode" = "docker" ]; then
        claude_cmd="/home/claude/.local/bin/claude"
    else
        claude_cmd="claude"
    fi
    if [ "$claude_continue" = true ]; then
        claude_cmd="$claude_cmd --continue"
    elif [ "$claude_resume" = true ]; then
        claude_cmd="$claude_cmd --resume"
    fi

    if [ "$cfg_isolationMode" = "docker" ]; then
        # Docker mode: run claude inside container
        # Determine working directory inside container
        if [ -n "$start_subdir" ]; then
            docker_workdir="$docker_mount_dest/$start_subdir"
        else
            docker_workdir="$docker_mount_dest"
        fi

        if [ -n "$cfg_docker_user" ]; then
            docker_exec "$docker_container_name_value" --user "$cfg_docker_user" bash -c "cd \"$docker_workdir\" && $claude_cmd"
        else
            docker_exec "$docker_container_name_value" bash -c "cd \"$docker_workdir\" && $claude_cmd"
        fi
        exit_code=$?
    else
        # bwrap mode: run Claude via bwrap with mapped home and project
        if [ "$cfg_directMount" = "workspace" ]; then
            # Workspace mode: start in the specified subdirectory within the mount
            run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$mount_point/$start_subdir" "$claude_cmd"
        elif [ "$cfg_directMount" = "project" ]; then
            # Project mode: start at the mount point root (which is the project dir)
            run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$mount_point" "$claude_cmd"
        else
            # Sync mode: start in the subdirectory corresponding to CWD relative to config root
            if [ -n "$start_subdir" ]; then
                run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$mount_point/$start_subdir" "$claude_cmd"
            else
                run_in_bwrap "$cfg_user" "$mapped_home" "$mapped_project" "$mount_point" "$mount_point" "$claude_cmd"
            fi
        fi
        exit_code=$?
    fi
fi

# Explicit exit to ensure cleanup trap fires
exit $exit_code
