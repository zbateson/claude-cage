#!/bin/bash

# Detect operating system
detect_os() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        echo "macos"
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        echo "linux"
    else
        echo "unsupported"
    fi
}

OS_TYPE=$(detect_os)

# Parse --dry-run and --os early to allow OS simulation
dry_run=false
simulated_os=""
next_is_os=false
for arg in "$@"; do
    if [ "$next_is_os" = true ]; then
        simulated_os="$arg"
        next_is_os=false
    elif [ "$arg" = "--dry-run" ]; then
        dry_run=true
    elif [ "$arg" = "--os" ]; then
        next_is_os=true
    fi
done

# Handle --os flag (only valid with --dry-run)
if [ -n "$simulated_os" ]; then
    if [ "$dry_run" != true ]; then
        echo "Error: --os can only be used with --dry-run"
        exit 1
    fi
    if [ "$simulated_os" != "linux" ] && [ "$simulated_os" != "macos" ]; then
        echo "Error: --os must be 'linux' or 'macos'"
        exit 1
    fi
    OS_TYPE="$simulated_os"
    echo "[dry-run] Simulating OS: $OS_TYPE"
fi

if [ "$OS_TYPE" = "unsupported" ]; then
    echo "Unsupported operating system: $OSTYPE"
    echo "claude-cage supports Linux and macOS only."
    exit 1
fi

# ============================================================================
# OS Abstraction Functions - User Management
# ============================================================================

# Check if user exists
user_exists() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -u "$username" >/dev/null 2>&1
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" >/dev/null 2>&1
    fi
}

# Get user UID
get_user_uid() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -u "$username" 2>/dev/null
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" UniqueID 2>/dev/null | awk '{print $2}'
    fi
}

# Get user GID
get_user_gid() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        id -g "$username" 2>/dev/null
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" PrimaryGroupID 2>/dev/null | awk '{print $2}'
    fi
}

# Get user home directory
get_user_home() {
    local username="$1"
    if [ "$OS_TYPE" = "linux" ]; then
        getent passwd "$username" 2>/dev/null | cut -d: -f6
    elif [ "$OS_TYPE" = "macos" ]; then
        dscl . -read /Users/"$username" NFSHomeDirectory 2>/dev/null | awk '{print $2}'
    fi
}

# Create user
create_user() {
    local username="$1"
    local user_home="$2"
    local use_custom_home="$3"  # true/false

    if [ "$OS_TYPE" = "linux" ]; then
        if [ "$use_custom_home" = "true" ]; then
            run adduser --disabled-password --shell /bin/bash --home "$user_home" --comment "" "$username"
        else
            run adduser --disabled-password --shell /bin/bash --comment "" "$username"
        fi
    elif [ "$OS_TYPE" = "macos" ]; then
        # Find next available UID (starting from 501, avoiding system range)
        local max_uid=$(dscl . -list /Users UniqueID | awk '{print $2}' | sort -n | tail -1)
        local new_uid=$((max_uid + 1))
        if [ $new_uid -lt 501 ]; then
            new_uid=501
        fi

        # Find next available GID
        local max_gid=$(dscl . -list /Groups PrimaryGroupID | awk '{print $2}' | sort -n | tail -1)
        local new_gid=$((max_gid + 1))
        if [ $new_gid -lt 501 ]; then
            new_gid=501
        fi

        # Set home directory
        if [ "$use_custom_home" != "true" ]; then
            user_home="/Users/$username"
        fi

        # Create user using dscl
        run dscl . -create /Users/"$username"
        run dscl . -create /Users/"$username" UserShell /bin/bash
        run dscl . -create /Users/"$username" RealName "$username"
        run dscl . -create /Users/"$username" UniqueID "$new_uid"
        run dscl . -create /Users/"$username" PrimaryGroupID "$new_gid"
        run dscl . -create /Users/"$username" NFSHomeDirectory "$user_home"

        # Create home directory if it doesn't exist
        if [ ! -d "$user_home" ] || [ "$dry_run" = true ]; then
            run mkdir -p "$user_home"
            run chown "$username:staff" "$user_home"
            run chmod 755 "$user_home"
        fi

        # Create group (macOS requires this)
        if ! dscl . -read /Groups/"$username" >/dev/null 2>&1 || [ "$dry_run" = true ]; then
            run dscl . -create /Groups/"$username"
            run dscl . -create /Groups/"$username" PrimaryGroupID "$new_gid"
        fi
    fi
}

# Delete user
delete_user() {
    local username="$1"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet userdel -r "$username" || run_quiet userdel "$username"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Delete user
        run_quiet dscl . -delete /Users/"$username"
        # Delete group if it exists
        run_quiet dscl . -delete /Groups/"$username"
        # Remove home directory if it exists
        local user_home=$(dscl . -read /Users/"$username" NFSHomeDirectory 2>/dev/null | awk '{print $2}')
        if [ -n "$user_home" ] && [ -d "$user_home" ]; then
            run rm -rf "$user_home"
        fi
    fi
}

# ============================================================================
# OS Abstraction Functions - Network/Firewall
# ============================================================================

# Check if firewall chain/anchor exists
firewall_chain_exists() {
    local chain_name="$1"

    # In dry-run mode, report what we would check and return false (chain doesn't exist)
    if [ "$dry_run" = true ]; then
        echo "[dry-run] check firewall chain exists: $chain_name"
        return 1
    fi

    if [ "$OS_TYPE" = "linux" ]; then
        iptables -L "$chain_name" >/dev/null 2>&1
    elif [ "$OS_TYPE" = "macos" ]; then
        # Check if anchor exists in pf rules
        pfctl -s Anchors 2>/dev/null | grep -q "^$chain_name$"
    fi
}

# Create firewall chain/anchor
create_firewall_chain() {
    local chain_name="$1"
    local user_uid="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet iptables -N "$chain_name" || return 1
        # Jump to our chain for output from user
        run iptables -I OUTPUT -m owner --uid-owner "$user_uid" -j "$chain_name"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Create anchor in pf
        # macOS pf uses anchors - we'll load rules from a temp file
        local pf_rules_file="/tmp/${chain_name}.pf"

        if [ "$dry_run" = true ]; then
            echo "[dry-run] echo '# Claude-cage rules for UID $user_uid' > $pf_rules_file"
            echo "[dry-run] echo 'anchor \"$chain_name\"' >> $pf_rules_file"
            echo "[dry-run] pfctl -a $chain_name -f $pf_rules_file"
            return 0
        fi

        # Create the anchor definition
        echo "# Claude-cage rules for UID $user_uid" > "$pf_rules_file"
        echo "anchor \"$chain_name\"" >> "$pf_rules_file"

        # Load the anchor (this doesn't activate rules yet, just creates the anchor point)
        pfctl -a "$chain_name" -f "$pf_rules_file" 2>/dev/null || return 1
    fi
}

# Add firewall rule
add_firewall_rule() {
    local chain_name="$1"
    local action="$2"        # ACCEPT or REJECT
    local ip_or_network="$3"
    local ports="$4"          # Optional: comma-separated ports or empty
    local insert_mode="$5"    # Optional: "insert" to add at beginning

    if [ "$OS_TYPE" = "linux" ]; then
        local iptables_action
        if [ "$action" = "ACCEPT" ]; then
            iptables_action="ACCEPT"
        else
            iptables_action="REJECT"
        fi

        local iptables_flag="-A"
        if [ "$insert_mode" = "insert" ]; then
            iptables_flag="-I"
        fi

        if [ -z "$ports" ]; then
            # No port restriction - allow/block all ports
            run iptables $iptables_flag "$chain_name" -d "$ip_or_network" -j "$iptables_action"
        else
            # Port restriction - apply to TCP and UDP
            if [[ "$ports" == *","* ]]; then
                # Multiple ports - use multiport
                run iptables $iptables_flag "$chain_name" -p tcp -d "$ip_or_network" -m multiport --dports "$ports" -j "$iptables_action"
                run iptables $iptables_flag "$chain_name" -p udp -d "$ip_or_network" -m multiport --dports "$ports" -j "$iptables_action"
            else
                # Single port
                run iptables $iptables_flag "$chain_name" -p tcp -d "$ip_or_network" --dport "$ports" -j "$iptables_action"
                run iptables $iptables_flag "$chain_name" -p udp -d "$ip_or_network" --dport "$ports" -j "$iptables_action"
            fi
        fi
    elif [ "$OS_TYPE" = "macos" ]; then
        # macOS pfctl - append rules to the anchor's rule file
        local pf_rules_file="/tmp/${chain_name}.pf"
        local pf_action

        if [ "$action" = "ACCEPT" ]; then
            pf_action="pass"
        else
            pf_action="block"
        fi

        if [ "$dry_run" = true ]; then
            if [ -z "$ports" ]; then
                echo "[dry-run] echo '$pf_action out to $ip_or_network' >> $pf_rules_file"
            else
                IFS=',' read -ra port_array <<< "$ports"
                for port in "${port_array[@]}"; do
                    echo "[dry-run] echo '$pf_action out proto tcp to $ip_or_network port $port' >> $pf_rules_file"
                    echo "[dry-run] echo '$pf_action out proto udp to $ip_or_network port $port' >> $pf_rules_file"
                done
            fi
            echo "[dry-run] pfctl -a $chain_name -f $pf_rules_file"
            return 0
        fi

        if [ -z "$ports" ]; then
            # No port restriction
            echo "$pf_action out to $ip_or_network" >> "$pf_rules_file"
        else
            # With port restriction
            IFS=',' read -ra port_array <<< "$ports"
            for port in "${port_array[@]}"; do
                echo "$pf_action out proto tcp to $ip_or_network port $port" >> "$pf_rules_file"
                echo "$pf_action out proto udp to $ip_or_network port $port" >> "$pf_rules_file"
            done
        fi

        # Reload the anchor with updated rules
        pfctl -a "$chain_name" -f "$pf_rules_file" 2>/dev/null
    fi
}

# Delete firewall chain/anchor
delete_firewall_chain() {
    local chain_name="$1"
    local user_uid="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        # Remove jump rule from OUTPUT chain
        run_quiet iptables -D OUTPUT -m owner --uid-owner "$user_uid" -j "$chain_name"

        # Flush and delete the chain
        run_quiet iptables -F "$chain_name"
        run_quiet iptables -X "$chain_name"
    elif [ "$OS_TYPE" = "macos" ]; then
        # Flush rules from anchor
        run_quiet pfctl -a "$chain_name" -F all

        # Remove the anchor (by clearing its rules, pf will clean it up)
        local pf_rules_file="/tmp/${chain_name}.pf"
        run_quiet rm -f "$pf_rules_file"
    fi
}

# Get last rule number in chain (Linux iptables only)
get_last_firewall_rule_number() {
    local chain_name="$1"

    if [ "$OS_TYPE" = "linux" ]; then
        iptables -L "$chain_name" -n --line-numbers | grep -E "^[0-9]" | tail -1 | awk '{print $1}'
    elif [ "$OS_TYPE" = "macos" ]; then
        # Not applicable to pf
        echo ""
    fi
}

# Delete specific firewall rule by number (Linux iptables only)
delete_firewall_rule_by_number() {
    local chain_name="$1"
    local rule_number="$2"

    if [ "$OS_TYPE" = "linux" ]; then
        run_quiet iptables -D "$chain_name" "$rule_number"
    elif [ "$OS_TYPE" = "macos" ]; then
        # For pf, we rebuild the entire ruleset instead
        # This is handled in add_firewall_rule by rewriting the file
        :
    fi
}

# Add final catch-all rule to chain
add_catchall_firewall_rule() {
    local chain_name="$1"
    local action="$2"  # ACCEPT or REJECT

    if [ "$OS_TYPE" = "linux" ]; then
        run iptables -A "$chain_name" -j "$action"
    elif [ "$OS_TYPE" = "macos" ]; then
        local pf_rules_file="/tmp/${chain_name}.pf"

        if [ "$dry_run" = true ]; then
            if [ "$action" = "ACCEPT" ]; then
                echo "[dry-run] echo 'pass out' >> $pf_rules_file"
            else
                echo "[dry-run] echo 'block out' >> $pf_rules_file"
            fi
            echo "[dry-run] pfctl -a $chain_name -f $pf_rules_file"
            return 0
        fi

        if [ "$action" = "ACCEPT" ]; then
            echo "pass out" >> "$pf_rules_file"
        else
            echo "block out" >> "$pf_rules_file"
        fi
        pfctl -a "$chain_name" -f "$pf_rules_file" 2>/dev/null
    fi
}

# ============================================================================
# Docker Mode Functions
# ============================================================================

# Check if docker command is available
docker_available() {
    command -v docker >/dev/null 2>&1
}

# Check if user has docker access (in docker group or root)
docker_accessible() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker ps (checking access)"
        return 0
    fi
    docker ps >/dev/null 2>&1
}

# Generate container name for isolated mode (per-project)
# Format: prefix-project-hash (hash from source path for uniqueness)
docker_container_name_isolated() {
    local prefix="$1"
    local project="$2"
    local source_path="$3"
    local hash=$(echo "$source_path" | md5sum | cut -c1-8)
    echo "${prefix}-${project}-${hash}"
}

# Generate container name for shared mode (all projects share one container)
# Format: prefix-uid (unique per user on the system)
docker_container_name_shared() {
    local prefix="$1"
    local uid="$2"
    echo "${prefix}-${uid}"
}

# Check if container exists (running or stopped)
docker_container_exists() {
    local container_name="$1"
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker container inspect $container_name"
        return 1  # Assume doesn't exist in dry-run
    fi
    docker container inspect "$container_name" >/dev/null 2>&1
}

# Check if container is running
docker_container_running() {
    local container_name="$1"
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker container inspect -f '{{.State.Running}}' $container_name"
        return 1  # Assume not running in dry-run
    fi
    [ "$(docker container inspect -f '{{.State.Running}}' "$container_name" 2>/dev/null)" = "true" ]
}

# Build or pull docker image with required packages
# Creates a cached image: claude-cage:hash (where hash is from base image + packages)
docker_ensure_image() {
    local base_image="$1"
    local packages="$2"  # pipe-separated list

    # Generate image tag from base + packages
    local image_hash=$(echo "${base_image}|${packages}" | md5sum | cut -c1-12)
    local image_tag="claude-cage:${image_hash}"

    # Check if our custom image already exists
    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker image inspect $image_tag"
    elif docker image inspect "$image_tag" >/dev/null 2>&1; then
        echo "$image_tag"
        return 0
    fi

    # If no packages, just use the base image directly
    if [ -z "$packages" ]; then
        if [ "$dry_run" = true ]; then
            echo "[dry-run] docker pull $base_image (if needed)" >&2
        else
            echo "Pullin' base image $base_image (this might take a minute)..." >&2
            docker pull "$base_image" 2>&1 | grep -E '^[a-f0-9]+:|Status:|Digest:' >&2 || true
        fi
        echo "$base_image"
        return 0
    fi

    # Build custom image with packages
    # Convert pipe-separated packages to space-separated for apt
    local pkg_list=$(echo "$packages" | tr '|' ' ')

    # Create Dockerfile
    local dockerfile_content="FROM ${base_image}
RUN apt-get update && apt-get install -y ${pkg_list} && rm -rf /var/lib/apt/lists/*
"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] Building Docker image $image_tag with packages: $pkg_list" >&2
        echo "[dry-run] docker build -t $image_tag -" >&2
        echo "$image_tag"
        return 0
    fi

    echo "Buildin' Docker image with packages: $pkg_list (this might take a minute)..." >&2
    echo "$dockerfile_content" | docker build -t "$image_tag" - 2>&1 | grep -E '^Step |^Successfully |^ ---> ' >&2 || true
    if [ $? -ne 0 ]; then
        echo "Failed to build Docker image" >&2
        return 1
    fi

    echo "$image_tag"
}

# Start a new container
docker_start_container() {
    local container_name="$1"
    local image="$2"
    local mount_source="$3"
    local mount_dest="$4"
    local network_mode="$5"  # "none" or "bridge"
    local extra_args="$6"
    local host_uid="$7"
    local host_gid="$8"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker run -d --name $container_name --hostname $container_name --network=$network_mode -u ${host_uid}:${host_gid} -e HOME=/home/claude -v \"$mount_source:$mount_dest\" -w \"$mount_dest\" --init $extra_args $image tail -f /dev/null"
        return 0
    fi

    # Build args array to handle paths with spaces properly
    # Set HOME explicitly since the UID may not exist in container's /etc/passwd
    # Use container name as hostname for consistency
    local -a docker_args=(
        "run" "-d"
        "--name" "$container_name"
        "--hostname" "$container_name"
        "--network=$network_mode"
        "-u" "${host_uid}:${host_gid}"
        "-e" "HOME=/home/claude"
        "-v" "$mount_source:$mount_dest"
        "-w" "$mount_dest"
        "--init"
    )

    # Add extra args if provided (these get word-split intentionally)
    if [ -n "$extra_args" ]; then
        docker_args+=($extra_args)
    fi

    docker_args+=("$image" "tail" "-f" "/dev/null")

    local output
    output=$(docker "${docker_args[@]}" 2>&1)
    local exit_code=$?
    if [ $exit_code -ne 0 ]; then
        echo "Docker error: $output" >&2
        return $exit_code
    fi
}

# Execute command in running container
# Usage: docker_exec container_name [--user username] command...
docker_exec() {
    local container_name="$1"
    shift
    local -a user_opt=()
    if [ "$1" = "--user" ]; then
        user_opt=("-u" "$2")
        shift 2
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker exec -it -e HOME=/home/claude ${user_opt[*]} $container_name $*"
        return 0
    fi

    # Set HOME explicitly since the UID may not exist in container's /etc/passwd
    docker exec -it -e HOME=/home/claude "${user_opt[@]}" "$container_name" "$@"
}

# Execute command in running container (non-interactive)
# Usage: docker_exec_quiet container_name [--user username] command...
docker_exec_quiet() {
    local container_name="$1"
    shift
    local -a user_opt=()
    if [ "$1" = "--user" ]; then
        user_opt=("-u" "$2")
        shift 2
    fi

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker exec -e HOME=/home/claude ${user_opt[*]} $container_name $*"
        return 0
    fi

    # Set HOME explicitly since the UID may not exist in container's /etc/passwd
    docker exec -e HOME=/home/claude "${user_opt[@]}" "$container_name" "$@"
}

# Stop a running container
docker_stop_container() {
    local container_name="$1"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker stop $container_name"
        return 0
    fi

    docker stop "$container_name" >/dev/null 2>&1
}

# Remove a container
docker_remove_container() {
    local container_name="$1"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker rm $container_name"
        return 0
    fi

    docker rm "$container_name" >/dev/null 2>&1
}

# Copy file/directory to container
# For directories, removes destination first to avoid nesting (docker cp quirk)
docker_copy_to_container() {
    local container_name="$1"
    local source_path="$2"
    local dest_path="$3"

    if [ "$dry_run" = true ]; then
        echo "[dry-run] docker cp $source_path $container_name:$dest_path"
        return 0
    fi

    # For directories, remove destination first to avoid docker cp nesting issue
    # (docker cp copies INTO existing directories instead of replacing them)
    if [ -d "$source_path" ]; then
        docker exec "$container_name" rm -rf "$dest_path" 2>/dev/null || true
    fi

    docker cp "$source_path" "$container_name:$dest_path"
}

# Important things first
print_banner() {
    local banner=$(cat << 'EOF'



   ██████╗██╗      █████╗ ██╗   ██╗██████╗ ███████╗
  ██╔════╝██║     ██╔══██╗██║   ██║██╔══██╗██╔════╝
  ██║     ██║     ███████║██║   ██║██║  ██║█████╗
  ██║     ██║     ██╔══██║██║   ██║██║  ██║██╔══╝
  ╚██████╗███████╗██║  ██║╚██████╔╝██████╔╝███████╗
   ╚═════╝╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝
                  ___________
                .'           '.
               /  -_-    -_-   \
              |    (_)  (_)     |
              |                 |          ,----.
              |      .---.      |         /||||||\
               \    '.__.'     /         | ||||||.|
                '.          .'           | |||||| |
                  '-._____.-'            | |||||| |
                      |||                |_||||||_|
                     /|||\                 \    /
                    / ||| \                 |  |

        ██████╗ █████╗  ██████╗ ███████╗
        ██╔════╝██╔══██╗██╔════╝ ██╔════╝
        ██║     ███████║██║  ███╗█████╗
        ██║     ██╔══██║██║   ██║██╔══╝
        ╚██████╗██║  ██║╚██████╔╝███████╗
         ╚═════╝╚═╝  ╚═╝ ╚═════╝ ╚══════╝


EOF
)

    # ANSI color codes
    local yellow='\033[33m'
    local reset='\033[0m'

    # Print banner line by line with a slight delay for "slide up" effect
    local line_num=0
    while IFS= read -r line; do
        line_num=$((line_num + 1))
        # Lines 4-9 are CLAUDE (after 3 blank lines), lines 23-28 are CAGE
        if (( line_num >= 4 && line_num <= 9 )) || (( line_num >= 23 && line_num <= 28 )); then
            echo -e "${yellow}${line}${reset}"
        else
            echo "$line"
        fi
        sleep 0.01
    done <<< "$banner"
    sleep 0.3
}

# ============================================================================
# Dry-run Mode Helper Functions
# ============================================================================

# Note: dry_run and OS_TYPE are parsed at the top of the script

# Wrapper function for commands that modify the system
# In dry-run mode, prints the command instead of executing it
run() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] $*"
        return 0
    else
        "$@"
    fi
}

# Wrapper for commands that should be silent in normal mode but shown in dry-run
run_quiet() {
    if [ "$dry_run" = true ]; then
        echo "[dry-run] $*"
        return 0
    else
        "$@" >/dev/null 2>&1
    fi
}

# Check if lua is available early (before sudo check)
if ! command -v lua >/dev/null 2>&1; then
    echo "Now listen carefully. We got a problem here."
    echo "I need lua installed on this bird."
    echo "Can't do nothin' without it."
    exit 1
fi

# Check for file monitoring tools (OS-specific)
if [ "$OS_TYPE" = "linux" ]; then
    # Linux uses inotify-tools
    if ! command -v inotifywait >/dev/null 2>&1; then
        echo "Hold on now. We got a problem here."
        echo "Unison needs inotify-tools for file monitoring."
        echo "Without it, this bird ain't gonna watch your files properly."
        echo "Install it: sudo apt install inotify-tools"
        exit 1
    fi
elif [ "$OS_TYPE" = "macos" ]; then
    # macOS - fswatch is optional for unison, we'll fall back to polling
    # Just check that unison itself is available
    if ! command -v unison >/dev/null 2>&1; then
        echo "Hold on now. We got a problem here."
        echo "I need unison installed on this bird."
        echo "Install it: brew install unison"
        exit 1
    fi
fi

# Get the original user (in case running with sudo)
original_user="${SUDO_USER:-$USER}"

# Define config file paths
system_config="/etc/claude-cage/config"
user_config="/home/${original_user}/.config/claude-cage/config"

# Parse --config flag early (before config search)
explicit_config=""
config_next=false
for arg in "$@"; do
    if [ "$config_next" = true ]; then
        explicit_config="$arg"
        config_next=false
    elif [ "$arg" = "--config" ]; then
        config_next=true
    fi
done

# Function to search for config file up the directory tree
find_config() {
    local dir="$1"
    while [ "$dir" != "/" ]; do
        if [ -f "$dir/claude-cage.config" ]; then
            echo "$dir"
            return 0
        fi
        dir=$(dirname "$dir")
    done
    return 1
}

# Determine config file location
if [ -n "$explicit_config" ]; then
    # Explicit config specified with --config
    if [ ! -f "$explicit_config" ]; then
        echo "Hold on now. That config file '$explicit_config' ain't there."
        echo "Check your path and try again."
        exit 1
    fi
    local_config="$explicit_config"
    config_root=$(dirname "$(realpath "$explicit_config")")
else
    # Search up directory tree for config
    current_dir=$(pwd)
    config_root=$(find_config "$current_dir")
    if [ -z "$config_root" ]; then
        echo "Hold on now. I'm lookin' for a file called 'claude-cage.config' and it ain't here."
        echo "Searched from $(pwd) all the way up to /."
        echo "Can't take off without that config file somewhere above this directory."
        echo "You understand what I'm tellin' you?"
        exit 1
    fi
    local_config="$config_root/claude-cage.config"
fi

# Compute the relative path from config root to current working directory
current_dir=$(pwd)
config_root_real=$(realpath "$config_root")
current_dir_real=$(realpath "$current_dir")

# Calculate relative path from config root to CWD
if [ "$config_root_real" = "$current_dir_real" ]; then
    relative_path=""
else
    # Strip config_root prefix from current_dir to get relative path
    relative_path="${current_dir_real#$config_root_real/}"
fi

# Derive project name and start subdirectory from directory structure
# Project = first component of relative path (or basename of config root if at root)
# Start subdir = remainder of relative path
if [ -n "$relative_path" ]; then
    derived_project=$(echo "$relative_path" | cut -d'/' -f1)
    start_subdir_from_path=$(echo "$relative_path" | cut -d'/' -f2- -s)
else
    derived_project=$(basename "$config_root_real")
    start_subdir_from_path=""
fi

# Parse command line arguments BEFORE running Lua
# Need to extract non-flag argument to pass to Lua
cli_project_arg=""
skip_next=false
for arg in "$@"; do
    if [ "$skip_next" = true ]; then
        skip_next=false
        continue
    fi
    if [ "$arg" = "--config" ] || [ "$arg" = "--os" ]; then
        skip_next=true
        continue
    fi
    if [ "$arg" != "--test" ] && [ "$arg" != "--no-banner" ] && [ "$arg" != "--cleanup" ] && [ "$arg" != "--continue" ] && [ "$arg" != "--resume" ] && [ "$arg" != "--dry-run" ] && [ "$arg" != "--delete-docker-container" ]; then
        cli_project_arg="$arg"
        break
    fi
done

# Extract config values using Lua with multi-level loading
# Pass command-line project argument and derived values to Lua
lua_output=$(lua - "$cli_project_arg" "$derived_project" "$config_root_real" "$relative_path" <<EOF 2>&1
-- Get command-line project argument and derived values
local cli_arg = arg[1] or ""
local derived_project = arg[2] or ""
local config_root = arg[3] or ""
local relative_path = arg[4] or ""

-- Function to merge two tables (later overrides earlier)
local function merge_config(base, override)
    local result = {}

    -- Copy base config
    for k, v in pairs(base) do
        if type(v) == "table" then
            result[k] = {}
            for k2, v2 in pairs(v) do
                result[k][k2] = v2
            end
        else
            result[k] = v
        end
    end

    -- Override with new values
    for k, v in pairs(override) do
        if k == "exclude" and type(v) == "table" then
            -- Merge exclude sub-fields (path, name, belowPath, regex)
            result.exclude = result.exclude or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.exclude[subkey] = result.exclude[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.exclude[subkey], item)
                    end
                end
            end
        elseif k == "block" and type(v) == "table" then
            -- Merge block sub-fields (domains, ips, networks)
            result.block = result.block or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.block[subkey] = result.block[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.block[subkey], item)
                    end
                end
            end
        elseif k == "allow" and type(v) == "table" then
            -- Merge allow sub-fields (domains, ips, networks)
            result.allow = result.allow or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.allow[subkey] = result.allow[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.allow[subkey], item)
                    end
                end
            end
        elseif k == "cageLocal" and type(v) == "table" then
            -- Merge cageLocal sub-fields (path, name, belowPath, regex)
            -- cageLocal prevents new files created in cage from appearing in source
            result.cageLocal = result.cageLocal or {}
            for subkey, subval in pairs(v) do
                if type(subval) == "table" then
                    result.cageLocal[subkey] = result.cageLocal[subkey] or {}
                    for _, item in ipairs(subval) do
                        table.insert(result.cageLocal[subkey], item)
                    end
                end
            end
        else
            -- Override value
            result[k] = v
        end
    end

    return result
end

-- Define a handler for claude_cage function
local configs = {}
function claude_cage(tbl)
    table.insert(configs, tbl)
end

-- Track items by source for display
local sources = {
    { name = "system", path = "$system_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "user", path = "$user_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "local", path = "$local_config", exclude = {}, cageLocal = {}, block = {}, allow = {} },
    { name = "project", path = "", exclude = {}, cageLocal = {}, block = {}, allow = {} }  -- path set later
}

-- Helper to extract items from a config into a source tracker
local function track_items(source_entry, cfg)
    if cfg.exclude then
        for subkey, items in pairs(cfg.exclude) do
            source_entry.exclude[subkey] = source_entry.exclude[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.exclude[subkey], item)
                end
            end
        end
    end
    if cfg.cageLocal then
        for subkey, items in pairs(cfg.cageLocal) do
            source_entry.cageLocal[subkey] = source_entry.cageLocal[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.cageLocal[subkey], item)
                end
            end
        end
    end
    if cfg.block then
        for subkey, items in pairs(cfg.block) do
            source_entry.block[subkey] = source_entry.block[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.block[subkey], item)
                end
            end
        end
    end
    if cfg.allow then
        for subkey, items in pairs(cfg.allow) do
            source_entry.allow[subkey] = source_entry.allow[subkey] or {}
            if type(items) == "table" then
                for _, item in ipairs(items) do
                    table.insert(source_entry.allow[subkey], item)
                end
            end
        end
    end
end

-- Load configs in priority order (system -> user -> local)
local config_files = {
    { idx = 1, path = "$system_config" },
    { idx = 2, path = "$user_config" },
    { idx = 3, path = "$local_config" }
}

for _, cf in ipairs(config_files) do
    local f = io.open(cf.path, "r")
    if f then
        f:close()
        local before_count = #configs
        local success, err = pcall(function()
            dofile(cf.path)
        end)
        if not success then
            io.stderr:write("Error loading config file: " .. cf.path .. "\n")
            io.stderr:write(tostring(err) .. "\n")
            os.exit(1)
        end
        -- Track items from newly loaded configs
        for i = before_count + 1, #configs do
            track_items(sources[cf.idx], configs[i])
        end
    end
end

-- Merge all configs loaded so far
local config = {}
for _, cfg in ipairs(configs) do
    config = merge_config(config, cfg)
end

-- Determine project name from CLI arg, config, or derived from directory structure
local project = cli_arg ~= "" and cli_arg or config.project or derived_project or ""

-- If project name is set, try to load project-specific config
if project ~= "" then
    local project_config = config_root .. "/" .. project .. ".claude-cage.config"
    sources[4].path = project_config
    local f = io.open(project_config, "r")
    if f then
        f:close()
        -- Reset configs table to reload just the project config
        local project_configs = {}
        local old_claude_cage = claude_cage
        function claude_cage(tbl)
            table.insert(project_configs, tbl)
        end

        local success, err = pcall(function()
            dofile(project_config)
        end)

        -- Restore original function
        claude_cage = old_claude_cage

        if not success then
            io.stderr:write("Error loading project config file: " .. project_config .. "\n")
            io.stderr:write(tostring(err) .. "\n")
            os.exit(1)
        end

        -- Track and merge project-specific configs
        for _, cfg in ipairs(project_configs) do
            track_items(sources[4], cfg)
            config = merge_config(config, cfg)
        end
    end
end

-- Update project from CLI arg if provided (CLI arg takes precedence)
if cli_arg ~= "" then
    config.project = cli_arg
    project = cli_arg
end

-- Set defaults from config, using derived values as fallbacks
-- Priority: CLI arg > config > derived from directory structure
if project == "" then
    project = config.project or derived_project
end
local user = config.user or "claude"
local isolationMode = config.isolationMode or "user"  -- Options: "user" or "docker"
local source = config.source or ""
local sync = config.sync or ""
local mountBase = config.mountBase  -- nil if not set, "" if explicitly empty
local mountBaseExplicitlySet = config.mountBase ~= nil
local mounted = config.mounted or ""
local directMount = config.directMount or false
local showBanner = config.showBanner
if showBanner == nil then showBanner = true end

-- Docker configuration defaults
local docker = config.docker or {}
local dockerImage = docker.image or "node:lts-slim"
local dockerPackages = docker.packages or {}
local dockerNamePrefix = docker.namePrefix or "claude-cage"
local dockerExtraArgs = docker.extraArgs or ""
local dockerIsolated = docker.isolated or false  -- false: shared container, true: per-project
local dockerContainer = docker.container or ""   -- Use existing container (user-managed)
local dockerUser = docker.user or ""             -- User to run as in existing container
local dockerWorkdir = docker.workdir or ""       -- Working directory in existing container

-- Validate isolationMode
if isolationMode ~= "user" and isolationMode ~= "docker" then
    error("Invalid isolationMode: must be 'user' or 'docker'")
end

-- Source defaults to the project directory (config_root/project)
-- This ensures we sync the specific project, not the entire parent workspace
-- In direct mount modes, source is the config root (mount the whole workspace or just project)
if source == "" then
    if directMount == "workspace" then
        -- Workspace mode: mount the entire config root
        source = config_root
    elseif directMount == "project" then
        -- Project mode: mount just the project subdirectory
        if relative_path ~= "" then
            source = config_root .. "/" .. project
        else
            source = config_root
        end
    else
        -- Sync mode: sync the project directory (first component of relative path)
        if relative_path ~= "" then
            source = config_root .. "/" .. project
        else
            -- At config root - this will be caught by validation later
            source = config_root
        end
    end
end

-- If sync is empty, determine from project
-- Structure: config_root/.caged/project-name/sync
-- The .caged directory is always at the config root for consistency
if sync == "" then
    if project ~= "" then
        sync = config_root .. "/.caged/" .. project .. "/sync"
    else
        sync = config_root .. "/.caged/default/sync"
    end
end

-- Set mountBase default (only if not explicitly set in config)
if not mountBaseExplicitlySet then
    mountBase = "caged"
elseif mountBase == nil then
    mountBase = ""
end

-- Set mounted default to project name
if mounted == "" then
    if project ~= "" then
        mounted = project
    else
        mounted = "project"
    end
end

-- Network configuration defaults
local networkMode = config.networkMode or "disabled"

-- Build exclude arguments for unison
local exclude_args = ""
local exclude = config.exclude or {}

-- In sync mode, always exclude .caged to prevent recursion issues
if not directMount or directMount == false then
    exclude_args = exclude_args .. '-ignore "Name .caged" '
end

-- exclude.name: Ignore files/folders by name anywhere in the tree
if exclude.name then
    for _, item in ipairs(exclude.name) do
        exclude_args = exclude_args .. '-ignore "Name ' .. item .. '" '
    end
end

-- exclude.path: Ignore exact paths relative to replica root
if exclude.path then
    for _, item in ipairs(exclude.path) do
        exclude_args = exclude_args .. '-ignore "Path ' .. item .. '" '
    end
end

-- exclude.regex: Ignore paths matching regex patterns
if exclude.regex then
    for _, item in ipairs(exclude.regex) do
        exclude_args = exclude_args .. '-ignore "Regex ' .. item .. '" '
    end
end

-- exclude.belowPath: Ignore everything below a certain path
if exclude.belowPath then
    for _, item in ipairs(exclude.belowPath) do
        exclude_args = exclude_args .. '-ignore "BelowPath ' .. item .. '" '
    end
end

-- Build cageLocal arguments for unison (prevent new files in cage from being created on source)
-- Uses -nocreationpartial - only blocks creation, existing files still sync normally
-- Syntax: -nocreationpartial "Name pattern -> /path/to/source"
local cageLocal_args = ""
local cageLocal = config.cageLocal or {}

-- cageLocal.name: Block creation of new files by name on source (existing files sync normally)
if cageLocal.name then
    for _, item in ipairs(cageLocal.name) do
        cageLocal_args = cageLocal_args .. '-nocreationpartial "Name ' .. item .. ' -> ' .. source .. '" '
    end
end

-- cageLocal.path: Block creation of new files at exact paths on source
if cageLocal.path then
    for _, item in ipairs(cageLocal.path) do
        cageLocal_args = cageLocal_args .. '-nocreationpartial "Path ' .. item .. ' -> ' .. source .. '" '
    end
end

-- cageLocal.regex: Block creation of new files matching regex on source
if cageLocal.regex then
    for _, item in ipairs(cageLocal.regex) do
        cageLocal_args = cageLocal_args .. '-nocreationpartial "Regex ' .. item .. ' -> ' .. source .. '" '
    end
end

-- cageLocal.belowPath: Block creation of new files below a path on source
if cageLocal.belowPath then
    for _, item in ipairs(cageLocal.belowPath) do
        cageLocal_args = cageLocal_args .. '-nocreationpartial "BelowPath ' .. item .. ' -> ' .. source .. '" '
    end
end

-- Output basic config (use | delimiter to preserve empty fields)
print(user .. "|" .. source .. "|" .. sync .. "|" .. mountBase .. "|" .. mounted .. "|" .. exclude_args .. "|" .. tostring(showBanner) .. "|" .. cageLocal_args)

-- Output exclude patterns for validation (pipe-separated)
local function array_to_string(arr)
    if not arr or #arr == 0 then return "EMPTY" end
    local result = {}
    for _, item in ipairs(arr) do
        table.insert(result, item)
    end
    return table.concat(result, "|")
end

print(array_to_string(exclude.path))
print(array_to_string(exclude.name))
print(array_to_string(exclude.regex))
print(array_to_string(exclude.belowPath))

-- Output cageLocal patterns for validation (pipe-separated)
print(array_to_string(cageLocal.path))
print(array_to_string(cageLocal.name))
print(array_to_string(cageLocal.regex))
print(array_to_string(cageLocal.belowPath))

-- Output network configuration
local allow = config.allow or {}
local block = config.block or {}
print(networkMode)
print(array_to_string(allow.domains))
print(array_to_string(allow.ips))
print(array_to_string(allow.networks))
print(array_to_string(block.domains))
print(array_to_string(block.ips))
print(array_to_string(block.networks))

-- Output project for validation
print(project)

-- Output directMount setting (false, "workspace", or "project")
print(tostring(directMount))

-- Output relative_path for start subdirectory (bash will use this)
print(relative_path)

-- Output config_root for source directory
print(config_root)

-- Output source-tracked items for display (format: SOURCE|TYPE|items,comma,separated)
-- This allows bash to display items grouped by source
local function format_source_items(src, category)
    local lines = {}
    local items = src[category] or {}
    for subkey, arr in pairs(items) do
        if #arr > 0 then
            table.insert(lines, src.name .. "|" .. subkey .. "|" .. table.concat(arr, ", "))
        end
    end
    return lines
end

-- Collect all display lines
local display_lines = {}
for _, src in ipairs(sources) do
    -- Check if this source has any items
    local has_items = false
    for _, cat in ipairs({"exclude", "cageLocal", "block", "allow"}) do
        for _, arr in pairs(src[cat] or {}) do
            if #arr > 0 then has_items = true break end
        end
        if has_items then break end
    end

    if has_items then
        for _, line in ipairs(format_source_items(src, "exclude")) do
            table.insert(display_lines, "EXCLUDE|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "cageLocal")) do
            table.insert(display_lines, "CAGELOCAL|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "block")) do
            table.insert(display_lines, "BLOCK|" .. line)
        end
        for _, line in ipairs(format_source_items(src, "allow")) do
            table.insert(display_lines, "ALLOW|" .. line)
        end
    end
end

-- Output homeConfigSync entries
-- Format: source|dest (dest may be same as source)
local homeConfigSync = config.homeConfigSync or {}
print(#homeConfigSync)
for _, entry in ipairs(homeConfigSync) do
    if type(entry) == "string" then
        -- Simple string: source = dest
        print(entry .. "|" .. entry)
    elseif type(entry) == "table" and #entry == 2 then
        -- Array with source, dest
        print(entry[1] .. "|" .. entry[2])
    end
end

-- Output display line count, then lines
print(#display_lines)
for _, line in ipairs(display_lines) do
    print(line)
end

-- Output isolation mode and docker configuration
print(isolationMode)
print(dockerImage)
print(array_to_string(dockerPackages))
print(dockerNamePrefix)
print(dockerExtraArgs)
print(tostring(dockerIsolated))
print(dockerContainer)
print(dockerUser)
print(dockerWorkdir)
EOF
)
lua_exit_code=$?

# Check if lua command failed BEFORE parsing output
if [ $lua_exit_code -ne 0 ]; then
    echo ""
    echo "============================================"
    echo "Somethin' went wrong with the config files"
    echo "============================================"
    echo ""
    echo "$lua_output"
    echo ""
    echo "Now I want you to fix that and we'll try this again."
    exit 1
fi

# Parse the lua output (only if lua succeeded)
{
    IFS='|' read -r cfg_user cfg_source cfg_sync cfg_mountBase cfg_mounted cfg_exclude cfg_showBanner cfg_cageLocal
    read -r cfg_exclude_path
    read -r cfg_exclude_name
    read -r cfg_exclude_regex
    read -r cfg_exclude_belowPath
    read -r cfg_cageLocal_path
    read -r cfg_cageLocal_name
    read -r cfg_cageLocal_regex
    read -r cfg_cageLocal_belowPath
    read -r cfg_networkMode
    read -r cfg_allow_domains
    read -r cfg_allow_ips
    read -r cfg_allow_networks
    read -r cfg_block_domains
    read -r cfg_block_ips
    read -r cfg_block_networks
    read -r cfg_project
    read -r cfg_directMount
    read -r cfg_relative_path
    read -r cfg_config_root
    read -r cfg_homeConfigSync_count
    # Read homeConfigSync entries into array
    cfg_homeConfigSync=()
    for ((i=0; i<cfg_homeConfigSync_count; i++)); do
        read -r line
        cfg_homeConfigSync+=("$line")
    done
    read -r cfg_display_line_count
    # Read display lines into array
    cfg_display_lines=()
    for ((i=0; i<cfg_display_line_count; i++)); do
        read -r line
        cfg_display_lines+=("$line")
    done
    # Read isolation mode and docker configuration
    read -r cfg_isolationMode
    read -r cfg_docker_image
    read -r cfg_docker_packages
    read -r cfg_docker_namePrefix
    read -r cfg_docker_extraArgs
    read -r cfg_docker_isolated
    read -r cfg_docker_container
    read -r cfg_docker_user
    read -r cfg_docker_workdir
} <<< "$lua_output"

# Replace EMPTY placeholder with empty string for array values
[ "$cfg_exclude_path" = "EMPTY" ] && cfg_exclude_path=""
[ "$cfg_exclude_name" = "EMPTY" ] && cfg_exclude_name=""
[ "$cfg_exclude_regex" = "EMPTY" ] && cfg_exclude_regex=""
[ "$cfg_exclude_belowPath" = "EMPTY" ] && cfg_exclude_belowPath=""
[ "$cfg_cageLocal_path" = "EMPTY" ] && cfg_cageLocal_path=""
[ "$cfg_cageLocal_name" = "EMPTY" ] && cfg_cageLocal_name=""
[ "$cfg_cageLocal_regex" = "EMPTY" ] && cfg_cageLocal_regex=""
[ "$cfg_cageLocal_belowPath" = "EMPTY" ] && cfg_cageLocal_belowPath=""
[ "$cfg_allow_domains" = "EMPTY" ] && cfg_allow_domains=""
[ "$cfg_allow_ips" = "EMPTY" ] && cfg_allow_ips=""
[ "$cfg_allow_networks" = "EMPTY" ] && cfg_allow_networks=""
[ "$cfg_block_domains" = "EMPTY" ] && cfg_block_domains=""
[ "$cfg_block_ips" = "EMPTY" ] && cfg_block_ips=""
[ "$cfg_block_networks" = "EMPTY" ] && cfg_block_networks=""
[ "$cfg_docker_packages" = "EMPTY" ] && cfg_docker_packages=""

# Parse command line arguments
test_mode=false
cleanup_mode=false
delete_docker_container=false
claude_continue=false
claude_resume=false
source_arg=""
start_subdir=""
project_arg=""
skip_next_arg=false

for arg in "$@"; do
    if [ "$skip_next_arg" = true ]; then
        skip_next_arg=false
        continue
    fi
    if [ "$arg" = "--test" ]; then
        test_mode=true
    elif [ "$arg" = "--no-banner" ]; then
        cfg_showBanner="false"
    elif [ "$arg" = "--cleanup" ]; then
        cleanup_mode=true
    elif [ "$arg" = "--delete-docker-container" ]; then
        delete_docker_container=true
    elif [ "$arg" = "--continue" ]; then
        claude_continue=true
    elif [ "$arg" = "--resume" ]; then
        claude_resume=true
    elif [ "$arg" = "--config" ] || [ "$arg" = "--os" ]; then
        skip_next_arg=true
    elif [ "$arg" = "--dry-run" ]; then
        # Already parsed early, just skip here
        :
    else
        # Non-flag argument is either project name or subdirectory (depending on mode)
        source_arg="$arg"
    fi
done

# Handle start_subdir based on mode and relative path
# For sync mode: start_subdir is the path WITHIN the project (after the first component)
# For direct mount workspace: start_subdir is the full relative path
# For direct mount project: start_subdir is the path within the project
if [ "$cfg_directMount" = "workspace" ]; then
    # Workspace mode: full relative path from config root
    start_subdir="$cfg_relative_path"
elif [ "$cfg_directMount" = "project" ]; then
    # Project mode: path within project (after first component)
    if [ -n "$cfg_relative_path" ]; then
        start_subdir=$(echo "$cfg_relative_path" | cut -d'/' -f2- -s)
    fi
else
    # Sync mode: path within project (after first component)
    if [ -n "$cfg_relative_path" ]; then
        start_subdir=$(echo "$cfg_relative_path" | cut -d'/' -f2- -s)
    fi
fi

# Command-line argument can override start_subdir in direct mount modes
if [ -n "$source_arg" ] && [ "$cfg_directMount" = "workspace" -o "$cfg_directMount" = "project" ]; then
    start_subdir="$source_arg"
fi

# Source is now derived from config root by Lua
# No need to set default here

# Define cage_home_base early (needed by cleanup mode)
cage_home_base="/home/.claude-cage"

# Project is now derived from directory structure if not in config
# It will only be empty if both config and directory structure failed
if [ -z "$cfg_project" ]; then
    echo "Listen to me very carefully now."
    echo "Couldn't figure out a project name."
    echo "This shouldn't happen since it's derived from the directory structure."
    echo "Check your config file location and try again."
    exit 1
fi

# Docker mode dependency checks (must happen after config is parsed)
if [ "$cfg_isolationMode" = "docker" ]; then
    if ! docker_available; then
        echo "Hold on now. You're tryin' to use Docker mode but docker ain't installed."
        echo "Either install Docker or switch to user mode (isolationMode = \"user\")."
        exit 1
    fi
    if ! docker_accessible; then
        echo "Hold on now. Can't talk to Docker."
        echo "Either the daemon ain't runnin', or you don't have permission."
        echo ""
        echo "Try one of these:"
        echo "  - Start Docker: sudo systemctl start docker"
        echo "  - Add yourself to docker group: sudo usermod -aG docker $USER"
        echo "    (then log out and back in)"
        exit 1
    fi
fi

# In sync mode, validate we're not at the config root
# Running from config root would cause the .caged directory to be synced into itself
if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ]; then
    if [ -z "$cfg_relative_path" ]; then
        echo "Hold on now. You're tryin' to run sync mode from the config root directory."
        echo "That ain't gonna work. The .caged directory would end up syncing into itself."
        echo ""
        echo "You got a few options:"
        echo "  1. cd into a subdirectory and run from there"
        echo "  2. Use direct mount mode: directMount = \"workspace\" or \"project\""
        echo "  3. Move your config file up one level"
        exit 1
    fi
fi

# Define PID and instance file paths early (needed for cleanup mode)
# These are at the config root to be consistent regardless of where you run from
pid_file="$cfg_config_root/.caged/$cfg_project/claude-cage.pid"
local_instance_file="$cfg_config_root/.caged/$cfg_project/claude-cage.instances"

# For direct mount mode, we track instances by mount point (not project)
# This allows multiple projects under the same mount to share it
# The mount point instance file is stored in the user's home directory
# (will be set after user_home is determined)

# Source is derived from config_root, which should always exist
if [ -z "$cfg_source" ]; then
    echo "Hold on. Where's the source directory?"
    echo "This shouldn't happen since it's derived from the config location."
    echo "Check your setup and try again."
    exit 1
fi

if [ ! -d "$cfg_source" ]; then
    echo "Now we got a problem. That source directory '$cfg_source' don't exist."
    echo "Can't work with somethin' that ain't there."
    exit 1
fi

# In directMount mode, require a starting subdirectory/project if not at a subdirectory already
if [ "$cfg_directMount" = "workspace" ] || [ "$cfg_directMount" = "project" ]; then
    if [ -z "$start_subdir" ]; then
        echo "Hold on now. In direct mount mode, you gotta tell me which project to work in."
        echo "Either cd into a project subdirectory, or specify it on the command line."
        echo "Run it like: sudo claude-cage <subdirectory>"
        echo "For example: sudo claude-cage my-project"
        exit 1
    fi

    # Validate the subdirectory exists
    if [ ! -d "$cfg_source/$start_subdir" ]; then
        echo "Now we got a problem. That subdirectory '$cfg_source/$start_subdir' don't exist."
        echo "Can't start Claude in somethin' that ain't there."
        exit 1
    fi
fi

# Handle --delete-docker-container
if [ "$delete_docker_container" = true ]; then
    if [ "$cfg_isolationMode" != "docker" ]; then
        echo "Hold on. --delete-docker-container only works in Docker mode."
        echo "Your config has isolationMode = \"$cfg_isolationMode\""
        exit 1
    fi

    # Compute container name
    if [ -n "$cfg_docker_container" ]; then
        # User-specified existing container
        container_name="$cfg_docker_container"
    elif [ "$cfg_docker_isolated" = "true" ]; then
        # Isolated mode: per-project container
        if [ "$cfg_directMount" = "workspace" ]; then
            workspace_name=$(basename "$cfg_source")
            container_name=$(docker_container_name_isolated "$cfg_docker_namePrefix" "$workspace_name" "$cfg_source")
        else
            container_name=$(docker_container_name_isolated "$cfg_docker_namePrefix" "$cfg_project" "$cfg_source")
        fi
    else
        # Shared mode (default): single container for all projects
        container_name=$(docker_container_name_shared "$cfg_docker_namePrefix" "$(id -u)")
    fi

    echo "Container: $container_name"

    if ! docker_container_exists "$container_name"; then
        echo "Container don't exist. Nothin' to delete."
        exit 0
    fi

    if docker_container_running "$container_name"; then
        echo "Stoppin' container..."
        docker_stop_container "$container_name"
    fi

    echo "Removin' container..."
    docker_remove_container "$container_name"
    echo "Done. Container's gone."
    exit 0
fi

# Handle cleanup mode
if [ "$cleanup_mode" = true ]; then
    # Check for root (unless dry-run or docker mode)
    if [ "$cfg_isolationMode" != "docker" ] && [ "$EUID" -ne 0 ] && [ "$dry_run" != true ]; then
        echo "Gonna need you to run this as root. Use sudo, Bay-BEE!"
        exit 1
    fi

    echo "=== CLEANUP MODE ==="
    echo "Alright, let's clean up this operation."
    echo ""

    # Get user home directory
    if user_exists "$cfg_user"; then
        # Get home directory using OS abstraction function
        user_home=$(get_user_home "$cfg_user")
    else
        # User doesn't exist, construct expected home path
        user_home="/home/$cfg_user"
    fi

    # Construct mount point using same logic as main script
    if [ -n "$cfg_mountBase" ]; then
        mount_point="$user_home/${cfg_mountBase}/${cfg_mounted}"
    else
        mount_point="$user_home/${cfg_mounted}"
    fi

    # Find and unmount any bindfs mounts for this user
    if mountpoint -q "$mount_point" 2>/dev/null || [ "$dry_run" = true ]; then
        echo "Found mounted directory at $mount_point, unmountin' it now..."
        run_quiet umount -l "$mount_point"
        if [ $? -eq 0 ]; then
            echo "  Unmounted. All clear."
        else
            echo "  Had some trouble unmountin'. May need to clean that up yourself."
        fi
    else
        echo "No mounted directory at $mount_point. Already clean."
    fi

    # Clean up iptables rules for this user
    if user_exists "$cfg_user" || [ "$dry_run" = true ]; then
        user_uid=$(get_user_uid "$cfg_user")
        # Look for any chains with our pattern
        if [ "$OS_TYPE" = "linux" ]; then
            if [ "$dry_run" = true ]; then
                echo "[dry-run] iptables -L OUTPUT -n | grep CLAUDE_CAGE_"
                echo "[dry-run] (would clean up any matching firewall chains)"
            else
                # First, get all CLAUDE_CAGE chains and their associated UIDs from OUTPUT rules
                iptables -L OUTPUT -n | grep "CLAUDE_CAGE_" | while read -r line; do
                    chain=$(echo "$line" | awk '{print $1}')
                    uid=$(echo "$line" | grep -o "owner UID match [0-9]*" | awk '{print $4}')

                    echo "Found firewall chain: $chain (UID: $uid), cleanin' it up..."

                    # Remove the OUTPUT jump rule
                    iptables -D OUTPUT -m owner --uid-owner "$uid" -j "$chain" 2>/dev/null

                    # Flush and delete the chain
                    iptables -F "$chain" 2>/dev/null
                    iptables -X "$chain" 2>/dev/null

                    echo "  Done. $chain is gone."
                done
            fi
        elif [ "$OS_TYPE" = "macos" ]; then
            if [ "$dry_run" = true ]; then
                echo "[dry-run] pfctl -s Anchors | grep CLAUDE_CAGE_"
                echo "[dry-run] (would clean up any matching pf anchors)"
            else
                # Clean up pf anchors
                for anchor in $(pfctl -s Anchors 2>/dev/null | grep "CLAUDE_CAGE_"); do
                    echo "Found firewall anchor: $anchor, cleanin' it up..."
                    delete_firewall_chain "$anchor" "$user_uid"
                    echo "  Done. $anchor is gone."
                done
            fi
        fi
    fi

    # Docker mode doesn't need --cleanup (no system-level changes)
    if [ "$cfg_isolationMode" = "docker" ]; then
        echo ""
        echo "Docker mode doesn't leave system-level mess to clean up."
        echo "To delete a container, use: claude-cage --delete-docker-container"
    fi

    # Kill processes from PID file
    if [ -f "$pid_file" ] || [ "$dry_run" = true ]; then
        echo "Found PID file, stoppin' tracked processes..."
        if [ "$dry_run" = true ]; then
            echo "[dry-run] kill <PIDs from $pid_file>"
            echo "[dry-run] rm -f $pid_file"
        else
            while IFS= read -r pid; do
                if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
                    kill "$pid" 2>/dev/null
                    echo "  Process $pid stopped."
                fi
            done < "$pid_file"
            rm -f "$pid_file"
        fi
        echo "  PID file's gone."
    else
        echo "No PID file found at $pid_file"
    fi

    # Ask about user deletion (only in user mode, not docker mode)
    # Docker mode doesn't create system users
    if [ "$cfg_isolationMode" != "docker" ]; then
        if user_exists "$cfg_user"; then
            echo ""
            echo "User '$cfg_user' exists on this system."
            echo "This is a shared user for all projects."
            echo "Not deletin' the user. If you want to remove it, do that manually."
        else
            echo "User '$cfg_user' doesn't exist. Nothin' to delete."
        fi
    fi

    echo ""
    echo "Cleanup complete. All done."
    exit 0
fi

# Now check for root after validating config (unless dry-run or docker mode)
# Docker mode doesn't need root - just Docker group membership
if [ "$cfg_isolationMode" != "docker" ] && [ "$EUID" -ne 0 ] && [ "$dry_run" != true ]; then
    echo "Gonna need you to run this as root. Use sudo, Bay-BEE!"
    exit 1
fi

if [ "$cfg_showBanner" = "true" ]; then
    print_banner
fi

echo "Alright. Here's what we're workin' with:"
echo ""
echo "Configuration:"
echo "  Project:       $cfg_project"
echo "  Isolation:     $cfg_isolationMode"
if [ "$cfg_isolationMode" = "docker" ]; then
    echo "  Image:         $cfg_docker_image"
    if [ -n "$cfg_docker_packages" ]; then
        echo "  Packages:      $(echo "$cfg_docker_packages" | tr '|' ' ')"
    fi
else
    echo "  User:          $cfg_user"
fi
if [ "$cfg_directMount" = "workspace" ]; then
    echo "  File mode:     Direct mount (workspace - access to sibling projects)"
    echo "  Source:        $cfg_source"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
elif [ "$cfg_directMount" = "project" ]; then
    echo "  File mode:     Direct mount (project only)"
    echo "  Source:        $cfg_source"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
else
    echo "  File mode:     Sync mode"
    echo "  Source:        $cfg_source"
    echo "  Sync:          $cfg_sync"
    if [ -n "$start_subdir" ]; then
        echo "  Start dir:     $start_subdir"
    fi
fi
if [ "$cfg_isolationMode" != "docker" ]; then
    if [ -n "$cfg_mountBase" ]; then
        echo "  Mount point:   /home/$cfg_user/$cfg_mountBase/$cfg_mounted"
    else
        echo "  Mount point:   /home/$cfg_user/$cfg_mounted"
    fi
fi
echo "  Network mode:  $cfg_networkMode"

# Display excludes and network rules grouped by source config
# Format from Lua: CATEGORY|source|type|items,comma,separated
# Sources are ordered: system, user, local, project

# Helper to get display name for source
get_source_display() {
    case "$1" in
        system) echo "System config" ;;
        user) echo "User config" ;;
        local) echo "Local config" ;;
        project) echo "Project config" ;;
        *) echo "$1" ;;
    esac
}

# Collect and display excludes by source
echo ""
echo "Excludes:"
has_excludes=false
current_source=""
for line in "${cfg_display_lines[@]}"; do
    IFS='|' read -r category source type items <<< "$line"
    if [ "$category" = "EXCLUDE" ]; then
        has_excludes=true
        if [ "$source" != "$current_source" ]; then
            current_source="$source"
            echo "  $(get_source_display "$source"):"
        fi
        # Capitalize first letter of type
        type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
        [ "$type" = "belowPath" ] && type_display="BelowPath"
        printf "    %-10s %s\n" "$type_display:" "$items"
    fi
done
if [ "$has_excludes" = false ]; then
    echo "  (none)"
fi

# Display cageLocal patterns if any
has_cageLocal=false
for line in "${cfg_display_lines[@]}"; do
    IFS='|' read -r category source type items <<< "$line"
    if [ "$category" = "CAGELOCAL" ]; then
        if [ "$has_cageLocal" = false ]; then
            echo ""
            echo "Cage-local files (new creations blocked on source):"
            has_cageLocal=true
            current_source=""
        fi
        if [ "$source" != "$current_source" ]; then
            current_source="$source"
            echo "  $(get_source_display "$source"):"
        fi
        # Capitalize first letter of type
        type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
        [ "$type" = "belowPath" ] && type_display="BelowPath"
        printf "    %-10s %s\n" "$type_display:" "$items"
    fi
done

# Display network rules by source if network mode is enabled
if [ "$cfg_networkMode" != "disabled" ]; then
    echo ""
    echo "Network restrictions ($cfg_networkMode mode):"

    has_block=false
    has_allow=false
    current_source=""

    # Show block rules first (for blocklist mode)
    if [ "$cfg_networkMode" = "blocklist" ]; then
        for line in "${cfg_display_lines[@]}"; do
            IFS='|' read -r category source type items <<< "$line"
            if [ "$category" = "BLOCK" ]; then
                has_block=true
                if [ "$source" != "$current_source" ]; then
                    current_source="$source"
                    echo "  Block ($(get_source_display "$source")):"
                fi
                type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
                printf "    %-10s %s\n" "$type_display:" "$items"
            fi
        done
    fi

    # Show allow rules
    current_source=""
    for line in "${cfg_display_lines[@]}"; do
        IFS='|' read -r category source type items <<< "$line"
        if [ "$category" = "ALLOW" ]; then
            has_allow=true
            if [ "$source" != "$current_source" ]; then
                current_source="$source"
                if [ "$cfg_networkMode" = "blocklist" ]; then
                    echo "  Exceptions ($(get_source_display "$source")):"
                else
                    echo "  Allow ($(get_source_display "$source")):"
                fi
            fi
            type_display=$(echo "$type" | sed 's/\b\(.\)/\u\1/')
            printf "    %-10s %s\n" "$type_display:" "$items"
        fi
    done
fi
echo ""

# Set computed values
cfg_user="${cfg_user:-claude}"
if [ -z "$cfg_mounted" ]; then
    cfg_mounted="$cfg_source"
fi

# Validate and sanitize username
original_username="$cfg_user"
sanitized_username="$cfg_user"
was_truncated=false

# Check for invalid characters (allowed: lowercase letters, digits, hyphens, underscores)
# Must start with a letter or underscore
if [[ ! "$sanitized_username" =~ ^[a-zA-Z_][a-zA-Z0-9_-]*$ ]]; then
    # Replace invalid characters with hyphens
    # First, ensure it starts with a valid character
    if [[ ! "$sanitized_username" =~ ^[a-zA-Z_] ]]; then
        sanitized_username="u-$sanitized_username"
    fi
    # Replace invalid characters with hyphens
    sanitized_username=$(echo "$sanitized_username" | sed 's/[^a-zA-Z0-9_-]/-/g')
    # Convert to lowercase for maximum compatibility
    sanitized_username=$(echo "$sanitized_username" | tr '[:upper:]' '[:lower:]')
fi

# Remove trailing hyphens/underscores (valid but not best practice)
if [[ "$sanitized_username" =~ [-_]+$ ]]; then
    sanitized_username=$(echo "$sanitized_username" | sed 's/[-_]*$//')
fi

# Check username length (useradd has 32 character limit)
if [ ${#sanitized_username} -gt 32 ]; then
    sanitized_username="${sanitized_username:0:32}"
    # Re-check for trailing hyphens after truncation
    sanitized_username=$(echo "$sanitized_username" | sed 's/[-_]*$//')
    was_truncated=true
fi

# Display warning only if username was truncated
if [ "$was_truncated" = true ]; then
    echo ""
    echo "Hold on now. That username's too long for this bird."
    echo "What you wanted:  $original_username (${#original_username} characters)"
    echo "What you got:     $sanitized_username (${#sanitized_username} characters)"
    echo "Had to trim it down. Regulations, you understand."
    echo ""
fi

cfg_user="$sanitized_username"

# Check if sanitized username conflicts with existing system user
if [ "$original_username" != "$sanitized_username" ] && user_exists "$sanitized_username"; then
    echo ""
    echo "Hold on now. We got ourselves a situation here."
    echo "After cleanin' up that username, it became '$sanitized_username'"
    echo "But there's already a user with that name on this system."
    echo ""
    echo "You got two choices:"
    echo "  1. Change the username in your config to somethin' else"
    echo "  2. Continue if you're sure this is the right user to use"
    echo ""
    read -p "Continue with existing user '$sanitized_username'? [y/N] " -n 1 -r
    echo
    if ! [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "Smart move. Change that username and try again."
        exit 1
    fi
fi

# Track if user exists before we start
user_existed_before=false
if user_exists "$cfg_user"; then
    user_existed_before=true
fi

# Create claude-cage base directory for tracking/config
run mkdir -p "$cage_home_base"

# Track whether we prompted the user to continue
user_was_prompted=false

# Create user if it doesn't exist (or show what would be created in dry-run)
if ! user_exists "$cfg_user" || [ "$dry_run" = true ]; then
    if [ "$dry_run" = true ]; then
        echo "Would create user '$cfg_user' (doesn't exist or dry-run mode)."
        create_user "$cfg_user" "" "false"
        user_home="/home/$cfg_user"
        user_was_prompted=true
    else
        echo "That user '$cfg_user' ain't on this system yet."
        read -p "Want me to create that user? [y/N] " -n 1 -r
        echo
        user_was_prompted=true
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            create_user "$cfg_user" "" "false"
            user_home=$(get_user_home "$cfg_user")
            echo "Done. User '$cfg_user' is ready to go (home: $user_home)."
        else
            echo "Can't fly this bird without that user. We're done here."
            exit 1
        fi
    fi
fi

# Prompt to continue if user wasn't already prompted during user creation (skip in dry-run)
if [ "$user_was_prompted" = "false" ] && [ "$dry_run" != true ]; then
    echo ""
    read -p "Ready to proceed? [Y/n] " -n 1 -r key
    echo
    if [[ $key =~ ^[Nn]$ ]]; then
        echo "Alright, abortin' the mission."
        exit 0
    fi
fi

# Set user_home for later use
if [ "$dry_run" = true ]; then
    # In dry-run, user might not exist, so use default path
    user_home="${user_home:-/home/$cfg_user}"
    user_uid="${user_uid:-<UID>}"
elif [ "$cfg_isolationMode" = "docker" ]; then
    # Docker mode: no host user, use defaults for any host-side paths
    user_home="/home/$cfg_user"
    user_uid="$(id -u)"  # Current user's UID for file ownership
else
    user_home=$(get_user_home "$cfg_user")
    # Get user UID for cleanup function (needed for firewall rule deletion)
    user_uid=$(get_user_uid "$cfg_user")
fi

# Check if Claude Code is installed for the user
check_claude_installed() {
    local username="$1"
    local home_dir="$2"

    # Check if claude is in user's PATH (including ~/.local/bin)
    if su - "$username" -c "command -v claude" >/dev/null 2>&1; then
        return 0
    fi

    # Also check common locations explicitly
    if [ -x "$home_dir/.local/bin/claude" ]; then
        return 0
    fi

    return 1
}

install_claude_code() {
    local username="$1"
    local home_dir="$2"

    echo ""
    echo "Now hold on. Claude Code ain't installed for user '$username'."
    echo "Can't run this operation without the main man himself."
    echo ""
    read -p "Want me to install Claude Code for this user? [y/N] " -n 1 -r
    echo

    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Alright, we're bailin' out. Install Claude Code yourself and try again."
        echo "Run this as the user: curl -fsSL https://claude.ai/install.sh | bash"
        return 1
    fi

    # Check for curl
    if ! command -v curl >/dev/null 2>&1; then
        echo "Now we got a problem. Need curl to download, and it ain't here."
        echo "Install curl and try again, or install Claude Code manually."
        return 1
    fi

    echo "Alright, runnin' the official installer..."
    echo "This might take a minute. Sit tight."

    # Run the official Claude Code installer as the target user
    if su - "$username" -c "curl -fsSL https://claude.ai/install.sh | bash" 2>&1; then
        echo ""
        echo "Done. Claude Code is locked and loaded."
        return 0
    else
        echo ""
        echo "The installer hit a snag. You might need to install manually."
        echo "Try runnin' as the user: curl -fsSL https://claude.ai/install.sh | bash"
        return 1
    fi
}

# Check if Claude Code is available for the user (skip in dry-run and Docker mode)
# In Docker mode, Claude Code is checked/installed inside the container, not on the host
if [ "$dry_run" = true ]; then
    echo "[dry-run] Would check if Claude Code is installed for user '$cfg_user'"
elif [ "$cfg_isolationMode" = "docker" ]; then
    # Docker mode: will check inside container later
    :
elif ! check_claude_installed "$cfg_user" "$user_home"; then
    if ! install_claude_code "$cfg_user" "$user_home"; then
        echo "Can't proceed without Claude Code installed. We're done here."
        exit 1
    fi
fi

# Construct mount point: /home/<user>/<mountBase>/<mounted>/ or /home/<user>/<mounted>/
# In workspace mode, use source directory basename or "workspace" if source is "."
# In project mode, use the project/subdirectory name
if [ "$cfg_directMount" = "workspace" ]; then
    # Workspace mode: mounted name based on source directory
    if [ "$cfg_source" = "." ]; then
        workspace_name=$(basename "$(pwd)")
    else
        workspace_name=$(basename "$cfg_source")
    fi
    if [ -n "$cfg_mountBase" ]; then
        mount_point="$user_home/${cfg_mountBase}/${workspace_name}"
    else
        mount_point="$user_home/${workspace_name}"
    fi
elif [ "$cfg_directMount" = "project" ]; then
    # Project mode: mounted name is the project subdirectory
    if [ -n "$cfg_mountBase" ]; then
        mount_point="$user_home/${cfg_mountBase}/${start_subdir}"
    else
        mount_point="$user_home/${start_subdir}"
    fi
else
    # Sync mode: use configured mounted name
    if [ -n "$cfg_mountBase" ]; then
        mount_point="$user_home/${cfg_mountBase}/${cfg_mounted}"
    else
        mount_point="$user_home/${cfg_mounted}"
    fi
fi

# For workspace direct mount mode, track instances by mount point instead of project
# This allows multiple subdirectories under the same mount to share it
if [ "$cfg_directMount" = "workspace" ]; then
    # Create a safe filename from mount point path
    mount_point_hash=$(echo "$mount_point" | md5sum | cut -d' ' -f1)
    mount_instance_file="$user_home/.claude-cage-mount-$mount_point_hash"
else
    mount_instance_file=""
fi

# Track iptables chain name for cleanup (shared chain for the user)
iptables_chain="CLAUDE_CAGE_${cfg_user}"

# Global instance file (tracks all projects for this user)
# Only used in user mode - Docker mode doesn't have a host user home
if [ "$cfg_isolationMode" = "docker" ]; then
    global_instance_file=""
else
    global_instance_file="$user_home/.claude-cage-instances"
fi

# Pre-compute Docker container name and mount destination
# (needs to be available for cleanup and launch)
if [ "$cfg_isolationMode" = "docker" ]; then
    # Determine container name
    if [ -n "$cfg_docker_container" ]; then
        # User-specified existing container
        docker_container_name_value="$cfg_docker_container"
        docker_using_existing_container=true
    elif [ "$cfg_docker_isolated" = "true" ]; then
        # Isolated mode: per-project container
        if [ "$cfg_directMount" = "workspace" ]; then
            workspace_name=$(basename "$cfg_source")
            docker_container_name_value=$(docker_container_name_isolated "$cfg_docker_namePrefix" "$workspace_name" "$cfg_source")
        else
            docker_container_name_value=$(docker_container_name_isolated "$cfg_docker_namePrefix" "$cfg_project" "$cfg_source")
        fi
        docker_using_existing_container=false
    else
        # Shared mode (default): single container for all projects
        docker_container_name_value=$(docker_container_name_shared "$cfg_docker_namePrefix" "$(id -u)")
        docker_using_existing_container=false
    fi

    # Determine mount destination / working directory
    if [ -n "$cfg_docker_workdir" ]; then
        # User-specified working directory (for existing containers)
        docker_mount_dest="$cfg_docker_workdir"
    elif [ "$cfg_directMount" = "workspace" ]; then
        workspace_name=$(basename "$cfg_source")
        docker_mount_dest="/home/claude/caged/$workspace_name"
    elif [ "$cfg_directMount" = "project" ]; then
        docker_mount_dest="/home/claude/caged/$cfg_project"
    else
        # Sync mode
        docker_mount_dest="/home/claude/caged/$cfg_project"
    fi
else
    docker_container_name_value=""
    docker_mount_dest=""
    docker_using_existing_container=false
fi

# This instance's ID
instance_id="$$"

cleanup() {
    # Skip cleanup in dry-run mode (nothing was actually set up)
    if [ "$dry_run" = true ]; then
        return
    fi

    echo ""
    echo "Alright, shuttin' down operations..."

    # Docker mode cleanup
    if [ "$cfg_isolationMode" = "docker" ]; then
        # Kill unison if running (sync mode)
        if [ -f "$pid_file" ]; then
            echo "Stoppin' unison sync..."
            while IFS= read -r pid; do
                if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
                    kill "$pid" 2>/dev/null
                fi
            done < "$pid_file"
            rm -f "$pid_file"
        fi

        # Stop container (it stays around for --continue/--resume)
        if [ -n "$docker_container_name_value" ] && docker_container_running "$docker_container_name_value"; then
            echo "Stoppin' Docker container..."
            docker_stop_container "$docker_container_name_value"
        fi

        echo "All done. Stay safe out there."
        return
    fi

    # For workspace direct mount mode, track by mount point instead of project
    # This ensures we only unmount when the last instance using that mount exits
    should_unmount=true

    if [ "$cfg_directMount" = "workspace" ] && [ -n "$mount_instance_file" ] && [ -f "$mount_instance_file" ]; then
        # Remove this instance from mount point tracker
        sed -i "/^$instance_id$/d" "$mount_instance_file"

        # Check if other instances are still using this mount point
        remaining_mount=()
        while IFS= read -r inst_id; do
            if [ -n "$inst_id" ] && kill -0 "$inst_id" 2>/dev/null; then
                remaining_mount+=("$inst_id")
            fi
        done < "$mount_instance_file"

        if [ ${#remaining_mount[@]} -gt 0 ]; then
            echo "Other instances still usin' mount point (${remaining_mount[*]}). Leavin' it mounted."
            # Update instance file to remove dead instances
            printf "%s\n" "${remaining_mount[@]}" > "$mount_instance_file"
            should_unmount=false
        else
            # Last instance using this mount, clean up the instance file
            rm -f "$mount_instance_file"
        fi
    fi

    # Remove this instance from the local instance file (project tracking)
    if [ -f "$local_instance_file" ]; then
        sed -i "/^$instance_id$/d" "$local_instance_file"

        # Check if there are other instances of THIS project still running
        remaining_local=()
        while IFS= read -r inst_id; do
            if [ -n "$inst_id" ] && kill -0 "$inst_id" 2>/dev/null; then
                remaining_local+=("$inst_id")
            fi
        done < "$local_instance_file"

        if [ ${#remaining_local[@]} -gt 0 ]; then
            echo "Other instances of this project still runnin' (${remaining_local[*]}). Leavin' processes alone."
            # Update local instance file to remove dead instances
            printf "%s\n" "${remaining_local[@]}" > "$local_instance_file"

            # Still need to remove from global in user mode
            if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
                sed -i "/^$instance_id$/d" "$global_instance_file"
            fi

            echo "This session's done. Stay safe out there."
            return
        else
            # No more instances of this project, remove the local instance file
            rm -f "$local_instance_file"
        fi
    fi

    # Remove from global instance file (user mode)
    if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
        sed -i "/^$instance_id$/d" "$global_instance_file"

        # Check if there are other projects still running as this user
        remaining_global=()
        while IFS= read -r inst_id; do
            if [ -n "$inst_id" ] && kill -0 "$inst_id" 2>/dev/null; then
                remaining_global+=("$inst_id")
            fi
        done < "$global_instance_file" 2>/dev/null

        if [ ${#remaining_global[@]} -gt 0 ]; then
            echo "Other projects still runnin' as user $cfg_user (${remaining_global[*]})."
            echo "Cleanin' up this project only. User and network rules stay in place."
            # Update global instance file to remove dead instances
            printf "%s\n" "${remaining_global[@]}" > "$global_instance_file"

            # Clean up local processes and mount (only if we should unmount)
            if [ -f "$pid_file" ]; then
                echo "Stoppin' processes from $pid_file..."
                while IFS= read -r pid; do
                    if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
                        kill "$pid" 2>/dev/null
                    fi
                done < "$pid_file"
                rm -f "$pid_file"
            fi

            if [ "$should_unmount" = "true" ] && mountpoint -q "$mount_point" 2>/dev/null; then
                echo "Unmountin' $mount_point..."
                umount -l "$mount_point" 2>/dev/null
            fi

            echo "This project's done. Other projects still flyin'. Stay safe out there."
            return
        else
            # No more instances for this user, remove the global instance file
            rm -f "$global_instance_file"
        fi
    fi

    # Only run full cleanup if this is the last instance
    echo "Last instance shuttin' down. Cleanin' up everything..."

    # Kill processes from PID file
    if [ -f "$pid_file" ]; then
        echo "Stoppin' processes from $pid_file..."
        while IFS= read -r pid; do
            if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
                kill "$pid" 2>/dev/null
            fi
        done < "$pid_file"
        rm -f "$pid_file"
    fi

    # Unmount the bindfs mount (only if we should)
    if [ "$should_unmount" = "true" ] && mountpoint -q "$mount_point" 2>/dev/null; then
        echo "Unmountin' $mount_point..."
        umount -l "$mount_point" 2>/dev/null
    fi

    # Clean up firewall rules (only if no other instances exist)
    has_other_instances=false
    if [ -n "$global_instance_file" ] && [ -f "$global_instance_file" ]; then
        while IFS= read -r inst_id; do
            if [ -n "$inst_id" ] && kill -0 "$inst_id" 2>/dev/null; then
                has_other_instances=true
                break
            fi
        done < "$global_instance_file"
    fi

    if [ "$has_other_instances" = "false" ] && firewall_chain_exists "$iptables_chain"; then
        echo "Last instance for user $cfg_user, cleanin' up network restrictions..."
        delete_firewall_chain "$iptables_chain" "$user_uid"
    fi

    # User mode always uses a shared user, so we don't delete it

    echo "All done. Stay safe out there."
}
trap cleanup SIGINT SIGTERM EXIT

# Function to resolve domain to IPs
resolve_domain() {
    local domain="$1"
    # Use getent to resolve domain (supports /etc/hosts and DNS)
    getent ahosts "$domain" 2>/dev/null | awk '{print $1}' | sort -u
}

# Function to parse IP/domain:port specification
# Returns: ip, ports (comma-separated)
parse_ip_port() {
    local spec="$1"
    local ip=""
    local ports=""

    if [[ "$spec" =~ ^(.+):([0-9,]+)$ ]]; then
        ip="${BASH_REMATCH[1]}"
        ports="${BASH_REMATCH[2]}"
    else
        ip="$spec"
        ports=""
    fi

    echo "$ip|$ports"
}

# Function to add iptables rule with optional port restriction
# Wrapper for backward compatibility - now uses OS abstraction
add_iptables_rule() {
    add_firewall_rule "$@"
}

# Function to setup network restrictions
setup_network_restrictions() {
    local mode="$1"
    local user_uid
    user_uid=$(get_user_uid "$cfg_user")

    if [ "$mode" = "disabled" ]; then
        echo "Network restrictions: None. You're flyin' without that extra safety net."
        return 0
    fi

    # Check if chain already exists
    local chain_exists=false
    if firewall_chain_exists "$iptables_chain"; then
        chain_exists=true
        echo "Addin' network restrictions to existing chain (shared in user mode)..."

        # Remove the final catch-all rule (could be ACCEPT or REJECT depending on previous mode)
        # We need to remove it so we can add new rules, then re-add it at the end
        # Try to get the last rule number and delete it (Linux only)
        local last_rule_num=$(get_last_firewall_rule_number "$iptables_chain")
        if [ -n "$last_rule_num" ]; then
            echo "Removin' final rule (line $last_rule_num) to add new restrictions..."
            delete_firewall_rule_by_number "$iptables_chain" "$last_rule_num"
        fi
    else
        echo "Settin' up network restrictions (mode: $mode)..."
        # Create custom chain for claude-cage rules
        create_firewall_chain "$iptables_chain" "$user_uid" || {
            echo "Hold on. Couldn't create firewall chain. Network restrictions may not work right."
            return 1
        }
    fi

    if [ "$mode" = "allowlist" ]; then
        # No need to remove final rule here - already done above if chain exists

        # Allow user-configured domains
        if [ -n "$cfg_allow_domains" ]; then
            IFS='|' read -ra domains <<< "$cfg_allow_domains"
            for domain_spec in "${domains[@]}"; do
                IFS='|' read -r domain ports < <(parse_ip_port "$domain_spec")
                while IFS= read -r ip; do
                    [ -n "$ip" ] && add_iptables_rule "$iptables_chain" "ACCEPT" "$ip" "$ports"
                done < <(resolve_domain "$domain")
            done
        fi

        # Allow user-configured IPs
        if [ -n "$cfg_allow_ips" ]; then
            IFS='|' read -ra ips <<< "$cfg_allow_ips"
            for ip_spec in "${ips[@]}"; do
                IFS='|' read -r ip ports < <(parse_ip_port "$ip_spec")
                add_iptables_rule "$iptables_chain" "ACCEPT" "$ip" "$ports"
            done
        fi

        # Allow user-configured networks
        if [ -n "$cfg_allow_networks" ]; then
            IFS='|' read -ra networks <<< "$cfg_allow_networks"
            for network_spec in "${networks[@]}"; do
                IFS='|' read -r network ports < <(parse_ip_port "$network_spec")
                add_iptables_rule "$iptables_chain" "ACCEPT" "$network" "$ports"
            done
        fi

        # Reject everything else (re-add at the end)
        add_catchall_firewall_rule "$iptables_chain" "REJECT"

    elif [ "$mode" = "blocklist" ]; then
        # No need to remove final rule here - already done above if chain exists

        # First, allow exceptions (these rules are processed first)
        # Use INSERT mode so exceptions go at the beginning of the chain, before any existing blocks
        # Allow user-configured domains
        if [ -n "$cfg_allow_domains" ]; then
            IFS='|' read -ra domains <<< "$cfg_allow_domains"
            for domain_spec in "${domains[@]}"; do
                IFS='|' read -r domain ports < <(parse_ip_port "$domain_spec")
                while IFS= read -r ip; do
                    [ -n "$ip" ] && add_iptables_rule "$iptables_chain" "ACCEPT" "$ip" "$ports" "insert"
                done < <(resolve_domain "$domain")
            done
        fi

        # Allow user-configured IPs
        if [ -n "$cfg_allow_ips" ]; then
            IFS='|' read -ra ips <<< "$cfg_allow_ips"
            for ip_spec in "${ips[@]}"; do
                IFS='|' read -r ip ports < <(parse_ip_port "$ip_spec")
                add_iptables_rule "$iptables_chain" "ACCEPT" "$ip" "$ports" "insert"
            done
        fi

        # Allow user-configured networks
        if [ -n "$cfg_allow_networks" ]; then
            IFS='|' read -ra networks <<< "$cfg_allow_networks"
            for network_spec in "${networks[@]}"; do
                IFS='|' read -r network ports < <(parse_ip_port "$network_spec")
                add_iptables_rule "$iptables_chain" "ACCEPT" "$network" "$ports" "insert"
            done
        fi

        # Then, block configured targets
        # Block user-configured domains
        if [ -n "$cfg_block_domains" ]; then
            IFS='|' read -ra domains <<< "$cfg_block_domains"
            for domain_spec in "${domains[@]}"; do
                IFS='|' read -r domain ports < <(parse_ip_port "$domain_spec")
                while IFS= read -r ip; do
                    [ -n "$ip" ] && add_iptables_rule "$iptables_chain" "REJECT" "$ip" "$ports"
                done < <(resolve_domain "$domain")
            done
        fi

        # Block user-configured IPs
        if [ -n "$cfg_block_ips" ]; then
            IFS='|' read -ra ips <<< "$cfg_block_ips"
            for ip_spec in "${ips[@]}"; do
                IFS='|' read -r ip ports < <(parse_ip_port "$ip_spec")
                add_iptables_rule "$iptables_chain" "REJECT" "$ip" "$ports"
            done
        fi

        # Block user-configured networks
        if [ -n "$cfg_block_networks" ]; then
            IFS='|' read -ra networks <<< "$cfg_block_networks"
            for network_spec in "${networks[@]}"; do
                IFS='|' read -r network ports < <(parse_ip_port "$network_spec")
                add_iptables_rule "$iptables_chain" "REJECT" "$network" "$ports"
            done
        fi

        # Accept everything else
        add_catchall_firewall_rule "$iptables_chain" "ACCEPT"
    fi

    echo "Network restrictions in place. Locked down tight."
}

# Check for excluded files in sync directory (skip in directMount mode)
# Only check patterns that changed since last run
if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ] && [ -d "$cfg_sync" ]; then
    config_cache="$cfg_config_root/.caged/${cfg_project}/excludes-cache"
    current_excludes="${cfg_exclude_path}|${cfg_exclude_name}|${cfg_exclude_regex}|${cfg_exclude_belowPath}"

    # Check if exclude patterns changed since last run
    if [ -f "$config_cache" ]; then
        previous_excludes=$(cat "$config_cache")
        if [ "$current_excludes" != "$previous_excludes" ]; then
            echo "Hold on now. Your exclude patterns changed since last time."
            echo "Let me check if any newly-excluded files are sittin' in the sync directory..."

            # Find newly added patterns by comparing
            excluded_files=()

            # Only check patterns that are new (weren't in previous config)
            # This is a simplified check - we scan all current excludes and warn the user

            # Check exclude.path patterns
            if [ -n "$cfg_exclude_path" ]; then
                IFS='|' read -ra paths <<< "$cfg_exclude_path"
                for pattern in "${paths[@]}"; do
                    if [ -e "$cfg_sync/$pattern" ]; then
                        excluded_files+=("$cfg_sync/$pattern")
                    fi
                done
            fi

            # Check exclude.name patterns
            if [ -n "$cfg_exclude_name" ]; then
                IFS='|' read -ra names <<< "$cfg_exclude_name"
                for pattern in "${names[@]}"; do
                    while IFS= read -r -d '' file; do
                        excluded_files+=("$file")
                    done < <(find "$cfg_sync" -name "$pattern" -print0 2>/dev/null)
                done
            fi

            # Check exclude.regex patterns
            if [ -n "$cfg_exclude_regex" ]; then
                IFS='|' read -ra regexes <<< "$cfg_exclude_regex"
                for pattern in "${regexes[@]}"; do
                    while IFS= read -r -d '' file; do
                        excluded_files+=("$file")
                    done < <(find "$cfg_sync" -regextype posix-extended -regex "$cfg_sync/$pattern" -print0 2>/dev/null)
                done
            fi

            # Check belowPath patterns
            # Check exclude.belowPath patterns
            if [ -n "$cfg_exclude_belowPath" ]; then
                IFS='|' read -ra paths <<< "$cfg_exclude_belowPath"
                for pattern in "${paths[@]}"; do
                    if [ -d "$cfg_sync/$pattern" ]; then
                        excluded_files+=("$cfg_sync/$pattern")
                    fi
                done
            fi

            # If excluded files found, prompt user
            if [ ${#excluded_files[@]} -gt 0 ]; then
                echo ""
                echo "Now hold on. We got files here that match your new exclusion rules:"
                for file in "${excluded_files[@]}"; do
                    echo "  - $file"
                done
                echo ""
                echo "These could be from before you changed the rules."
                echo "They'll be ignored during sync, but they're still takin' up space."
                echo ""
                read -p "Want me to remove these files? [y/N] " -n 1 -r
                echo
                if [[ $REPLY =~ ^[Yy]$ ]]; then
                    for file in "${excluded_files[@]}"; do
                        rm -rf "$file"
                        echo "Gone: $file"
                    done
                else
                    echo "Alright. They'll stay there but won't sync. Your call."
                fi
            fi
        fi
    fi

    # Save current exclude patterns for next run
    echo "$current_excludes" > "$config_cache"
fi

# Check if there's already a running instance
skip_setup=false
if [ -f "$pid_file" ]; then
    echo "Hold on now. Found a PID file from a previous run."
    echo "Checkin' if those processes are still alive..."

    running_pids=()
    while IFS= read -r pid; do
        if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
            running_pids+=("$pid")
        fi
    done < "$pid_file"

    if [ ${#running_pids[@]} -gt 0 ]; then
        echo "Processes still runnin': ${running_pids[*]}"
        echo "Reusing existing unison and bindfs processes."
        echo ""
        skip_setup=true
    else
        echo "Those processes are gone. Cleanin' up the old PID file..."
        rm -f "$pid_file"
    fi
fi

if [ "$skip_setup" = false ]; then
    # Create .caged/project-name/ directory for instance/PID files at config root
    run mkdir -p "$cfg_config_root/.caged/$cfg_project"

    # Set ownership of .caged directory and everything under it to original user
    # (only needed in user mode where we run as root - Docker mode runs as user already)
    if [ "$cfg_isolationMode" != "docker" ]; then
        run chown -R "$original_user:$original_user" "$cfg_config_root/.caged"
    fi

    if [ "$cfg_isolationMode" = "docker" ]; then
        # Docker mode setup
        echo "Docker mode: settin' up container..."
        echo "Container name: $docker_container_name_value"

        if [ "$docker_using_existing_container" = true ]; then
            # Using user-specified existing container
            echo "Using existing container (user-managed)..."

            # Verify container exists
            if ! docker_container_exists "$docker_container_name_value"; then
                echo "Hold on now. That container '$docker_container_name_value' don't exist."
                echo "Make sure you've created it first. See docs/docker-existing-container.md"
                exit 1
            fi

            # Verify container is running
            if ! docker_container_running "$docker_container_name_value"; then
                echo "Container exists but ain't runnin'. Startin' it..."
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] docker start $docker_container_name_value"
                else
                    docker start "$docker_container_name_value" >/dev/null 2>&1
                    if ! docker_container_running "$docker_container_name_value"; then
                        echo "Failed to start container."
                        exit 1
                    fi
                fi
            fi
            echo "Container ready."

            # Note: Skip homeConfigSync for existing containers - user manages their own config

        else
            # claude-cage manages the container
            # Determine network mode for Docker
            case "$cfg_networkMode" in
                disabled|allowlist)
                    docker_network="none"
                    ;;
                blocklist)
                    docker_network="bridge"
                    ;;
                *)
                    docker_network="none"
                    ;;
            esac

            # Build/ensure image with packages
            docker_image_to_use=$(docker_ensure_image "$cfg_docker_image" "$cfg_docker_packages")
            if [ -z "$docker_image_to_use" ]; then
                echo "Failed to prepare Docker image."
                exit 1
            fi
            echo "Using image: $docker_image_to_use"

            # Determine mount source (destination was pre-computed)
            if [ "$cfg_directMount" = "workspace" ] || [ "$cfg_directMount" = "project" ]; then
                # Direct mount mode: mount source directly
                docker_mount_source="$cfg_source"
            else
                # Sync mode: run unison first, then mount sync directory
                run mkdir -p "$cfg_sync"

                # Build unison command with exclude options
                unison_cmd_base="unison \"$cfg_source\" \"$cfg_sync\" -batch -confirmbigdel=false"
                if [ -n "$cfg_exclude" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_exclude"
                fi
                if [ -n "$cfg_cageLocal" ]; then
                    unison_cmd_base="$unison_cmd_base $cfg_cageLocal"
                fi

                unison_cmd_initial="$unison_cmd_base -force \"$cfg_source\" -prefer \"$cfg_source\""
                unison_cmd_ongoing="$unison_cmd_base -auto"

                # Check for watch mode
                if command -v unison-fsmonitor >/dev/null 2>&1; then
                    repeat_mode="watch"
                else
                    repeat_mode="1"
                    echo "No unison-fsmonitor. Using polling mode (check every second)."
                fi

                # Run initial and ongoing sync
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] bash -c '$unison_cmd_initial'"
                    echo "[dry-run] bash -c '$unison_cmd_ongoing -repeat $repeat_mode' &"
                    unison_pid="<PID>"
                else
                    bash -c "$unison_cmd_initial" >/dev/null 2>&1
                    bash -c "$unison_cmd_ongoing -repeat $repeat_mode" >/dev/null 2>&1 &
                    unison_pid=$!
                fi

                # Write unison PID to file
                run bash -c "echo '$unison_pid' > '$pid_file'"

                docker_mount_source="$cfg_sync"
            fi

            # Get host UID/GID for file ownership mapping
            host_uid=$(id -u)
            host_gid=$(id -g)

            # Check if container already exists
            if docker_container_exists "$docker_container_name_value"; then
                if docker_container_running "$docker_container_name_value"; then
                    echo "Container already runnin'. Reusin' it."
                else
                    echo "Container exists but stopped. Startin' it..."
                    if [ "$dry_run" = true ]; then
                        echo "[dry-run] docker start $docker_container_name_value"
                    else
                        docker start "$docker_container_name_value" >/dev/null 2>&1
                    fi
                fi
            else
                # Start new container
                echo "Creatin' new container..."
                docker_start_container "$docker_container_name_value" "$docker_image_to_use" \
                    "$docker_mount_source" "$docker_mount_dest" \
                    "$docker_network" "$cfg_docker_extraArgs" \
                    "$host_uid" "$host_gid"

                if [ "$dry_run" != true ] && ! docker_container_running "$docker_container_name_value"; then
                    echo "Failed to start Docker container."
                    exit 1
                fi
                echo "Container started."
            fi

            # Ensure home directory exists, create claude user, and set ownership
            # Run as root to: create home dir, add claude user to /etc/passwd, chown
            # Adding user entry ensures 'whoami' returns 'claude' not 'node' (which has same UID)
            if [ "$dry_run" = true ]; then
                echo "[dry-run] docker exec -u root ... setup claude user and home directory"
            else
                docker exec -u root "$docker_container_name_value" bash -c "
                    mkdir -p /home/claude
                    # Add claude user entry if not exists (maps host UID to 'claude' username)
                    if ! grep -q '^claude:' /etc/passwd; then
                        echo 'claude:x:${host_uid}:${host_gid}::/home/claude:/bin/bash' >> /etc/passwd
                    fi
                    # Add claude group if not exists
                    if ! grep -q '^claude:' /etc/group; then
                        echo 'claude:x:${host_gid}:' >> /etc/group
                    fi
                    chown ${host_uid}:${host_gid} /home/claude
                "
                # Create .profile with PATH if it doesn't exist
                docker exec -e HOME=/home/claude "$docker_container_name_value" bash -c '[ -f ~/.profile ] || cat > ~/.profile << "PROFILE"
export PATH="$HOME/.local/bin:$PATH"
PROFILE'
            fi

            # Check if Claude Code is installed in container
            # Check explicit path since the UID may not exist in /etc/passwd (no profile to set PATH)
            if ! docker exec "$docker_container_name_value" test -x /home/claude/.local/bin/claude 2>/dev/null; then
                echo "Claude Code ain't installed in the container. Installin' it now..."
                if [ "$dry_run" = true ]; then
                    echo "[dry-run] Installing curl and Claude Code in container"
                else
                    # Install curl if needed (slim images don't have it)
                    # Run as root since apt-get needs privileges
                    if ! docker exec "$docker_container_name_value" which curl >/dev/null 2>&1; then
                        echo "Installing curl first..."
                        docker exec -u root "$docker_container_name_value" bash -c "apt-get update -qq && apt-get install -qq -y curl" >/dev/null
                        if [ $? -ne 0 ]; then
                            echo "Failed to install curl in container."
                            exit 1
                        fi
                    fi
                    # Install Claude Code (as the regular user for correct home dir)
                    # HOME and PATH must be set for the installer to work correctly and not warn
                    echo "Downloading and installing Claude Code..."
                    docker exec -e HOME=/home/claude -e PATH="/home/claude/.local/bin:\$PATH" "$docker_container_name_value" bash -c "set -o pipefail && curl -fsSL https://claude.ai/install.sh | bash"
                    if [ $? -ne 0 ]; then
                        echo "Failed to install Claude Code in container."
                        exit 1
                    fi
                    # Verify installation by checking explicit path
                    if ! docker exec "$docker_container_name_value" test -x /home/claude/.local/bin/claude 2>/dev/null; then
                        echo "Claude Code installation failed - binary not found at /home/claude/.local/bin/claude"
                        exit 1
                    fi
                    echo "Claude Code installed."
                fi
            else
                echo "Claude Code already installed in container."
            fi

            # Copy homeConfigSync files into container
            original_home="/home/${original_user}"
            for entry in "${cfg_homeConfigSync[@]}"; do
                IFS='|' read -r sync_source sync_dest <<< "$entry"
                source_path="${original_home}/${sync_source}"
                # In container, home is /home/claude (matching the user ID mapping)
                container_dest="/home/claude/${sync_dest}"

                if [ -f "$source_path" ] || [ -d "$source_path" ] || [ "$dry_run" = true ]; then
                    # Create parent directory in container first
                    container_dir=$(dirname "$container_dest")
                    docker_exec_quiet "$docker_container_name_value" mkdir -p "$container_dir"

                    # Copy file/directory
                    docker_copy_to_container "$docker_container_name_value" "$source_path" "$container_dest"
                    if [ "$dry_run" != true ]; then
                        echo "Synced $sync_source -> $sync_dest (in container)"
                    fi
                fi
            done
        fi

    else
        # User mode setup (existing code)
        # Setup network restrictions if configured
        setup_network_restrictions "$cfg_networkMode"

        # Create mount point if it doesn't exist
        run mkdir -p "$mount_point"

        # In sync mode, create sync directory and set ownership
        if [ "$cfg_directMount" != "workspace" ] && [ "$cfg_directMount" != "project" ]; then
            run mkdir -p "$cfg_sync"
            run chown -R "$original_user:$original_user" "$cfg_sync"
        fi

        # Check if mount point is already mounted
        if [ "$dry_run" != true ] && mountpoint -q "$mount_point" 2>/dev/null; then
        if [ "$cfg_directMount" = "workspace" ]; then
            # In workspace mode, reusing an existing mount is fine
            # Just register this instance and continue
            echo "Mount point already exists at $mount_point. Reusin' it."
            run bash -c "echo '$instance_id' >> '$mount_instance_file'"
            skip_mount=true
        elif [ "$cfg_directMount" = "project" ]; then
            # In project mode, mount point collision means another project is there
            echo "Hold on now. That mount point's already in use."
            echo "Location: $mount_point"
            echo ""
            echo "Another project's already mounted there."
            echo "Either that project's still runnin', or cleanup didn't happen."
            echo ""
            echo "Try one of these:"
            echo "  1. Run: sudo claude-cage --cleanup (if old instance is dead)"
            echo "  2. Check what's mounted: mount | grep $mount_point"
            exit 1
        else
            # In sync mode, an existing mount is a problem
            echo "Hold on now. That mount point's already in use."
            echo "Location: $mount_point"
            echo ""
            echo "Looks like another project's already mounted there."
            echo "Either that project's still runnin', or cleanup didn't happen."
            echo ""
            echo "Try one of these:"
            echo "  1. Set a different 'mounted' name in your config"
            echo "  2. Run: sudo claude-cage --cleanup (if old instance is dead)"
            echo "  3. Check what's mounted: mount | grep $mount_point"
            exit 1
        fi
    else
        skip_mount=false
    fi

    if [ "$cfg_directMount" = "workspace" ]; then
        if [ "$skip_mount" = "false" ]; then
            # Workspace mode: mount entire source directory
            echo "Workspace mode: mountin' $cfg_source directly..."
            # Quote paths properly to handle spaces
            if ! run bindfs -u "$cfg_user" -g "$cfg_user" --create-for-user="$original_user" --create-for-group="$original_user" "$cfg_source" "$mount_point"; then
                if [ "$dry_run" != true ]; then
                    echo "Now we got a problem. bindfs failed to mount."
                    echo "Check that bindfs is installed and $cfg_source exists."
                    exit 1
                fi
            fi

            # Verify mount succeeded (skip in dry-run)
            if [ "$dry_run" != true ] && ! mountpoint -q "$mount_point" 2>/dev/null; then
                echo "Somethin' went wrong. Mount point ain't there after bindfs."
                echo "Check your permissions and try again."
                exit 1
            fi

            echo "Mount successful."

            # Register this instance with the mount point tracker
            run bash -c "echo '$instance_id' >> '$mount_instance_file'"
        fi
        # Note: if skip_mount=true, instance was already registered earlier
    elif [ "$cfg_directMount" = "project" ]; then
        # Project mode: mount only the specific project subdirectory
        echo "Project mode: mountin' $cfg_source/$start_subdir directly..."
        # Quote paths properly to handle spaces
        if ! run bindfs -u "$cfg_user" -g "$cfg_user" --create-for-user="$original_user" --create-for-group="$original_user" "$cfg_source/$start_subdir" "$mount_point"; then
            if [ "$dry_run" != true ]; then
                echo "Now we got a problem. bindfs failed to mount."
                echo "Check that bindfs is installed and $cfg_source/$start_subdir exists."
                exit 1
            fi
        fi

        # Verify mount succeeded (skip in dry-run)
        if [ "$dry_run" != true ] && ! mountpoint -q "$mount_point" 2>/dev/null; then
            echo "Somethin' went wrong. Mount point ain't there after bindfs."
            echo "Check your permissions and try again."
            exit 1
        fi

        echo "Mount successful."
    else
        # Sync mode: use unison + bindfs
        # Build unison command with exclude options
        # Quote paths to handle spaces properly
        unison_cmd_base="unison \"$cfg_source\" \"$cfg_sync\" -batch -confirmbigdel=false"
        if [ -n "$cfg_exclude" ]; then
            unison_cmd_base="$unison_cmd_base $cfg_exclude"
        fi
        # Add cageLocal patterns (block creation of new files on source)
        if [ -n "$cfg_cageLocal" ]; then
            unison_cmd_base="$unison_cmd_base $cfg_cageLocal"
        fi

        # Initial sync: force from source to sync to establish clean starting state
        unison_cmd_initial="$unison_cmd_base -force \"$cfg_source\" -prefer \"$cfg_source\""

        # Ongoing sync: bidirectional with auto-resolution
        unison_cmd_ongoing="$unison_cmd_base -auto"

        # Check if unison-fsmonitor is available for watch mode
        if command -v unison-fsmonitor >/dev/null 2>&1; then
            repeat_mode="watch"
        else
            # Fall back to polling mode (every 1 second)
            repeat_mode="1"
            echo "Looks like unison-fsmonitor ain't installed. That's alright."
            echo "We're gonna use polling mode instead. Check for changes every second."
            echo "You want it faster? Install unison-fsmonitor. But this'll do the job."
        fi

        # Run initial sync, then ongoing sync as the original user
        # Pass command to bash to preserve quoting
        if [ "$dry_run" = true ]; then
            echo "[dry-run] su $original_user -c \"bash -c '$unison_cmd_initial'\""
            echo "[dry-run] su $original_user -c \"bash -c '$unison_cmd_ongoing -repeat $repeat_mode'\" &"
            unison_pid="<PID>"
        else
            su "$original_user" -c "bash -c '$unison_cmd_initial'" >/dev/null 2>&1
            su "$original_user" -c "bash -c '$unison_cmd_ongoing -repeat $repeat_mode'" >/dev/null 2>&1 &
            unison_pid=$!
        fi

        if ! run bindfs -u "$cfg_user" -g "$cfg_user" --create-for-user="$original_user" --create-for-group="$original_user" "$cfg_sync" "$mount_point"; then
            if [ "$dry_run" != true ]; then
                echo "Now we got a problem. bindfs failed to mount."
                echo "Check that bindfs is installed and $cfg_sync exists."
                # Kill unison since we're bailing
                kill "$unison_pid" 2>/dev/null
                exit 1
            fi
        fi

        # Verify mount succeeded (skip in dry-run)
        if [ "$dry_run" != true ] && ! mountpoint -q "$mount_point" 2>/dev/null; then
            echo "Somethin' went wrong. Mount point ain't there after bindfs."
            echo "Check your permissions and try again."
            kill "$unison_pid" 2>/dev/null
            exit 1
        fi

        # Write unison PID to file for cleanup (bindfs doesn't run as a daemon)
        run bash -c "echo '$unison_pid' > '$pid_file'"
    fi
    fi  # End of user mode setup
else
    # Verify mount point still exists (user mode only)
    if [ "$cfg_isolationMode" != "docker" ] && ! mountpoint -q "$mount_point" 2>/dev/null; then
        echo "Wait a minute. The mount point ain't there anymore."
        echo "Somethin' went wrong. Run: sudo claude-cage --cleanup"
        exit 1
    fi
    echo "Mount point's still there at $mount_point. We're good."
fi

# Register this instance
run bash -c "echo '$instance_id' >> '$local_instance_file'"

# In user mode, also register globally
if [ "$cfg_isolationMode" != "docker" ] && [ -n "$global_instance_file" ]; then
    run bash -c "echo '$instance_id' >> '$global_instance_file'"
fi

# Sync home config files from original user's home to cage user's home
# Configured via homeConfigSync in config file
# Entries are processed in order - useful for copying a directory then overwriting specific files
# Skip for Docker mode - handled in Docker setup branch
if [ "$cfg_isolationMode" != "docker" ]; then
    original_home="/home/${original_user}"
    for entry in "${cfg_homeConfigSync[@]}"; do
        IFS='|' read -r sync_source sync_dest <<< "$entry"
        source_path="${original_home}/${sync_source}"
        dest_path="${user_home}/${sync_dest}"
        dest_dir=$(dirname "$dest_path")

        if [ -f "$source_path" ] || [ -d "$source_path" ] || [ "$dry_run" = true ]; then
        # Create destination parent directory if needed
        if [ ! -d "$dest_dir" ]; then
            run mkdir -p "$dest_dir"
            run chown "$cfg_user:$cfg_user" "$dest_dir"
        fi

        # Sync file or directory
        if [ "$dry_run" = true ]; then
            if [ -d "$source_path" ]; then
                echo "[dry-run] rsync -r $source_path/ $dest_path/"
                echo "[dry-run] chown -R $cfg_user:$cfg_user $dest_path"
            else
                echo "[dry-run] rsync $source_path $dest_path"
                echo "[dry-run] chown $cfg_user:$cfg_user $dest_path"
            fi
        else
            if [ -d "$source_path" ]; then
                # Directory: recursive sync with trailing slashes
                rsync -r "$source_path/" "$dest_path/"
                chown -R "$cfg_user:$cfg_user" "$dest_path"
                echo "Synced $sync_source/ -> $sync_dest/"
            elif [ -f "$source_path" ]; then
                rsync "$source_path" "$dest_path"
                chown "$cfg_user:$cfg_user" "$dest_path"
                echo "Synced $sync_source -> $sync_dest"
            fi
        fi
    fi
    done
fi  # End of homeConfigSync for user mode

if [ "$dry_run" = true ]; then
    echo ""
    echo "=== DRY-RUN COMPLETE ==="
    echo "No changes were made. Above shows what would be executed."
    echo ""
    exit 0
elif [ "$test_mode" = true ]; then
    echo ""
    echo "=== TEST MODE ==="

    if [ "$cfg_isolationMode" = "docker" ]; then
        echo "Alright, everything's ready. Droppin' you into the Docker container."
        echo "Your files are at: $docker_mount_dest"
        if [ -n "$start_subdir" ]; then
            echo "Navigate to your project with: cd $docker_mount_dest/$start_subdir"
        fi
        echo ""
        echo "When you're done pokin' around, type 'exit' and we'll clean up."
        echo "================="
        echo ""
        # Use bash with PATH set up so 'claude' command works
        if [ -n "$cfg_docker_user" ]; then
            docker_exec "$docker_container_name_value" --user "$cfg_docker_user" bash -c "export PATH=\"/home/claude/.local/bin:\$PATH\" && exec bash"
        else
            docker_exec "$docker_container_name_value" bash -c "export PATH=\"/home/claude/.local/bin:\$PATH\" && exec bash"
        fi
        exit_code=$?
    else
        echo "Alright, everything's ready. Switchin' you over to user '$cfg_user' so you can test things out."
        if [ "$cfg_directMount" = "workspace" ]; then
            echo "Your files are mounted at: $mount_point"
            echo "Navigate to your project with: cd $mount_point/$start_subdir"
            echo "You can access sibling projects from the mount root."
        elif [ "$cfg_directMount" = "project" ]; then
            echo "Your files are mounted at: $mount_point"
            echo "Navigate there with: cd $mount_point"
            echo "Only this project is accessible (no sibling projects)."
        else
            echo "Your files are mounted at: $mount_point"
            if [ -n "$start_subdir" ]; then
                echo "Navigate to your project with: cd $mount_point/$start_subdir"
            else
                echo "Navigate there with: cd $mount_point"
            fi
        fi
        echo ""
        echo "When you're done pokin' around, type 'exit' and we'll clean up."
        echo "================="
        echo ""
        su - "$cfg_user"
        exit_code=$?
    fi
else
    # Build claude command with optional flags
    # Use full path in Docker mode since PATH isn't set up for non-existent users
    if [ "$cfg_isolationMode" = "docker" ]; then
        claude_cmd="/home/claude/.local/bin/claude"
    else
        claude_cmd="claude"
    fi
    if [ "$claude_continue" = true ]; then
        claude_cmd="$claude_cmd --continue"
    elif [ "$claude_resume" = true ]; then
        claude_cmd="$claude_cmd --resume"
    fi

    if [ "$cfg_isolationMode" = "docker" ]; then
        # Docker mode: run claude inside container
        # Determine working directory inside container
        if [ -n "$start_subdir" ]; then
            docker_workdir="$docker_mount_dest/$start_subdir"
        else
            docker_workdir="$docker_mount_dest"
        fi

        if [ -n "$cfg_docker_user" ]; then
            docker_exec "$docker_container_name_value" --user "$cfg_docker_user" bash -c "cd \"$docker_workdir\" && $claude_cmd"
        else
            docker_exec "$docker_container_name_value" bash -c "cd \"$docker_workdir\" && $claude_cmd"
        fi
        exit_code=$?
    else
        # User mode: run Claude as the caged user in the mounted directory
        if [ "$cfg_directMount" = "workspace" ]; then
            # Workspace mode: start in the specified subdirectory within the mount
            su - "$cfg_user" -c "cd \"$mount_point/$start_subdir\" && $claude_cmd"
        elif [ "$cfg_directMount" = "project" ]; then
            # Project mode: start at the mount point root (which is the project dir)
            su - "$cfg_user" -c "cd \"$mount_point\" && $claude_cmd"
        else
            # Sync mode: start in the subdirectory corresponding to CWD relative to config root
            if [ -n "$start_subdir" ]; then
                su - "$cfg_user" -c "cd \"$mount_point/$start_subdir\" && $claude_cmd"
            else
                su - "$cfg_user" -c "cd \"$mount_point\" && $claude_cmd"
            fi
        fi
        exit_code=$?
    fi
fi

# Explicit exit to ensure cleanup trap fires
exit $exit_code
